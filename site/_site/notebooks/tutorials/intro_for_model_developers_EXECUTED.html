<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.47">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ValidMind Introduction for Model Developers – ValidMind</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../validmind.png" rel="icon" type="image/png">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": true,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-S46CKWPNSS"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-S46CKWPNSS', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"express",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../about/ValidMind-logo-color.svg" alt="" class="navbar-logo">
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about/overview.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../get-started/get-started.html"> 
<span class="menu-text">Get Started</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../guide/guides.html"> 
<span class="menu-text">Guides</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-fa-cube--developer-framework" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text"><i class="fa-solid fa-cube" aria-label="cube"></i> Developer Framework</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-fa-cube--developer-framework">    
        <li>
    <a class="dropdown-item" href="../../developer/get-started-developer-framework.html">
 <span class="dropdown-text"><i class="fa-solid fa-rocket" aria-label="rocket"></i> Get Started</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../developer/model-documentation/supported-models.html">
 <span class="dropdown-text"><i class="fa-solid fa-cubes" aria-label="cubes"></i> Supported Models</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header"><i class="fa-solid fa-vial" aria-label="vial"></i> TESTING</li>
        <li>
    <a class="dropdown-item" href="../../developer/model-testing/testing-overview.html">
 <span class="dropdown-text"><i class="fa-solid fa-flask-vial" aria-label="flask-vial"></i> Run Tests &amp; Test Suites</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../developer/model-testing/test-descriptions.html">
 <span class="dropdown-text"><i class="fa-solid fa-microscope" aria-label="microscope"></i> Test Descriptions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../developer/model-testing/test-sandbox.html">
 <span class="dropdown-text"><i class="fa-solid fa-toolbox" aria-label="toolbox"></i> Test sandbox (BETA)</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header"><i class="fa-solid fa-code" aria-label="code"></i> CODE SAMPLES</li>
        <li>
    <a class="dropdown-item" href="../../developer/samples-jupyter-notebooks.html">
 <span class="dropdown-text"><i class="fa-solid fa-book-open-reader" aria-label="book-open-reader"></i> All Code Samples · <code>LLM</code> · <code>NLP</code> · <code>Time Series</code> · <code>Etc.</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notebooks.zip">
 <span class="dropdown-text"><i class="fa-solid fa-download" aria-label="download"></i> Download Code Samples · <code>notebooks.zip</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://jupyterhub.validmind.ai/">
 <span class="dropdown-text"><i class="fa-solid fa-hand-point-right" aria-label="hand-point-right"></i> Try it on Jupyter Hub <i class="fa-solid fa-hand-point-left" aria-label="hand-point-left"></i></span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header"><i class="fa-solid fa-book" aria-label="book"></i> REFERENCE</li>
        <li>
    <a class="dropdown-item" href="../../validmind/validmind.html" target="_blank">
 <span class="dropdown-text"><i class="fa-solid fa-external-link" aria-label="external-link"></i> ValidMind Developer Framework</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../faq/faq.html"> 
<span class="menu-text">FAQ</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../support/support.html"> 
<span class="menu-text">Support</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://validmind.com/" target="_blank"> 
<span class="menu-text">validmind.com <i class="fa-solid fa-external-link" aria-label="external-link"></i></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview-of-the-notebook" id="toc-overview-of-the-notebook" class="nav-link active" data-scroll-target="#overview-of-the-notebook">Overview of the notebook</a></li>
  <li><a href="#contents" id="toc-contents" class="nav-link" data-scroll-target="#contents">Contents</a></li>
  <li><a href="#about-validmind" id="toc-about-validmind" class="nav-link" data-scroll-target="#about-validmind">About ValidMind</a>
  <ul class="collapse">
  <li><a href="#before-you-begin" id="toc-before-you-begin" class="nav-link" data-scroll-target="#before-you-begin">Before you begin</a></li>
  <li><a href="#new-to-validmind" id="toc-new-to-validmind" class="nav-link" data-scroll-target="#new-to-validmind">New to ValidMind?</a></li>
  <li><a href="#key-concepts" id="toc-key-concepts" class="nav-link" data-scroll-target="#key-concepts">Key concepts</a></li>
  </ul></li>
  <li><a href="#initializing-the-validmind-developer-framework" id="toc-initializing-the-validmind-developer-framework" class="nav-link" data-scroll-target="#initializing-the-validmind-developer-framework">1. Initializing the ValidMind Developer Framework</a>
  <ul class="collapse">
  <li><a href="#install-the-client-library" id="toc-install-the-client-library" class="nav-link" data-scroll-target="#install-the-client-library">Install the client library</a></li>
  <li><a href="#register-a-new-model-in-validmind-ui-and-initialize-the-client-library" id="toc-register-a-new-model-in-validmind-ui-and-initialize-the-client-library" class="nav-link" data-scroll-target="#register-a-new-model-in-validmind-ui-and-initialize-the-client-library">Register a new model in ValidMind UI and initialize the client library</a></li>
  <li><a href="#verify-preview-the-documentation-template" id="toc-verify-preview-the-documentation-template" class="nav-link" data-scroll-target="#verify-preview-the-documentation-template">Verify &amp; preview the documentation template</a></li>
  </ul></li>
  <li><a href="#start-the-model-development-process-with-raw-data-run-out-of-the-box-tests-and-add-evidence-to-model-documentation" id="toc-start-the-model-development-process-with-raw-data-run-out-of-the-box-tests-and-add-evidence-to-model-documentation" class="nav-link" data-scroll-target="#start-the-model-development-process-with-raw-data-run-out-of-the-box-tests-and-add-evidence-to-model-documentation">2. Start the model development process with raw data, run out-of-the box tests, and add evidence to model documentation</a>
  <ul class="collapse">
  <li><a href="#initialize-the-validmind-datasets" id="toc-initialize-the-validmind-datasets" class="nav-link" data-scroll-target="#initialize-the-validmind-datasets">Initialize the ValidMind datasets</a></li>
  <li><a href="#run-some-tabular-data-tests" id="toc-run-some-tabular-data-tests" class="nav-link" data-scroll-target="#run-some-tabular-data-tests">Run some tabular data tests</a></li>
  <li><a href="#utilize-test-output" id="toc-utilize-test-output" class="nav-link" data-scroll-target="#utilize-test-output">Utilize test output</a></li>
  <li><a href="#documenting-the-results-based-on-two-datasets" id="toc-documenting-the-results-based-on-two-datasets" class="nav-link" data-scroll-target="#documenting-the-results-based-on-two-datasets">Documenting the results based on two datasets</a></li>
  <li><a href="#add-individual-test-results-to-model-documentation" id="toc-add-individual-test-results-to-model-documentation" class="nav-link" data-scroll-target="#add-individual-test-results-to-model-documentation">Add individual test results to model documentation</a></li>
  <li><a href="#model-testing" id="toc-model-testing" class="nav-link" data-scroll-target="#model-testing">Model Testing</a></li>
  <li><a href="#initialize-model-evaluation-objects-and-assigning-predictions" id="toc-initialize-model-evaluation-objects-and-assigning-predictions" class="nav-link" data-scroll-target="#initialize-model-evaluation-objects-and-assigning-predictions">Initialize model evaluation objects and assigning predictions</a></li>
  <li><a href="#run-the-model-evaluation-tests" id="toc-run-the-model-evaluation-tests" class="nav-link" data-scroll-target="#run-the-model-evaluation-tests">Run the model evaluation tests</a></li>
  </ul></li>
  <li><a href="#implementing-custom-tests" id="toc-implementing-custom-tests" class="nav-link" data-scroll-target="#implementing-custom-tests">3. Implementing custom tests</a>
  <ul class="collapse">
  <li><a href="#create-a-confusion-matrix-plot" id="toc-create-a-confusion-matrix-plot" class="nav-link" data-scroll-target="#create-a-confusion-matrix-plot">Create a confusion matrix plot</a></li>
  <li><a href="#add-parameters-to-custom-tests" id="toc-add-parameters-to-custom-tests" class="nav-link" data-scroll-target="#add-parameters-to-custom-tests">Add parameters to custom tests</a></li>
  <li><a href="#pass-parameters-to-custom-tests" id="toc-pass-parameters-to-custom-tests" class="nav-link" data-scroll-target="#pass-parameters-to-custom-tests">Pass parameters to custom tests</a></li>
  <li><a href="#log-the-confusion-matrix-results" id="toc-log-the-confusion-matrix-results" class="nav-link" data-scroll-target="#log-the-confusion-matrix-results">Log the confusion matrix results</a></li>
  <li><a href="#using-external-test-providers" id="toc-using-external-test-providers" class="nav-link" data-scroll-target="#using-external-test-providers">Using external test providers</a></li>
  <li><a href="#initializing-a-local-test-provider" id="toc-initializing-a-local-test-provider" class="nav-link" data-scroll-target="#initializing-a-local-test-provider">Initializing a local test provider</a></li>
  </ul></li>
  <li><a href="#finalize-testing-and-documentation" id="toc-finalize-testing-and-documentation" class="nav-link" data-scroll-target="#finalize-testing-and-documentation">4. Finalize testing and documentation</a>
  <ul class="collapse">
  <li><a href="#use-run_documentation_tests-to-ensure-custom-test-results-are-included-in-your-documentation" id="toc-use-run_documentation_tests-to-ensure-custom-test-results-are-included-in-your-documentation" class="nav-link" data-scroll-target="#use-run_documentation_tests-to-ensure-custom-test-results-are-included-in-your-documentation">Use <code>run_documentation_tests()</code> to ensure custom test results are included in your documentation</a></li>
  <li><a href="#viewing-and-updating-the-configuration-for-the-entire-model-documentation-template" id="toc-viewing-and-updating-the-configuration-for-the-entire-model-documentation-template" class="nav-link" data-scroll-target="#viewing-and-updating-the-configuration-for-the-entire-model-documentation-template">Viewing and updating the configuration for the entire model documentation template</a></li>
  </ul></li>
  <li><a href="#where-to-go-from-here" id="toc-where-to-go-from-here" class="nav-link" data-scroll-target="#where-to-go-from-here">Where to go from here</a>
  <ul class="collapse">
  <li><a href="#use-cases" id="toc-use-cases" class="nav-link" data-scroll-target="#use-cases">Use cases</a></li>
  <li><a href="#more-how-to-guides-and-code-samples" id="toc-more-how-to-guides-and-code-samples" class="nav-link" data-scroll-target="#more-how-to-guides-and-code-samples">More how-to guides and code samples</a></li>
  <li><a href="#discover-more-learning-resources" id="toc-discover-more-learning-resources" class="nav-link" data-scroll-target="#discover-more-learning-resources">Discover more learning resources</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/validmind/documentation/blob/main/site/notebooks/tutorials/intro_for_model_developers_EXECUTED.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/validmind/documentation/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">ValidMind Introduction for Model Developers</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>As a model developer, learn how the end-to-end documentation process works based on common scenarios you encounter in model development settings.</p>
<p>As a prerequisite, a model documentation template must be available on the platform. You can <a href="https://docs.validmind.com/guide/swap-documentation-templates.html#view-current-templates">view the available templates</a> to see what has been defined on the platform.</p>
<p>This notebook uses a binary classification model as an example, but the same principles shown here apply to other model types.</p>
<p><a id="toc1_"></a></p>
<section id="overview-of-the-notebook" class="level2">
<h2 class="anchored" data-anchor-id="overview-of-the-notebook">Overview of the notebook</h2>
<p><strong>1. Initializing the ValidMind Developer Framework</strong></p>
<p>ValidMind’s developer framework provides a rich collection of documentation tools and test suites, from documenting descriptions of datasets to validation and testing of models using a variety of open-source testing frameworks.</p>
<p><strong>2. Start the model development process with raw data, run out-of-the box tests, and add evidence to model documentation</strong></p>
<p>Learn how to access ValidMind’s test repository of individual tests that you will use as building blocks to ensure a model is being built appropriately. The goal is to show how to run tests, investigate results, and add tests results or evidence to the documentation.</p>
<p>For a full list of out-of-the-box tests, see <a href="https://docs.validmind.com/guide/test-descriptions.html">Test descriptions</a> or try the interactive <a href="https://docs.validmind.com/guide/test-sandbox.html">Test sandbox</a>.</p>
<p><strong>3. Implementing custom tests</strong></p>
<p>Usually, model developers have their own custom tests and it is important to include this within the model documentation. We will show you how to include custom tests and then how they can be added to documentation as additional evidence.</p>
<p><strong>4. Finalize testing and documentation</strong></p>
<p>Learn how you can ensure that model documentation includes custom tests and how to make test configuration changes that apply to all tests in the model documentation template. At the end of this section you should have a fully documented model ready for review.</p>
</section>
<section id="contents" class="level2">
<h2 class="anchored" data-anchor-id="contents">Contents</h2>
<ul>
<li><a href="#toc1_">Overview of the notebook</a></li>
<li><a href="#toc2_">About ValidMind</a>
<ul>
<li><a href="#toc2_1_">Before you begin</a></li>
<li><a href="#toc2_2_">New to ValidMind?</a></li>
<li><a href="#toc2_3_">Key concepts</a></li>
</ul></li>
<li><a href="#toc4_">1. Initializing the ValidMind Developer Framework</a>
<ul>
<li><a href="#toc4_1_">Install the client library</a></li>
<li><a href="#toc4_2_">Register a new model in ValidMind UI and initialize the client library</a></li>
<li><a href="#toc4_3_">Verify &amp; preview the documentation template</a></li>
</ul></li>
<li><a href="#toc5_">2. Start the model development process with raw data, run out-of-the box tests, and add evidence to model documentation</a>
<ul>
<li><a href="#toc5_1_">Initialize the ValidMind datasets</a></li>
<li><a href="#toc5_2_">Run some tabular data tests</a></li>
<li><a href="#toc5_3_">Utilize test output</a></li>
<li><a href="#toc5_4_">Documenting the results based on two datasets</a>
<ul>
<li><a href="#toc5_4_1_">Run <code>run_documentation_tests()</code> using <code>vm_raw_dataset_preprocessed</code> as input</a></li>
<li><a href="#toc5_4_2_">Log the individual result of the high correlation test that used <code>vm_balanced_raw_dataset</code> (that had a highly correlated <code>Age</code> column) as input</a></li>
</ul></li>
<li><a href="#toc5_5_">Add individual test results to model documentation</a></li>
<li><a href="#toc5_6_">Model Testing</a></li>
<li><a href="#toc5_7_">Initialize model evaluation objects and assigning predictions</a></li>
<li><a href="#toc5_8_">Run the model evaluation tests</a></li>
</ul></li>
<li><a href="#toc6_">3. Implementing custom tests</a>
<ul>
<li><a href="#toc6_1_">Create a confusion matrix plot</a></li>
<li><a href="#toc6_2_">Add parameters to custom tests</a></li>
<li><a href="#toc6_3_">Pass parameters to custom tests</a></li>
<li><a href="#toc6_4_">Log the confusion matrix results</a></li>
<li><a href="#toc6_5_">Using external test providers</a>
<ul>
<li><a href="#toc6_5_1_">Create a folder of custom tests from existing inline tests</a></li>
<li><a href="#toc6_5_2_">Save an inline test to a file</a></li>
<li><a href="#toc6_5_3_">Define and register a <code>LocalTestProvider</code> that points to that folder</a></li>
</ul></li>
<li><a href="#toc6_6_">Initializing a local test provider</a>
<ul>
<li><a href="#toc6_6_1_">Run test provider tests</a></li>
<li><a href="#toc6_6_2_">Add the test results to your documentation</a></li>
</ul></li>
</ul></li>
<li><a href="#toc7_">4. Finalize testing and documentation</a>
<ul>
<li><a href="#toc7_1_">Use <code>run_documentation_tests()</code> to ensure custom test results are included in your documentation</a></li>
<li><a href="#toc7_2_">Viewing and updating the configuration for the entire model documentation template</a>
<ul>
<li><a href="#toc7_2_1_">Update the config</a></li>
</ul></li>
</ul></li>
<li><a href="#toc8_">Where to go from here</a>
<ul>
<li><a href="#toc8_1_">Use cases</a></li>
<li><a href="#toc8_2_">More how-to guides and code samples</a></li>
<li><a href="#toc8_3_">Discover more learning resources</a></li>
</ul></li>
</ul>
<!-- vscode-jupyter-toc-config
    numbering=false
    anchor=true
    flat=false
    minLevel=2
    maxLevel=4
    /vscode-jupyter-toc-config -->
<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->
<p><a id="toc2_"></a></p>
</section>
<section id="about-validmind" class="level2">
<h2 class="anchored" data-anchor-id="about-validmind">About ValidMind</h2>
<p>ValidMind is a platform for managing model risk, including risk associated with AI and statistical models. You use the ValidMind Developer Framework to automate documentation and validation tests, and then use the ValidMind AI Risk Platform UI to collaborate on model documentation. Together, these products simplify model risk management, facilitate compliance with regulations and institutional standards, and enhance collaboration between yourself and model validators.</p>
<p><a id="toc2_1_"></a></p>
<section id="before-you-begin" class="level3">
<h3 class="anchored" data-anchor-id="before-you-begin">Before you begin</h3>
<p>This notebook assumes you have basic familiarity with Python, including an understanding of how functions work. If you are new to Python, you can still run the notebook but we recommend further familiarizing yourself with the language.</p>
<p>If you encounter errors due to missing modules in your Python environment, install the modules with <code>pip install</code>, and then re-run the notebook. For more help, refer to <a href="https://docs.python.org/3/installing/index.html">Installing Python Modules</a>.</p>
<p><a id="toc2_2_"></a></p>
</section>
<section id="new-to-validmind" class="level3">
<h3 class="anchored" data-anchor-id="new-to-validmind">New to ValidMind?</h3>
<p>If you haven’t already seen our <a href="https://docs.validmind.ai/guide/get-started-developer-framework.html">Get started with the ValidMind Developer Framework</a>, we recommend you explore the available resources for developers at some point. There, you can learn more about documenting models, find code samples, or read our developer reference.</p>
<div class="alert alert-block alert-info" style="background-color: #f7e4ee; color: #222425; border: 1px solid #222425;">
<p>For access to all features available in this notebook, create a free ValidMind account.</p>
Signing up is FREE — <a href="https://app.prod.validmind.ai"><b>Sign up now</b></a>
</div>
<p><a id="toc2_3_"></a></p>
</section>
<section id="key-concepts" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts">Key concepts</h3>
<p><strong>Model documentation</strong>: A structured and detailed record pertaining to a model, encompassing key components such as its underlying assumptions, methodologies, data sources, inputs, performance metrics, evaluations, limitations, and intended uses. It serves to ensure transparency, adherence to regulatory requirements, and a clear understanding of potential risks associated with the model’s application.</p>
<p><strong>Documentation template</strong>: Functions as a test suite and lays out the structure of model documentation, segmented into various sections and sub-sections. Documentation templates define the structure of your model documentation, specifying the tests that should be run, and how the results should be displayed.</p>
<p><strong>Tests</strong>: A function contained in the ValidMind Developer Framework, designed to run a specific quantitative test on the dataset or model. Tests are the building blocks of ValidMind, used to evaluate and document models and datasets, and can be run individually or as part of a suite defined by your model documentation template.</p>
<p><strong>Custom tests</strong>: Custom tests are functions that you define to evaluate your model or dataset. These functions can be registered with ValidMind to be used in the platform.</p>
<p><strong>Inputs</strong>: Objects to be evaluated and documented in the ValidMind framework. They can be any of the following:</p>
<ul>
<li><strong>model</strong>: A single model that has been initialized in ValidMind with <a href="https://docs.validmind.ai/validmind/validmind.html#init_model"><code>vm.init_model()</code></a>.</li>
<li><strong>dataset</strong>: Single dataset that has been initialized in ValidMind with <a href="https://docs.validmind.ai/validmind/validmind.html#init_dataset"><code>vm.init_dataset()</code></a>.</li>
<li><strong>models</strong>: A list of ValidMind models - usually this is used when you want to compare multiple models in your custom test.</li>
<li><strong>datasets</strong>: A list of ValidMind datasets - usually this is used when you want to compare multiple datasets in your custom test. See this <a href="https://docs.validmind.ai/notebooks/how_to/run_tests_that_require_multiple_datasets.html">example</a> for more information.</li>
</ul>
<p><strong>Parameters</strong>: Additional arguments that can be passed when running a ValidMind test, used to pass additional information to a test, customize its behavior, or provide additional context.</p>
<p><strong>Outputs</strong>: Custom tests can return elements like tables or plots. Tables may be a list of dictionaries (each representing a row) or a pandas DataFrame. Plots may be matplotlib or plotly figures.</p>
<p><strong>Test suites</strong>: Collections of tests designed to run together to automate and generate model documentation end-to-end for specific use-cases.</p>
<p>Example: the <a href="https://docs.validmind.ai/validmind/validmind/test_suites/classifier.html#ClassifierFullSuite"><code>classifier_full_suite</code></a> test suite runs tests from the <a href="https://docs.validmind.ai/validmind/validmind/test_suites/tabular_datasets.html"><code>tabular_dataset</code></a> and <a href="https://docs.validmind.ai/validmind/validmind/test_suites/classifier.html"><code>classifier</code></a> test suites to fully document the data and model sections for binary classification model use-cases.</p>
<p><a id="toc4_"></a></p>
</section>
</section>
<section id="initializing-the-validmind-developer-framework" class="level2">
<h2 class="anchored" data-anchor-id="initializing-the-validmind-developer-framework">1. Initializing the ValidMind Developer Framework</h2>
<p><a id="toc4_1_"></a></p>
<section id="install-the-client-library" class="level3">
<h3 class="anchored" data-anchor-id="install-the-client-library">Install the client library</h3>
<p>Please note the following recommended Python versions to use:</p>
<ul>
<li>Python 3.7 &gt; x &lt;= 3.11</li>
</ul>
<p>The client library provides Python support for the ValidMind Developer Framework. To install it run:</p>
<div id="cell-6" class="cell" data-metadata="{}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">-</span>q validmind</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>WARNING: visions 0.7.5 does not provide the extra 'type-image-path'
Note: you may need to restart the kernel to use updated packages.</code></pre>
</div>
</div>
<p><a id="toc4_2_"></a></p>
</section>
<section id="register-a-new-model-in-validmind-ui-and-initialize-the-client-library" class="level3">
<h3 class="anchored" data-anchor-id="register-a-new-model-in-validmind-ui-and-initialize-the-client-library">Register a new model in ValidMind UI and initialize the client library</h3>
<p>ValidMind generates a unique <em>code snippet</em> for each registered model to connect with your developer environment. You initialize the client library with this code snippet, which ensures that your documentation and tests are uploaded to the correct model when you run the notebook.</p>
<p>Get your code snippet:</p>
<ol type="1">
<li><p>In a browser, log into the <a href="https://app.prod.validmind.ai">Platform UI</a>.</p></li>
<li><p>In the left sidebar, navigate to <strong>Model Inventory</strong> and click <strong>+ Register new model</strong>.</p></li>
<li><p>Enter the model details and click <strong>Continue</strong>. (<a href="https://docs.validmind.ai/guide/register-models-in-model-inventory.html">Need more help?</a>)</p>
<p>For example, to register a model for use with this notebook, select:</p>
<ul>
<li>Documentation template: <code>Binary classification</code></li>
<li>Use case: <code>Marketing/Sales - Attrition/Churn Management</code></li>
</ul>
<p>You can fill in other options according to your preference.</p></li>
<li><p>Go to <strong>Getting Started</strong> and click <strong>Copy snippet to clipboard</strong>.</p></li>
</ol>
<p>Next, replace this placeholder with your own code snippet:</p>
<div id="cell-8" class="cell" data-metadata="{}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace with your code snippet</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> validmind <span class="im">as</span> vm</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>vm.init(</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    api_host<span class="op">=</span><span class="st">"https://api.prod.validmind.ai/api/v1/tracking"</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    api_key<span class="op">=</span><span class="st">"..."</span>,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    api_secret<span class="op">=</span><span class="st">"..."</span>,</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    project<span class="op">=</span><span class="st">"..."</span>,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-06-12 16:27:23,250 - INFO(validmind.api_client): Connected to ValidMind. Project: [Training] ValidMind Introduction for Model Developers - Initial Validation (clxcdxmru02ts29ifnnrg6k4j)</code></pre>
</div>
</div>
<p><a id="toc4_3_"></a></p>
</section>
<section id="verify-preview-the-documentation-template" class="level3">
<h3 class="anchored" data-anchor-id="verify-preview-the-documentation-template">Verify &amp; preview the documentation template</h3>
<p>Let’s verify that you have connected to ValidMind and that the appropriate template is selected. A template predefines sections for your model documentation and provides a general outline to follow, making the documentation process much easier.</p>
<p>You will upload documentation and test results for this template later on. For now, take a look at the structure that the template provides with the <code>vm.preview_template()</code> function from the ValidMind library and note the empty sections:</p>
<div id="cell-10" class="cell" data-metadata="{}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>vm.preview_template()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d07f825d75cc4edc956dad5f45161fec","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p>Before learning how to run tests, let’s explore the list of all available tests in the ValidMind Developer Framework. You can see that the documentation template for this model has references to some of the test IDs listed below.</p>
<div id="cell-12" class="cell" data-metadata="{}" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>vm.tests.list_tests()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<style type="text/css">
#T_0a3cb th {
  text-align: left;
}
#T_0a3cb_row0_col0, #T_0a3cb_row0_col1, #T_0a3cb_row0_col2, #T_0a3cb_row0_col3, #T_0a3cb_row0_col4, #T_0a3cb_row1_col0, #T_0a3cb_row1_col1, #T_0a3cb_row1_col2, #T_0a3cb_row1_col3, #T_0a3cb_row1_col4, #T_0a3cb_row2_col0, #T_0a3cb_row2_col1, #T_0a3cb_row2_col2, #T_0a3cb_row2_col3, #T_0a3cb_row2_col4, #T_0a3cb_row3_col0, #T_0a3cb_row3_col1, #T_0a3cb_row3_col2, #T_0a3cb_row3_col3, #T_0a3cb_row3_col4, #T_0a3cb_row4_col0, #T_0a3cb_row4_col1, #T_0a3cb_row4_col2, #T_0a3cb_row4_col3, #T_0a3cb_row4_col4, #T_0a3cb_row5_col0, #T_0a3cb_row5_col1, #T_0a3cb_row5_col2, #T_0a3cb_row5_col3, #T_0a3cb_row5_col4, #T_0a3cb_row6_col0, #T_0a3cb_row6_col1, #T_0a3cb_row6_col2, #T_0a3cb_row6_col3, #T_0a3cb_row6_col4, #T_0a3cb_row7_col0, #T_0a3cb_row7_col1, #T_0a3cb_row7_col2, #T_0a3cb_row7_col3, #T_0a3cb_row7_col4, #T_0a3cb_row8_col0, #T_0a3cb_row8_col1, #T_0a3cb_row8_col2, #T_0a3cb_row8_col3, #T_0a3cb_row8_col4, #T_0a3cb_row9_col0, #T_0a3cb_row9_col1, #T_0a3cb_row9_col2, #T_0a3cb_row9_col3, #T_0a3cb_row9_col4, #T_0a3cb_row10_col0, #T_0a3cb_row10_col1, #T_0a3cb_row10_col2, #T_0a3cb_row10_col3, #T_0a3cb_row10_col4, #T_0a3cb_row11_col0, #T_0a3cb_row11_col1, #T_0a3cb_row11_col2, #T_0a3cb_row11_col3, #T_0a3cb_row11_col4, #T_0a3cb_row12_col0, #T_0a3cb_row12_col1, #T_0a3cb_row12_col2, #T_0a3cb_row12_col3, #T_0a3cb_row12_col4, #T_0a3cb_row13_col0, #T_0a3cb_row13_col1, #T_0a3cb_row13_col2, #T_0a3cb_row13_col3, #T_0a3cb_row13_col4, #T_0a3cb_row14_col0, #T_0a3cb_row14_col1, #T_0a3cb_row14_col2, #T_0a3cb_row14_col3, #T_0a3cb_row14_col4, #T_0a3cb_row15_col0, #T_0a3cb_row15_col1, #T_0a3cb_row15_col2, #T_0a3cb_row15_col3, #T_0a3cb_row15_col4, #T_0a3cb_row16_col0, #T_0a3cb_row16_col1, #T_0a3cb_row16_col2, #T_0a3cb_row16_col3, #T_0a3cb_row16_col4, #T_0a3cb_row17_col0, #T_0a3cb_row17_col1, #T_0a3cb_row17_col2, #T_0a3cb_row17_col3, #T_0a3cb_row17_col4, #T_0a3cb_row18_col0, #T_0a3cb_row18_col1, #T_0a3cb_row18_col2, #T_0a3cb_row18_col3, #T_0a3cb_row18_col4, #T_0a3cb_row19_col0, #T_0a3cb_row19_col1, #T_0a3cb_row19_col2, #T_0a3cb_row19_col3, #T_0a3cb_row19_col4, #T_0a3cb_row20_col0, #T_0a3cb_row20_col1, #T_0a3cb_row20_col2, #T_0a3cb_row20_col3, #T_0a3cb_row20_col4, #T_0a3cb_row21_col0, #T_0a3cb_row21_col1, #T_0a3cb_row21_col2, #T_0a3cb_row21_col3, #T_0a3cb_row21_col4, #T_0a3cb_row22_col0, #T_0a3cb_row22_col1, #T_0a3cb_row22_col2, #T_0a3cb_row22_col3, #T_0a3cb_row22_col4, #T_0a3cb_row23_col0, #T_0a3cb_row23_col1, #T_0a3cb_row23_col2, #T_0a3cb_row23_col3, #T_0a3cb_row23_col4, #T_0a3cb_row24_col0, #T_0a3cb_row24_col1, #T_0a3cb_row24_col2, #T_0a3cb_row24_col3, #T_0a3cb_row24_col4, #T_0a3cb_row25_col0, #T_0a3cb_row25_col1, #T_0a3cb_row25_col2, #T_0a3cb_row25_col3, #T_0a3cb_row25_col4, #T_0a3cb_row26_col0, #T_0a3cb_row26_col1, #T_0a3cb_row26_col2, #T_0a3cb_row26_col3, #T_0a3cb_row26_col4, #T_0a3cb_row27_col0, #T_0a3cb_row27_col1, #T_0a3cb_row27_col2, #T_0a3cb_row27_col3, #T_0a3cb_row27_col4, #T_0a3cb_row28_col0, #T_0a3cb_row28_col1, #T_0a3cb_row28_col2, #T_0a3cb_row28_col3, #T_0a3cb_row28_col4, #T_0a3cb_row29_col0, #T_0a3cb_row29_col1, #T_0a3cb_row29_col2, #T_0a3cb_row29_col3, #T_0a3cb_row29_col4, #T_0a3cb_row30_col0, #T_0a3cb_row30_col1, #T_0a3cb_row30_col2, #T_0a3cb_row30_col3, #T_0a3cb_row30_col4, #T_0a3cb_row31_col0, #T_0a3cb_row31_col1, #T_0a3cb_row31_col2, #T_0a3cb_row31_col3, #T_0a3cb_row31_col4, #T_0a3cb_row32_col0, #T_0a3cb_row32_col1, #T_0a3cb_row32_col2, #T_0a3cb_row32_col3, #T_0a3cb_row32_col4, #T_0a3cb_row33_col0, #T_0a3cb_row33_col1, #T_0a3cb_row33_col2, #T_0a3cb_row33_col3, #T_0a3cb_row33_col4, #T_0a3cb_row34_col0, #T_0a3cb_row34_col1, #T_0a3cb_row34_col2, #T_0a3cb_row34_col3, #T_0a3cb_row34_col4, #T_0a3cb_row35_col0, #T_0a3cb_row35_col1, #T_0a3cb_row35_col2, #T_0a3cb_row35_col3, #T_0a3cb_row35_col4, #T_0a3cb_row36_col0, #T_0a3cb_row36_col1, #T_0a3cb_row36_col2, #T_0a3cb_row36_col3, #T_0a3cb_row36_col4, #T_0a3cb_row37_col0, #T_0a3cb_row37_col1, #T_0a3cb_row37_col2, #T_0a3cb_row37_col3, #T_0a3cb_row37_col4, #T_0a3cb_row38_col0, #T_0a3cb_row38_col1, #T_0a3cb_row38_col2, #T_0a3cb_row38_col3, #T_0a3cb_row38_col4, #T_0a3cb_row39_col0, #T_0a3cb_row39_col1, #T_0a3cb_row39_col2, #T_0a3cb_row39_col3, #T_0a3cb_row39_col4, #T_0a3cb_row40_col0, #T_0a3cb_row40_col1, #T_0a3cb_row40_col2, #T_0a3cb_row40_col3, #T_0a3cb_row40_col4, #T_0a3cb_row41_col0, #T_0a3cb_row41_col1, #T_0a3cb_row41_col2, #T_0a3cb_row41_col3, #T_0a3cb_row41_col4, #T_0a3cb_row42_col0, #T_0a3cb_row42_col1, #T_0a3cb_row42_col2, #T_0a3cb_row42_col3, #T_0a3cb_row42_col4, #T_0a3cb_row43_col0, #T_0a3cb_row43_col1, #T_0a3cb_row43_col2, #T_0a3cb_row43_col3, #T_0a3cb_row43_col4, #T_0a3cb_row44_col0, #T_0a3cb_row44_col1, #T_0a3cb_row44_col2, #T_0a3cb_row44_col3, #T_0a3cb_row44_col4, #T_0a3cb_row45_col0, #T_0a3cb_row45_col1, #T_0a3cb_row45_col2, #T_0a3cb_row45_col3, #T_0a3cb_row45_col4, #T_0a3cb_row46_col0, #T_0a3cb_row46_col1, #T_0a3cb_row46_col2, #T_0a3cb_row46_col3, #T_0a3cb_row46_col4, #T_0a3cb_row47_col0, #T_0a3cb_row47_col1, #T_0a3cb_row47_col2, #T_0a3cb_row47_col3, #T_0a3cb_row47_col4, #T_0a3cb_row48_col0, #T_0a3cb_row48_col1, #T_0a3cb_row48_col2, #T_0a3cb_row48_col3, #T_0a3cb_row48_col4, #T_0a3cb_row49_col0, #T_0a3cb_row49_col1, #T_0a3cb_row49_col2, #T_0a3cb_row49_col3, #T_0a3cb_row49_col4, #T_0a3cb_row50_col0, #T_0a3cb_row50_col1, #T_0a3cb_row50_col2, #T_0a3cb_row50_col3, #T_0a3cb_row50_col4, #T_0a3cb_row51_col0, #T_0a3cb_row51_col1, #T_0a3cb_row51_col2, #T_0a3cb_row51_col3, #T_0a3cb_row51_col4, #T_0a3cb_row52_col0, #T_0a3cb_row52_col1, #T_0a3cb_row52_col2, #T_0a3cb_row52_col3, #T_0a3cb_row52_col4, #T_0a3cb_row53_col0, #T_0a3cb_row53_col1, #T_0a3cb_row53_col2, #T_0a3cb_row53_col3, #T_0a3cb_row53_col4, #T_0a3cb_row54_col0, #T_0a3cb_row54_col1, #T_0a3cb_row54_col2, #T_0a3cb_row54_col3, #T_0a3cb_row54_col4, #T_0a3cb_row55_col0, #T_0a3cb_row55_col1, #T_0a3cb_row55_col2, #T_0a3cb_row55_col3, #T_0a3cb_row55_col4, #T_0a3cb_row56_col0, #T_0a3cb_row56_col1, #T_0a3cb_row56_col2, #T_0a3cb_row56_col3, #T_0a3cb_row56_col4, #T_0a3cb_row57_col0, #T_0a3cb_row57_col1, #T_0a3cb_row57_col2, #T_0a3cb_row57_col3, #T_0a3cb_row57_col4, #T_0a3cb_row58_col0, #T_0a3cb_row58_col1, #T_0a3cb_row58_col2, #T_0a3cb_row58_col3, #T_0a3cb_row58_col4, #T_0a3cb_row59_col0, #T_0a3cb_row59_col1, #T_0a3cb_row59_col2, #T_0a3cb_row59_col3, #T_0a3cb_row59_col4, #T_0a3cb_row60_col0, #T_0a3cb_row60_col1, #T_0a3cb_row60_col2, #T_0a3cb_row60_col3, #T_0a3cb_row60_col4, #T_0a3cb_row61_col0, #T_0a3cb_row61_col1, #T_0a3cb_row61_col2, #T_0a3cb_row61_col3, #T_0a3cb_row61_col4, #T_0a3cb_row62_col0, #T_0a3cb_row62_col1, #T_0a3cb_row62_col2, #T_0a3cb_row62_col3, #T_0a3cb_row62_col4, #T_0a3cb_row63_col0, #T_0a3cb_row63_col1, #T_0a3cb_row63_col2, #T_0a3cb_row63_col3, #T_0a3cb_row63_col4, #T_0a3cb_row64_col0, #T_0a3cb_row64_col1, #T_0a3cb_row64_col2, #T_0a3cb_row64_col3, #T_0a3cb_row64_col4, #T_0a3cb_row65_col0, #T_0a3cb_row65_col1, #T_0a3cb_row65_col2, #T_0a3cb_row65_col3, #T_0a3cb_row65_col4, #T_0a3cb_row66_col0, #T_0a3cb_row66_col1, #T_0a3cb_row66_col2, #T_0a3cb_row66_col3, #T_0a3cb_row66_col4, #T_0a3cb_row67_col0, #T_0a3cb_row67_col1, #T_0a3cb_row67_col2, #T_0a3cb_row67_col3, #T_0a3cb_row67_col4, #T_0a3cb_row68_col0, #T_0a3cb_row68_col1, #T_0a3cb_row68_col2, #T_0a3cb_row68_col3, #T_0a3cb_row68_col4, #T_0a3cb_row69_col0, #T_0a3cb_row69_col1, #T_0a3cb_row69_col2, #T_0a3cb_row69_col3, #T_0a3cb_row69_col4, #T_0a3cb_row70_col0, #T_0a3cb_row70_col1, #T_0a3cb_row70_col2, #T_0a3cb_row70_col3, #T_0a3cb_row70_col4, #T_0a3cb_row71_col0, #T_0a3cb_row71_col1, #T_0a3cb_row71_col2, #T_0a3cb_row71_col3, #T_0a3cb_row71_col4, #T_0a3cb_row72_col0, #T_0a3cb_row72_col1, #T_0a3cb_row72_col2, #T_0a3cb_row72_col3, #T_0a3cb_row72_col4, #T_0a3cb_row73_col0, #T_0a3cb_row73_col1, #T_0a3cb_row73_col2, #T_0a3cb_row73_col3, #T_0a3cb_row73_col4, #T_0a3cb_row74_col0, #T_0a3cb_row74_col1, #T_0a3cb_row74_col2, #T_0a3cb_row74_col3, #T_0a3cb_row74_col4, #T_0a3cb_row75_col0, #T_0a3cb_row75_col1, #T_0a3cb_row75_col2, #T_0a3cb_row75_col3, #T_0a3cb_row75_col4, #T_0a3cb_row76_col0, #T_0a3cb_row76_col1, #T_0a3cb_row76_col2, #T_0a3cb_row76_col3, #T_0a3cb_row76_col4, #T_0a3cb_row77_col0, #T_0a3cb_row77_col1, #T_0a3cb_row77_col2, #T_0a3cb_row77_col3, #T_0a3cb_row77_col4, #T_0a3cb_row78_col0, #T_0a3cb_row78_col1, #T_0a3cb_row78_col2, #T_0a3cb_row78_col3, #T_0a3cb_row78_col4, #T_0a3cb_row79_col0, #T_0a3cb_row79_col1, #T_0a3cb_row79_col2, #T_0a3cb_row79_col3, #T_0a3cb_row79_col4, #T_0a3cb_row80_col0, #T_0a3cb_row80_col1, #T_0a3cb_row80_col2, #T_0a3cb_row80_col3, #T_0a3cb_row80_col4, #T_0a3cb_row81_col0, #T_0a3cb_row81_col1, #T_0a3cb_row81_col2, #T_0a3cb_row81_col3, #T_0a3cb_row81_col4, #T_0a3cb_row82_col0, #T_0a3cb_row82_col1, #T_0a3cb_row82_col2, #T_0a3cb_row82_col3, #T_0a3cb_row82_col4, #T_0a3cb_row83_col0, #T_0a3cb_row83_col1, #T_0a3cb_row83_col2, #T_0a3cb_row83_col3, #T_0a3cb_row83_col4, #T_0a3cb_row84_col0, #T_0a3cb_row84_col1, #T_0a3cb_row84_col2, #T_0a3cb_row84_col3, #T_0a3cb_row84_col4, #T_0a3cb_row85_col0, #T_0a3cb_row85_col1, #T_0a3cb_row85_col2, #T_0a3cb_row85_col3, #T_0a3cb_row85_col4, #T_0a3cb_row86_col0, #T_0a3cb_row86_col1, #T_0a3cb_row86_col2, #T_0a3cb_row86_col3, #T_0a3cb_row86_col4, #T_0a3cb_row87_col0, #T_0a3cb_row87_col1, #T_0a3cb_row87_col2, #T_0a3cb_row87_col3, #T_0a3cb_row87_col4, #T_0a3cb_row88_col0, #T_0a3cb_row88_col1, #T_0a3cb_row88_col2, #T_0a3cb_row88_col3, #T_0a3cb_row88_col4, #T_0a3cb_row89_col0, #T_0a3cb_row89_col1, #T_0a3cb_row89_col2, #T_0a3cb_row89_col3, #T_0a3cb_row89_col4, #T_0a3cb_row90_col0, #T_0a3cb_row90_col1, #T_0a3cb_row90_col2, #T_0a3cb_row90_col3, #T_0a3cb_row90_col4, #T_0a3cb_row91_col0, #T_0a3cb_row91_col1, #T_0a3cb_row91_col2, #T_0a3cb_row91_col3, #T_0a3cb_row91_col4, #T_0a3cb_row92_col0, #T_0a3cb_row92_col1, #T_0a3cb_row92_col2, #T_0a3cb_row92_col3, #T_0a3cb_row92_col4, #T_0a3cb_row93_col0, #T_0a3cb_row93_col1, #T_0a3cb_row93_col2, #T_0a3cb_row93_col3, #T_0a3cb_row93_col4, #T_0a3cb_row94_col0, #T_0a3cb_row94_col1, #T_0a3cb_row94_col2, #T_0a3cb_row94_col3, #T_0a3cb_row94_col4, #T_0a3cb_row95_col0, #T_0a3cb_row95_col1, #T_0a3cb_row95_col2, #T_0a3cb_row95_col3, #T_0a3cb_row95_col4, #T_0a3cb_row96_col0, #T_0a3cb_row96_col1, #T_0a3cb_row96_col2, #T_0a3cb_row96_col3, #T_0a3cb_row96_col4, #T_0a3cb_row97_col0, #T_0a3cb_row97_col1, #T_0a3cb_row97_col2, #T_0a3cb_row97_col3, #T_0a3cb_row97_col4, #T_0a3cb_row98_col0, #T_0a3cb_row98_col1, #T_0a3cb_row98_col2, #T_0a3cb_row98_col3, #T_0a3cb_row98_col4, #T_0a3cb_row99_col0, #T_0a3cb_row99_col1, #T_0a3cb_row99_col2, #T_0a3cb_row99_col3, #T_0a3cb_row99_col4, #T_0a3cb_row100_col0, #T_0a3cb_row100_col1, #T_0a3cb_row100_col2, #T_0a3cb_row100_col3, #T_0a3cb_row100_col4, #T_0a3cb_row101_col0, #T_0a3cb_row101_col1, #T_0a3cb_row101_col2, #T_0a3cb_row101_col3, #T_0a3cb_row101_col4, #T_0a3cb_row102_col0, #T_0a3cb_row102_col1, #T_0a3cb_row102_col2, #T_0a3cb_row102_col3, #T_0a3cb_row102_col4, #T_0a3cb_row103_col0, #T_0a3cb_row103_col1, #T_0a3cb_row103_col2, #T_0a3cb_row103_col3, #T_0a3cb_row103_col4, #T_0a3cb_row104_col0, #T_0a3cb_row104_col1, #T_0a3cb_row104_col2, #T_0a3cb_row104_col3, #T_0a3cb_row104_col4, #T_0a3cb_row105_col0, #T_0a3cb_row105_col1, #T_0a3cb_row105_col2, #T_0a3cb_row105_col3, #T_0a3cb_row105_col4, #T_0a3cb_row106_col0, #T_0a3cb_row106_col1, #T_0a3cb_row106_col2, #T_0a3cb_row106_col3, #T_0a3cb_row106_col4, #T_0a3cb_row107_col0, #T_0a3cb_row107_col1, #T_0a3cb_row107_col2, #T_0a3cb_row107_col3, #T_0a3cb_row107_col4, #T_0a3cb_row108_col0, #T_0a3cb_row108_col1, #T_0a3cb_row108_col2, #T_0a3cb_row108_col3, #T_0a3cb_row108_col4, #T_0a3cb_row109_col0, #T_0a3cb_row109_col1, #T_0a3cb_row109_col2, #T_0a3cb_row109_col3, #T_0a3cb_row109_col4, #T_0a3cb_row110_col0, #T_0a3cb_row110_col1, #T_0a3cb_row110_col2, #T_0a3cb_row110_col3, #T_0a3cb_row110_col4, #T_0a3cb_row111_col0, #T_0a3cb_row111_col1, #T_0a3cb_row111_col2, #T_0a3cb_row111_col3, #T_0a3cb_row111_col4, #T_0a3cb_row112_col0, #T_0a3cb_row112_col1, #T_0a3cb_row112_col2, #T_0a3cb_row112_col3, #T_0a3cb_row112_col4, #T_0a3cb_row113_col0, #T_0a3cb_row113_col1, #T_0a3cb_row113_col2, #T_0a3cb_row113_col3, #T_0a3cb_row113_col4, #T_0a3cb_row114_col0, #T_0a3cb_row114_col1, #T_0a3cb_row114_col2, #T_0a3cb_row114_col3, #T_0a3cb_row114_col4, #T_0a3cb_row115_col0, #T_0a3cb_row115_col1, #T_0a3cb_row115_col2, #T_0a3cb_row115_col3, #T_0a3cb_row115_col4, #T_0a3cb_row116_col0, #T_0a3cb_row116_col1, #T_0a3cb_row116_col2, #T_0a3cb_row116_col3, #T_0a3cb_row116_col4, #T_0a3cb_row117_col0, #T_0a3cb_row117_col1, #T_0a3cb_row117_col2, #T_0a3cb_row117_col3, #T_0a3cb_row117_col4, #T_0a3cb_row118_col0, #T_0a3cb_row118_col1, #T_0a3cb_row118_col2, #T_0a3cb_row118_col3, #T_0a3cb_row118_col4, #T_0a3cb_row119_col0, #T_0a3cb_row119_col1, #T_0a3cb_row119_col2, #T_0a3cb_row119_col3, #T_0a3cb_row119_col4, #T_0a3cb_row120_col0, #T_0a3cb_row120_col1, #T_0a3cb_row120_col2, #T_0a3cb_row120_col3, #T_0a3cb_row120_col4, #T_0a3cb_row121_col0, #T_0a3cb_row121_col1, #T_0a3cb_row121_col2, #T_0a3cb_row121_col3, #T_0a3cb_row121_col4, #T_0a3cb_row122_col0, #T_0a3cb_row122_col1, #T_0a3cb_row122_col2, #T_0a3cb_row122_col3, #T_0a3cb_row122_col4, #T_0a3cb_row123_col0, #T_0a3cb_row123_col1, #T_0a3cb_row123_col2, #T_0a3cb_row123_col3, #T_0a3cb_row123_col4, #T_0a3cb_row124_col0, #T_0a3cb_row124_col1, #T_0a3cb_row124_col2, #T_0a3cb_row124_col3, #T_0a3cb_row124_col4, #T_0a3cb_row125_col0, #T_0a3cb_row125_col1, #T_0a3cb_row125_col2, #T_0a3cb_row125_col3, #T_0a3cb_row125_col4, #T_0a3cb_row126_col0, #T_0a3cb_row126_col1, #T_0a3cb_row126_col2, #T_0a3cb_row126_col3, #T_0a3cb_row126_col4, #T_0a3cb_row127_col0, #T_0a3cb_row127_col1, #T_0a3cb_row127_col2, #T_0a3cb_row127_col3, #T_0a3cb_row127_col4, #T_0a3cb_row128_col0, #T_0a3cb_row128_col1, #T_0a3cb_row128_col2, #T_0a3cb_row128_col3, #T_0a3cb_row128_col4, #T_0a3cb_row129_col0, #T_0a3cb_row129_col1, #T_0a3cb_row129_col2, #T_0a3cb_row129_col3, #T_0a3cb_row129_col4, #T_0a3cb_row130_col0, #T_0a3cb_row130_col1, #T_0a3cb_row130_col2, #T_0a3cb_row130_col3, #T_0a3cb_row130_col4, #T_0a3cb_row131_col0, #T_0a3cb_row131_col1, #T_0a3cb_row131_col2, #T_0a3cb_row131_col3, #T_0a3cb_row131_col4, #T_0a3cb_row132_col0, #T_0a3cb_row132_col1, #T_0a3cb_row132_col2, #T_0a3cb_row132_col3, #T_0a3cb_row132_col4, #T_0a3cb_row133_col0, #T_0a3cb_row133_col1, #T_0a3cb_row133_col2, #T_0a3cb_row133_col3, #T_0a3cb_row133_col4, #T_0a3cb_row134_col0, #T_0a3cb_row134_col1, #T_0a3cb_row134_col2, #T_0a3cb_row134_col3, #T_0a3cb_row134_col4, #T_0a3cb_row135_col0, #T_0a3cb_row135_col1, #T_0a3cb_row135_col2, #T_0a3cb_row135_col3, #T_0a3cb_row135_col4, #T_0a3cb_row136_col0, #T_0a3cb_row136_col1, #T_0a3cb_row136_col2, #T_0a3cb_row136_col3, #T_0a3cb_row136_col4, #T_0a3cb_row137_col0, #T_0a3cb_row137_col1, #T_0a3cb_row137_col2, #T_0a3cb_row137_col3, #T_0a3cb_row137_col4, #T_0a3cb_row138_col0, #T_0a3cb_row138_col1, #T_0a3cb_row138_col2, #T_0a3cb_row138_col3, #T_0a3cb_row138_col4, #T_0a3cb_row139_col0, #T_0a3cb_row139_col1, #T_0a3cb_row139_col2, #T_0a3cb_row139_col3, #T_0a3cb_row139_col4, #T_0a3cb_row140_col0, #T_0a3cb_row140_col1, #T_0a3cb_row140_col2, #T_0a3cb_row140_col3, #T_0a3cb_row140_col4, #T_0a3cb_row141_col0, #T_0a3cb_row141_col1, #T_0a3cb_row141_col2, #T_0a3cb_row141_col3, #T_0a3cb_row141_col4, #T_0a3cb_row142_col0, #T_0a3cb_row142_col1, #T_0a3cb_row142_col2, #T_0a3cb_row142_col3, #T_0a3cb_row142_col4, #T_0a3cb_row143_col0, #T_0a3cb_row143_col1, #T_0a3cb_row143_col2, #T_0a3cb_row143_col3, #T_0a3cb_row143_col4, #T_0a3cb_row144_col0, #T_0a3cb_row144_col1, #T_0a3cb_row144_col2, #T_0a3cb_row144_col3, #T_0a3cb_row144_col4, #T_0a3cb_row145_col0, #T_0a3cb_row145_col1, #T_0a3cb_row145_col2, #T_0a3cb_row145_col3, #T_0a3cb_row145_col4, #T_0a3cb_row146_col0, #T_0a3cb_row146_col1, #T_0a3cb_row146_col2, #T_0a3cb_row146_col3, #T_0a3cb_row146_col4, #T_0a3cb_row147_col0, #T_0a3cb_row147_col1, #T_0a3cb_row147_col2, #T_0a3cb_row147_col3, #T_0a3cb_row147_col4, #T_0a3cb_row148_col0, #T_0a3cb_row148_col1, #T_0a3cb_row148_col2, #T_0a3cb_row148_col3, #T_0a3cb_row148_col4, #T_0a3cb_row149_col0, #T_0a3cb_row149_col1, #T_0a3cb_row149_col2, #T_0a3cb_row149_col3, #T_0a3cb_row149_col4, #T_0a3cb_row150_col0, #T_0a3cb_row150_col1, #T_0a3cb_row150_col2, #T_0a3cb_row150_col3, #T_0a3cb_row150_col4, #T_0a3cb_row151_col0, #T_0a3cb_row151_col1, #T_0a3cb_row151_col2, #T_0a3cb_row151_col3, #T_0a3cb_row151_col4, #T_0a3cb_row152_col0, #T_0a3cb_row152_col1, #T_0a3cb_row152_col2, #T_0a3cb_row152_col3, #T_0a3cb_row152_col4, #T_0a3cb_row153_col0, #T_0a3cb_row153_col1, #T_0a3cb_row153_col2, #T_0a3cb_row153_col3, #T_0a3cb_row153_col4, #T_0a3cb_row154_col0, #T_0a3cb_row154_col1, #T_0a3cb_row154_col2, #T_0a3cb_row154_col3, #T_0a3cb_row154_col4, #T_0a3cb_row155_col0, #T_0a3cb_row155_col1, #T_0a3cb_row155_col2, #T_0a3cb_row155_col3, #T_0a3cb_row155_col4 {
  text-align: left;
}
</style>

<table id="T_0a3cb" class="caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th id="T_0a3cb_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">ID</th>
<th id="T_0a3cb_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">Name</th>
<th id="T_0a3cb_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">Description</th>
<th id="T_0a3cb_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">Required Inputs</th>
<th id="T_0a3cb_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">Params</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_0a3cb_row0_col0" class="data row0 col0">validmind.prompt_validation.Bias</td>
<td id="T_0a3cb_row0_col1" class="data row0 col1">Bias</td>
<td id="T_0a3cb_row0_col2" class="data row0 col2">Evaluates bias in a Large Language Model based on the order and distribution of exemplars in a prompt....</td>
<td id="T_0a3cb_row0_col3" class="data row0 col3">['model.prompt']</td>
<td id="T_0a3cb_row0_col4" class="data row0 col4">{'min_threshold': 7}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row1_col0" class="data row1 col0">validmind.prompt_validation.Clarity</td>
<td id="T_0a3cb_row1_col1" class="data row1 col1">Clarity</td>
<td id="T_0a3cb_row1_col2" class="data row1 col2">Evaluates and scores the clarity of prompts in a Large Language Model based on specified guidelines....</td>
<td id="T_0a3cb_row1_col3" class="data row1 col3">['model.prompt']</td>
<td id="T_0a3cb_row1_col4" class="data row1 col4">{'min_threshold': 7}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row2_col0" class="data row2 col0">validmind.prompt_validation.Specificity</td>
<td id="T_0a3cb_row2_col1" class="data row2 col1">Specificity</td>
<td id="T_0a3cb_row2_col2" class="data row2 col2">Evaluates and scores the specificity of prompts provided to a Large Language Model (LLM), based on clarity,...</td>
<td id="T_0a3cb_row2_col3" class="data row2 col3">['model.prompt']</td>
<td id="T_0a3cb_row2_col4" class="data row2 col4">{'min_threshold': 7}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row3_col0" class="data row3 col0">validmind.prompt_validation.Robustness</td>
<td id="T_0a3cb_row3_col1" class="data row3 col1">Robustness</td>
<td id="T_0a3cb_row3_col2" class="data row3 col2">Assesses the robustness of prompts provided to a Large Language Model under varying conditions and contexts....</td>
<td id="T_0a3cb_row3_col3" class="data row3 col3">['model']</td>
<td id="T_0a3cb_row3_col4" class="data row3 col4">{'num_tests': 10}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row4_col0" class="data row4 col0">validmind.prompt_validation.NegativeInstruction</td>
<td id="T_0a3cb_row4_col1" class="data row4 col1">Negative Instruction</td>
<td id="T_0a3cb_row4_col2" class="data row4 col2">Evaluates and grades the use of affirmative, proactive language over negative instructions in LLM prompts....</td>
<td id="T_0a3cb_row4_col3" class="data row4 col3">['model.prompt']</td>
<td id="T_0a3cb_row4_col4" class="data row4 col4">{'min_threshold': 7}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row5_col0" class="data row5 col0">validmind.prompt_validation.Conciseness</td>
<td id="T_0a3cb_row5_col1" class="data row5 col1">Conciseness</td>
<td id="T_0a3cb_row5_col2" class="data row5 col2">Analyzes and grades the conciseness of prompts provided to a Large Language Model....</td>
<td id="T_0a3cb_row5_col3" class="data row5 col3">['model.prompt']</td>
<td id="T_0a3cb_row5_col4" class="data row5 col4">{'min_threshold': 7}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row6_col0" class="data row6 col0">validmind.prompt_validation.Delimitation</td>
<td id="T_0a3cb_row6_col1" class="data row6 col1">Delimitation</td>
<td id="T_0a3cb_row6_col2" class="data row6 col2">Evaluates the proper use of delimiters in prompts provided to Large Language Models....</td>
<td id="T_0a3cb_row6_col3" class="data row6 col3">['model.prompt']</td>
<td id="T_0a3cb_row6_col4" class="data row6 col4">{'min_threshold': 7}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row7_col0" class="data row7 col0">validmind.model_validation.BertScore</td>
<td id="T_0a3cb_row7_col1" class="data row7 col1">Bert Score</td>
<td id="T_0a3cb_row7_col2" class="data row7 col2">Evaluates the quality of machine-generated text using BERTScore metrics and visualizes the results through histograms...</td>
<td id="T_0a3cb_row7_col3" class="data row7 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row7_col4" class="data row7 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row8_col0" class="data row8 col0">validmind.model_validation.RegardScore</td>
<td id="T_0a3cb_row8_col1" class="data row8 col1">Regard Score</td>
<td id="T_0a3cb_row8_col2" class="data row8 col2">Computes and visualizes the regard score for each text instance, assessing sentiment and potential biases....</td>
<td id="T_0a3cb_row8_col3" class="data row8 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row8_col4" class="data row8 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row9_col0" class="data row9 col0">validmind.model_validation.BleuScore</td>
<td id="T_0a3cb_row9_col1" class="data row9 col1">Bleu Score</td>
<td id="T_0a3cb_row9_col2" class="data row9 col2">Evaluates the quality of machine-generated text using BLEU metrics and visualizes the results through histograms...</td>
<td id="T_0a3cb_row9_col3" class="data row9 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row9_col4" class="data row9 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row10_col0" class="data row10 col0">validmind.model_validation.RegressionResidualsPlot</td>
<td id="T_0a3cb_row10_col1" class="data row10 col1">Regression Residuals Plot</td>
<td id="T_0a3cb_row10_col2" class="data row10 col2">Evaluates regression model performance using residual distribution and actual vs. predicted plots....</td>
<td id="T_0a3cb_row10_col3" class="data row10 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row10_col4" class="data row10 col4">{'bin_size': 0.1}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row11_col0" class="data row11 col0">validmind.model_validation.FeaturesAUC</td>
<td id="T_0a3cb_row11_col1" class="data row11 col1">Features AUC</td>
<td id="T_0a3cb_row11_col2" class="data row11 col2">Evaluates the discriminatory power of each individual feature within a binary classification model by calculating the Area Under the Curve (AUC) for each feature separately....</td>
<td id="T_0a3cb_row11_col3" class="data row11 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row11_col4" class="data row11 col4">{'fontsize': 12, 'figure_height': 500}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row12_col0" class="data row12 col0">validmind.model_validation.ContextualRecall</td>
<td id="T_0a3cb_row12_col1" class="data row12 col1">Contextual Recall</td>
<td id="T_0a3cb_row12_col2" class="data row12 col2">Evaluates a Natural Language Generation model's ability to generate contextually relevant and factually correct text, visualizing the results through histograms and bar charts, alongside compiling a comprehensive table of descriptive statistics for contextual recall scores....</td>
<td id="T_0a3cb_row12_col3" class="data row12 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row12_col4" class="data row12 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row13_col0" class="data row13 col0">validmind.model_validation.MeteorScore</td>
<td id="T_0a3cb_row13_col1" class="data row13 col1">Meteor Score</td>
<td id="T_0a3cb_row13_col2" class="data row13 col2">Computes and visualizes the METEOR score for each text generation instance, assessing translation quality....</td>
<td id="T_0a3cb_row13_col3" class="data row13 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row13_col4" class="data row13 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row14_col0" class="data row14 col0">validmind.model_validation.RougeScore</td>
<td id="T_0a3cb_row14_col1" class="data row14 col1">Rouge Score</td>
<td id="T_0a3cb_row14_col2" class="data row14 col2">Evaluates the quality of machine-generated text using ROUGE metrics and visualizes the results through histograms...</td>
<td id="T_0a3cb_row14_col3" class="data row14 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row14_col4" class="data row14 col4">{'metric': 'rouge-1'}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row15_col0" class="data row15 col0">validmind.model_validation.ModelMetadata</td>
<td id="T_0a3cb_row15_col1" class="data row15 col1">Model Metadata</td>
<td id="T_0a3cb_row15_col2" class="data row15 col2">Extracts and summarizes critical metadata from a machine learning model instance for comprehensive analysis....</td>
<td id="T_0a3cb_row15_col3" class="data row15 col3">['model']</td>
<td id="T_0a3cb_row15_col4" class="data row15 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row16_col0" class="data row16 col0">validmind.model_validation.ClusterSizeDistribution</td>
<td id="T_0a3cb_row16_col1" class="data row16 col1">Cluster Size Distribution</td>
<td id="T_0a3cb_row16_col2" class="data row16 col2">Compares and visualizes the distribution of cluster sizes in model predictions and actual data for assessing...</td>
<td id="T_0a3cb_row16_col3" class="data row16 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row16_col4" class="data row16 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row17_col0" class="data row17 col0">validmind.model_validation.TokenDisparity</td>
<td id="T_0a3cb_row17_col1" class="data row17 col1">Token Disparity</td>
<td id="T_0a3cb_row17_col2" class="data row17 col2">Evaluates the token disparity between reference and generated texts, visualizing the results through histograms...</td>
<td id="T_0a3cb_row17_col3" class="data row17 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row17_col4" class="data row17 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row18_col0" class="data row18 col0">validmind.model_validation.ToxicityScore</td>
<td id="T_0a3cb_row18_col1" class="data row18 col1">Toxicity Score</td>
<td id="T_0a3cb_row18_col2" class="data row18 col2">Computes and visualizes the toxicity score for input text, true text, and predicted text, assessing content quality and potential risk....</td>
<td id="T_0a3cb_row18_col3" class="data row18 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row18_col4" class="data row18 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row19_col0" class="data row19 col0">validmind.model_validation.embeddings.CosineSimilarityComparison</td>
<td id="T_0a3cb_row19_col1" class="data row19 col1">Cosine Similarity Comparison</td>
<td id="T_0a3cb_row19_col2" class="data row19 col2">Computes pairwise cosine similarities between model embeddings and visualizes the results through bar charts,...</td>
<td id="T_0a3cb_row19_col3" class="data row19 col3">['dataset', 'models']</td>
<td id="T_0a3cb_row19_col4" class="data row19 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row20_col0" class="data row20 col0">validmind.model_validation.embeddings.EmbeddingsVisualization2D</td>
<td id="T_0a3cb_row20_col1" class="data row20 col1">Embeddings Visualization2 D</td>
<td id="T_0a3cb_row20_col2" class="data row20 col2">Visualizes 2D representation of text embeddings generated by a model using t-SNE technique....</td>
<td id="T_0a3cb_row20_col3" class="data row20 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row20_col4" class="data row20 col4">{'cluster_column': None, 'perplexity': 30}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row21_col0" class="data row21 col0">validmind.model_validation.embeddings.StabilityAnalysisRandomNoise</td>
<td id="T_0a3cb_row21_col1" class="data row21 col1">Stability Analysis Random Noise</td>
<td id="T_0a3cb_row21_col2" class="data row21 col2">Evaluate robustness of embeddings models to random noise introduced by using...</td>
<td id="T_0a3cb_row21_col3" class="data row21 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row21_col4" class="data row21 col4">{'mean_similarity_threshold': 0.7, 'probability': 0.02}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row22_col0" class="data row22 col0">validmind.model_validation.embeddings.TSNEComponentsPairwisePlots</td>
<td id="T_0a3cb_row22_col1" class="data row22 col1">TSNE Components Pairwise Plots</td>
<td id="T_0a3cb_row22_col2" class="data row22 col2">Plots individual scatter plots for pairwise combinations of t-SNE components of embeddings....</td>
<td id="T_0a3cb_row22_col3" class="data row22 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row22_col4" class="data row22 col4">{'n_components': 2, 'perplexity': 30, 'title': 't-SNE'}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row23_col0" class="data row23 col0">validmind.model_validation.embeddings.CosineSimilarityDistribution</td>
<td id="T_0a3cb_row23_col1" class="data row23 col1">Cosine Similarity Distribution</td>
<td id="T_0a3cb_row23_col2" class="data row23 col2">Assesses the similarity between predicted text embeddings from a model using a Cosine Similarity distribution...</td>
<td id="T_0a3cb_row23_col3" class="data row23 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row23_col4" class="data row23 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row24_col0" class="data row24 col0">validmind.model_validation.embeddings.PCAComponentsPairwisePlots</td>
<td id="T_0a3cb_row24_col1" class="data row24 col1">PCA Components Pairwise Plots</td>
<td id="T_0a3cb_row24_col2" class="data row24 col2">Generates scatter plots for pairwise combinations of principal component analysis (PCA) components of model embeddings....</td>
<td id="T_0a3cb_row24_col3" class="data row24 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row24_col4" class="data row24 col4">{'n_components': 3}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row25_col0" class="data row25 col0">validmind.model_validation.embeddings.CosineSimilarityHeatmap</td>
<td id="T_0a3cb_row25_col1" class="data row25 col1">Cosine Similarity Heatmap</td>
<td id="T_0a3cb_row25_col2" class="data row25 col2">Generates an interactive heatmap to visualize the cosine similarities among embeddings derived from a given model....</td>
<td id="T_0a3cb_row25_col3" class="data row25 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row25_col4" class="data row25 col4">{'title': 'Cosine Similarity Matrix', 'color': 'Cosine Similarity', 'xaxis_title': 'Index', 'yaxis_title': 'Index', 'color_scale': 'Blues'}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row26_col0" class="data row26 col0">validmind.model_validation.embeddings.StabilityAnalysisTranslation</td>
<td id="T_0a3cb_row26_col1" class="data row26 col1">Stability Analysis Translation</td>
<td id="T_0a3cb_row26_col2" class="data row26 col2">Evaluate robustness of embeddings models to noise introduced by translating...</td>
<td id="T_0a3cb_row26_col3" class="data row26 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row26_col4" class="data row26 col4">{'source_lang': 'en', 'target_lang': 'fr', 'mean_similarity_threshold': 0.7}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row27_col0" class="data row27 col0">validmind.model_validation.embeddings.EuclideanDistanceComparison</td>
<td id="T_0a3cb_row27_col1" class="data row27 col1">Euclidean Distance Comparison</td>
<td id="T_0a3cb_row27_col2" class="data row27 col2">Computes pairwise Euclidean distances between model embeddings and visualizes the results through bar charts,...</td>
<td id="T_0a3cb_row27_col3" class="data row27 col3">['dataset', 'models']</td>
<td id="T_0a3cb_row27_col4" class="data row27 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row28_col0" class="data row28 col0">validmind.model_validation.embeddings.ClusterDistribution</td>
<td id="T_0a3cb_row28_col1" class="data row28 col1">Cluster Distribution</td>
<td id="T_0a3cb_row28_col2" class="data row28 col2">Assesses the distribution of text embeddings across clusters produced by a model using KMeans clustering....</td>
<td id="T_0a3cb_row28_col3" class="data row28 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row28_col4" class="data row28 col4">{'num_clusters': 5}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row29_col0" class="data row29 col0">validmind.model_validation.embeddings.EuclideanDistanceHeatmap</td>
<td id="T_0a3cb_row29_col1" class="data row29 col1">Euclidean Distance Heatmap</td>
<td id="T_0a3cb_row29_col2" class="data row29 col2">Generates an interactive heatmap to visualize the Euclidean distances among embeddings derived from a given model....</td>
<td id="T_0a3cb_row29_col3" class="data row29 col3">['dataset', 'model']</td>
<td id="T_0a3cb_row29_col4" class="data row29 col4">{'title': 'Euclidean Distance Matrix', 'color': 'Euclidean Distance', 'xaxis_title': 'Index', 'yaxis_title': 'Index', 'color_scale': 'Blues'}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row30_col0" class="data row30 col0">validmind.model_validation.embeddings.StabilityAnalysis</td>
<td id="T_0a3cb_row30_col1" class="data row30 col1">Stability Analysis</td>
<td id="T_0a3cb_row30_col2" class="data row30 col2">Base class for embeddings stability analysis tests</td>
<td id="T_0a3cb_row30_col3" class="data row30 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row30_col4" class="data row30 col4">{'mean_similarity_threshold': 0.7}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row31_col0" class="data row31 col0">validmind.model_validation.embeddings.StabilityAnalysisKeyword</td>
<td id="T_0a3cb_row31_col1" class="data row31 col1">Stability Analysis Keyword</td>
<td id="T_0a3cb_row31_col2" class="data row31 col2">Evaluate robustness of embeddings models to keyword swaps on the test dataset...</td>
<td id="T_0a3cb_row31_col3" class="data row31 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row31_col4" class="data row31 col4">{'keyword_dict': None, 'mean_similarity_threshold': 0.7}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row32_col0" class="data row32 col0">validmind.model_validation.embeddings.StabilityAnalysisSynonyms</td>
<td id="T_0a3cb_row32_col1" class="data row32 col1">Stability Analysis Synonyms</td>
<td id="T_0a3cb_row32_col2" class="data row32 col2">Evaluates the stability of text embeddings models when words in test data are replaced by their synonyms randomly....</td>
<td id="T_0a3cb_row32_col3" class="data row32 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row32_col4" class="data row32 col4">{'probability': 0.02, 'mean_similarity_threshold': 0.7}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row33_col0" class="data row33 col0">validmind.model_validation.embeddings.DescriptiveAnalytics</td>
<td id="T_0a3cb_row33_col1" class="data row33 col1">Descriptive Analytics</td>
<td id="T_0a3cb_row33_col2" class="data row33 col2">Evaluates statistical properties of text embeddings in an ML model via mean, median, and standard deviation...</td>
<td id="T_0a3cb_row33_col3" class="data row33 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row33_col4" class="data row33 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row34_col0" class="data row34 col0">validmind.model_validation.ragas.ContextEntityRecall</td>
<td id="T_0a3cb_row34_col1" class="data row34 col1">Context Entity Recall</td>
<td id="T_0a3cb_row34_col2" class="data row34 col2">Evaluates the context entity recall for dataset entries and visualizes the results....</td>
<td id="T_0a3cb_row34_col3" class="data row34 col3">['dataset']</td>
<td id="T_0a3cb_row34_col4" class="data row34 col4">{'contexts_column': 'contexts', 'ground_truth_column': 'ground_truth'}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row35_col0" class="data row35 col0">validmind.model_validation.ragas.Faithfulness</td>
<td id="T_0a3cb_row35_col1" class="data row35 col1">Faithfulness</td>
<td id="T_0a3cb_row35_col2" class="data row35 col2">Evaluates the faithfulness of the generated answers with respect to retrieved contexts....</td>
<td id="T_0a3cb_row35_col3" class="data row35 col3">['dataset']</td>
<td id="T_0a3cb_row35_col4" class="data row35 col4">{'answer_column': 'answer', 'contexts_column': 'contexts'}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row36_col0" class="data row36 col0">validmind.model_validation.ragas.AspectCritique</td>
<td id="T_0a3cb_row36_col1" class="data row36 col1">Aspect Critique</td>
<td id="T_0a3cb_row36_col2" class="data row36 col2">Evaluates generations against the following aspects: harmfulness, maliciousness,...</td>
<td id="T_0a3cb_row36_col3" class="data row36 col3">['dataset']</td>
<td id="T_0a3cb_row36_col4" class="data row36 col4">{'question_column': 'question', 'answer_column': 'answer', 'contexts_column': 'contexts', 'aspects': ['coherence', 'conciseness', 'correctness', 'harmfulness', 'maliciousness'], 'additional_aspects': None}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row37_col0" class="data row37 col0">validmind.model_validation.ragas.AnswerSimilarity</td>
<td id="T_0a3cb_row37_col1" class="data row37 col1">Answer Similarity</td>
<td id="T_0a3cb_row37_col2" class="data row37 col2">Calculates the semantic similarity between generated answers and ground truths...</td>
<td id="T_0a3cb_row37_col3" class="data row37 col3">['dataset']</td>
<td id="T_0a3cb_row37_col4" class="data row37 col4">{'answer_column': 'answer', 'ground_truth_column': 'ground_truth'}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row38_col0" class="data row38 col0">validmind.model_validation.ragas.AnswerCorrectness</td>
<td id="T_0a3cb_row38_col1" class="data row38 col1">Answer Correctness</td>
<td id="T_0a3cb_row38_col2" class="data row38 col2">Evaluates the correctness of answers in a dataset with respect to the provided ground...</td>
<td id="T_0a3cb_row38_col3" class="data row38 col3">['dataset']</td>
<td id="T_0a3cb_row38_col4" class="data row38 col4">{'question_column': 'question', 'answer_column': 'answer', 'ground_truth_column': 'ground_truth'}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row39_col0" class="data row39 col0">validmind.model_validation.ragas.ContextRecall</td>
<td id="T_0a3cb_row39_col1" class="data row39 col1">Context Recall</td>
<td id="T_0a3cb_row39_col2" class="data row39 col2">Context recall measures the extent to which the retrieved context aligns with the...</td>
<td id="T_0a3cb_row39_col3" class="data row39 col3">['dataset']</td>
<td id="T_0a3cb_row39_col4" class="data row39 col4">{'question_column': 'question', 'contexts_column': 'contexts', 'ground_truth_column': 'ground_truth'}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row40_col0" class="data row40 col0">validmind.model_validation.ragas.ContextRelevancy</td>
<td id="T_0a3cb_row40_col1" class="data row40 col1">Context Relevancy</td>
<td id="T_0a3cb_row40_col2" class="data row40 col2">Evaluates the context relevancy metric for entries in a dataset and visualizes the...</td>
<td id="T_0a3cb_row40_col3" class="data row40 col3">['dataset']</td>
<td id="T_0a3cb_row40_col4" class="data row40 col4">{'question_column': 'question', 'contexts_column': 'contexts'}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row41_col0" class="data row41 col0">validmind.model_validation.ragas.ContextPrecision</td>
<td id="T_0a3cb_row41_col1" class="data row41 col1">Context Precision</td>
<td id="T_0a3cb_row41_col2" class="data row41 col2">Context Precision is a metric that evaluates whether all of the ground-truth...</td>
<td id="T_0a3cb_row41_col3" class="data row41 col3">['dataset']</td>
<td id="T_0a3cb_row41_col4" class="data row41 col4">{'question_column': 'question', 'contexts_column': 'contexts', 'ground_truth_column': 'ground_truth'}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row42_col0" class="data row42 col0">validmind.model_validation.ragas.AnswerRelevance</td>
<td id="T_0a3cb_row42_col1" class="data row42 col1">Answer Relevance</td>
<td id="T_0a3cb_row42_col2" class="data row42 col2">Assesses how pertinent the generated answer is to the given prompt....</td>
<td id="T_0a3cb_row42_col3" class="data row42 col3">['dataset']</td>
<td id="T_0a3cb_row42_col4" class="data row42 col4">{'question_column': 'question', 'contexts_column': 'contexts', 'answer_column': 'answer'}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row43_col0" class="data row43 col0">validmind.model_validation.sklearn.RegressionModelsPerformanceComparison</td>
<td id="T_0a3cb_row43_col1" class="data row43 col1">Regression Models Performance Comparison</td>
<td id="T_0a3cb_row43_col2" class="data row43 col2">Compares and evaluates the performance of multiple regression models using five different metrics: MAE, MSE, RMSE,...</td>
<td id="T_0a3cb_row43_col3" class="data row43 col3">['dataset', 'models']</td>
<td id="T_0a3cb_row43_col4" class="data row43 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row44_col0" class="data row44 col0">validmind.model_validation.sklearn.AdjustedMutualInformation</td>
<td id="T_0a3cb_row44_col1" class="data row44 col1">Adjusted Mutual Information</td>
<td id="T_0a3cb_row44_col2" class="data row44 col2">Evaluates clustering model performance by measuring mutual information between true and predicted labels, adjusting...</td>
<td id="T_0a3cb_row44_col3" class="data row44 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row44_col4" class="data row44 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row45_col0" class="data row45 col0">validmind.model_validation.sklearn.SilhouettePlot</td>
<td id="T_0a3cb_row45_col1" class="data row45 col1">Silhouette Plot</td>
<td id="T_0a3cb_row45_col2" class="data row45 col2">Calculates and visualizes Silhouette Score, assessing degree of data point suitability to its cluster in ML models....</td>
<td id="T_0a3cb_row45_col3" class="data row45 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row45_col4" class="data row45 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row46_col0" class="data row46 col0">validmind.model_validation.sklearn.RobustnessDiagnosis</td>
<td id="T_0a3cb_row46_col1" class="data row46 col1">Robustness Diagnosis</td>
<td id="T_0a3cb_row46_col2" class="data row46 col2">Evaluates the robustness of a machine learning model by injecting Gaussian noise to input data and measuring...</td>
<td id="T_0a3cb_row46_col3" class="data row46 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row46_col4" class="data row46 col4">{'features_columns': None, 'scaling_factor_std_dev_list': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], 'accuracy_decay_threshold': 4}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row47_col0" class="data row47 col0">validmind.model_validation.sklearn.AdjustedRandIndex</td>
<td id="T_0a3cb_row47_col1" class="data row47 col1">Adjusted Rand Index</td>
<td id="T_0a3cb_row47_col2" class="data row47 col2">Measures the similarity between two data clusters using the Adjusted Rand Index (ARI) metric in clustering machine...</td>
<td id="T_0a3cb_row47_col3" class="data row47 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row47_col4" class="data row47 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row48_col0" class="data row48 col0">validmind.model_validation.sklearn.SHAPGlobalImportance</td>
<td id="T_0a3cb_row48_col1" class="data row48 col1">SHAP Global Importance</td>
<td id="T_0a3cb_row48_col2" class="data row48 col2">Evaluates and visualizes global feature importance using SHAP values for model explanation and risk identification....</td>
<td id="T_0a3cb_row48_col3" class="data row48 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row48_col4" class="data row48 col4">{'kernel_explainer_samples': 10, 'tree_or_linear_explainer_samples': 200}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row49_col0" class="data row49 col0">validmind.model_validation.sklearn.ConfusionMatrix</td>
<td id="T_0a3cb_row49_col1" class="data row49 col1">Confusion Matrix</td>
<td id="T_0a3cb_row49_col2" class="data row49 col2">Evaluates and visually represents the classification ML model's predictive performance using a Confusion Matrix...</td>
<td id="T_0a3cb_row49_col3" class="data row49 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row49_col4" class="data row49 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row50_col0" class="data row50 col0">validmind.model_validation.sklearn.HomogeneityScore</td>
<td id="T_0a3cb_row50_col1" class="data row50 col1">Homogeneity Score</td>
<td id="T_0a3cb_row50_col2" class="data row50 col2">Assesses clustering homogeneity by comparing true and predicted labels, scoring from 0 (heterogeneous) to 1...</td>
<td id="T_0a3cb_row50_col3" class="data row50 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row50_col4" class="data row50 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row51_col0" class="data row51 col0">validmind.model_validation.sklearn.CompletenessScore</td>
<td id="T_0a3cb_row51_col1" class="data row51 col1">Completeness Score</td>
<td id="T_0a3cb_row51_col2" class="data row51 col2">Evaluates a clustering model's capacity to categorize instances from a single class into the same cluster....</td>
<td id="T_0a3cb_row51_col3" class="data row51 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row51_col4" class="data row51 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row52_col0" class="data row52 col0">validmind.model_validation.sklearn.OverfitDiagnosis</td>
<td id="T_0a3cb_row52_col1" class="data row52 col1">Overfit Diagnosis</td>
<td id="T_0a3cb_row52_col2" class="data row52 col2">Detects and visualizes overfit regions in an ML model by comparing performance on training and test datasets....</td>
<td id="T_0a3cb_row52_col3" class="data row52 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row52_col4" class="data row52 col4">{'features_columns': None, 'cut_off_percentage': 4}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row53_col0" class="data row53 col0">validmind.model_validation.sklearn.ClusterPerformanceMetrics</td>
<td id="T_0a3cb_row53_col1" class="data row53 col1">Cluster Performance Metrics</td>
<td id="T_0a3cb_row53_col2" class="data row53 col2">Evaluates the performance of clustering machine learning models using multiple established metrics....</td>
<td id="T_0a3cb_row53_col3" class="data row53 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row53_col4" class="data row53 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row54_col0" class="data row54 col0">validmind.model_validation.sklearn.PermutationFeatureImportance</td>
<td id="T_0a3cb_row54_col1" class="data row54 col1">Permutation Feature Importance</td>
<td id="T_0a3cb_row54_col2" class="data row54 col2">Assesses the significance of each feature in a model by evaluating the impact on model performance when feature...</td>
<td id="T_0a3cb_row54_col3" class="data row54 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row54_col4" class="data row54 col4">{'fontsize': None, 'figure_height': 1000}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row55_col0" class="data row55 col0">validmind.model_validation.sklearn.FowlkesMallowsScore</td>
<td id="T_0a3cb_row55_col1" class="data row55 col1">Fowlkes Mallows Score</td>
<td id="T_0a3cb_row55_col2" class="data row55 col2">Evaluates the similarity between predicted and actual cluster assignments in a model using the Fowlkes-Mallows...</td>
<td id="T_0a3cb_row55_col3" class="data row55 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row55_col4" class="data row55 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row56_col0" class="data row56 col0">validmind.model_validation.sklearn.MinimumROCAUCScore</td>
<td id="T_0a3cb_row56_col1" class="data row56 col1">Minimum ROCAUC Score</td>
<td id="T_0a3cb_row56_col2" class="data row56 col2">Validates model by checking if the ROC AUC score meets or surpasses a specified threshold....</td>
<td id="T_0a3cb_row56_col3" class="data row56 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row56_col4" class="data row56 col4">{'min_threshold': 0.5}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row57_col0" class="data row57 col0">validmind.model_validation.sklearn.ClusterCosineSimilarity</td>
<td id="T_0a3cb_row57_col1" class="data row57 col1">Cluster Cosine Similarity</td>
<td id="T_0a3cb_row57_col2" class="data row57 col2">Measures the intra-cluster similarity of a clustering model using cosine similarity....</td>
<td id="T_0a3cb_row57_col3" class="data row57 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row57_col4" class="data row57 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row58_col0" class="data row58 col0">validmind.model_validation.sklearn.PrecisionRecallCurve</td>
<td id="T_0a3cb_row58_col1" class="data row58 col1">Precision Recall Curve</td>
<td id="T_0a3cb_row58_col2" class="data row58 col2">Evaluates the precision-recall trade-off for binary classification models and visualizes the Precision-Recall curve....</td>
<td id="T_0a3cb_row58_col3" class="data row58 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row58_col4" class="data row58 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row59_col0" class="data row59 col0">validmind.model_validation.sklearn.ClassifierPerformance</td>
<td id="T_0a3cb_row59_col1" class="data row59 col1">Classifier Performance</td>
<td id="T_0a3cb_row59_col2" class="data row59 col2">Evaluates performance of binary or multiclass classification models using precision, recall, F1-Score, accuracy,...</td>
<td id="T_0a3cb_row59_col3" class="data row59 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row59_col4" class="data row59 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row60_col0" class="data row60 col0">validmind.model_validation.sklearn.VMeasure</td>
<td id="T_0a3cb_row60_col1" class="data row60 col1">V Measure</td>
<td id="T_0a3cb_row60_col2" class="data row60 col2">Evaluates homogeneity and completeness of a clustering model using the V Measure Score....</td>
<td id="T_0a3cb_row60_col3" class="data row60 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row60_col4" class="data row60 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row61_col0" class="data row61 col0">validmind.model_validation.sklearn.MinimumF1Score</td>
<td id="T_0a3cb_row61_col1" class="data row61 col1">Minimum F1 Score</td>
<td id="T_0a3cb_row61_col2" class="data row61 col2">Evaluates if the model's F1 score on the validation set meets a predefined minimum threshold....</td>
<td id="T_0a3cb_row61_col3" class="data row61 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row61_col4" class="data row61 col4">{'min_threshold': 0.5}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row62_col0" class="data row62 col0">validmind.model_validation.sklearn.ROCCurve</td>
<td id="T_0a3cb_row62_col1" class="data row62 col1">ROC Curve</td>
<td id="T_0a3cb_row62_col2" class="data row62 col2">Evaluates binary classification model performance by generating and plotting the Receiver Operating Characteristic...</td>
<td id="T_0a3cb_row62_col3" class="data row62 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row62_col4" class="data row62 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row63_col0" class="data row63 col0">validmind.model_validation.sklearn.RegressionR2Square</td>
<td id="T_0a3cb_row63_col1" class="data row63 col1">Regression R2 Square</td>
<td id="T_0a3cb_row63_col2" class="data row63 col2">**Purpose**: The purpose of the RegressionR2Square Metric test is to measure the overall goodness-of-fit of a...</td>
<td id="T_0a3cb_row63_col3" class="data row63 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row63_col4" class="data row63 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row64_col0" class="data row64 col0">validmind.model_validation.sklearn.RegressionErrors</td>
<td id="T_0a3cb_row64_col1" class="data row64 col1">Regression Errors</td>
<td id="T_0a3cb_row64_col2" class="data row64 col2">**Purpose**: This metric is used to measure the performance of a regression model. It gauges the model's accuracy...</td>
<td id="T_0a3cb_row64_col3" class="data row64 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row64_col4" class="data row64 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row65_col0" class="data row65 col0">validmind.model_validation.sklearn.ClusterPerformance</td>
<td id="T_0a3cb_row65_col1" class="data row65 col1">Cluster Performance</td>
<td id="T_0a3cb_row65_col2" class="data row65 col2">Evaluates and compares a clustering model's performance on training and testing datasets using multiple defined...</td>
<td id="T_0a3cb_row65_col3" class="data row65 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row65_col4" class="data row65 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row66_col0" class="data row66 col0">validmind.model_validation.sklearn.TrainingTestDegradation</td>
<td id="T_0a3cb_row66_col1" class="data row66 col1">Training Test Degradation</td>
<td id="T_0a3cb_row66_col2" class="data row66 col2">Tests if model performance degradation between training and test datasets exceeds a predefined threshold....</td>
<td id="T_0a3cb_row66_col3" class="data row66 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row66_col4" class="data row66 col4">{'metrics': ['accuracy', 'precision', 'recall', 'f1'], 'max_threshold': 0.1}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row67_col0" class="data row67 col0">validmind.model_validation.sklearn.HyperParametersTuning</td>
<td id="T_0a3cb_row67_col1" class="data row67 col1">Hyper Parameters Tuning</td>
<td id="T_0a3cb_row67_col2" class="data row67 col2">Exerts exhaustive grid search to identify optimal hyperparameters for the model, improving performance....</td>
<td id="T_0a3cb_row67_col3" class="data row67 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row67_col4" class="data row67 col4">{'param_grid': None, 'scoring': None}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row68_col0" class="data row68 col0">validmind.model_validation.sklearn.KMeansClustersOptimization</td>
<td id="T_0a3cb_row68_col1" class="data row68 col1">K Means Clusters Optimization</td>
<td id="T_0a3cb_row68_col2" class="data row68 col2">Optimizes the number of clusters in K-means models using Elbow and Silhouette methods....</td>
<td id="T_0a3cb_row68_col3" class="data row68 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row68_col4" class="data row68 col4">{'n_clusters': None}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row69_col0" class="data row69 col0">validmind.model_validation.sklearn.ModelsPerformanceComparison</td>
<td id="T_0a3cb_row69_col1" class="data row69 col1">Models Performance Comparison</td>
<td id="T_0a3cb_row69_col2" class="data row69 col2">Evaluates and compares the performance of multiple Machine Learning models using various metrics like accuracy,...</td>
<td id="T_0a3cb_row69_col3" class="data row69 col3">['dataset', 'models']</td>
<td id="T_0a3cb_row69_col4" class="data row69 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row70_col0" class="data row70 col0">validmind.model_validation.sklearn.WeakspotsDiagnosis</td>
<td id="T_0a3cb_row70_col1" class="data row70 col1">Weakspots Diagnosis</td>
<td id="T_0a3cb_row70_col2" class="data row70 col2">Identifies and visualizes weak spots in a machine learning model's performance across various sections of the...</td>
<td id="T_0a3cb_row70_col3" class="data row70 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row70_col4" class="data row70 col4">{'features_columns': None, 'thresholds': {'accuracy': 0.75, 'precision': 0.5, 'recall': 0.5, 'f1': 0.7}}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row71_col0" class="data row71 col0">validmind.model_validation.sklearn.PopulationStabilityIndex</td>
<td id="T_0a3cb_row71_col1" class="data row71 col1">Population Stability Index</td>
<td id="T_0a3cb_row71_col2" class="data row71 col2">Evaluates the Population Stability Index (PSI) to quantify the stability of an ML model's predictions across...</td>
<td id="T_0a3cb_row71_col3" class="data row71 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row71_col4" class="data row71 col4">{'num_bins': 10, 'mode': 'fixed'}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row72_col0" class="data row72 col0">validmind.model_validation.sklearn.MinimumAccuracy</td>
<td id="T_0a3cb_row72_col1" class="data row72 col1">Minimum Accuracy</td>
<td id="T_0a3cb_row72_col2" class="data row72 col2">Checks if the model's prediction accuracy meets or surpasses a specified threshold....</td>
<td id="T_0a3cb_row72_col3" class="data row72 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row72_col4" class="data row72 col4">{'min_threshold': 0.7}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row73_col0" class="data row73 col0">validmind.model_validation.statsmodels.RegressionModelsCoeffs</td>
<td id="T_0a3cb_row73_col1" class="data row73 col1">Regression Models Coeffs</td>
<td id="T_0a3cb_row73_col2" class="data row73 col2">Compares feature importance by evaluating and contrasting coefficients of different regression models....</td>
<td id="T_0a3cb_row73_col3" class="data row73 col3">['models']</td>
<td id="T_0a3cb_row73_col4" class="data row73 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row74_col0" class="data row74 col0">validmind.model_validation.statsmodels.BoxPierce</td>
<td id="T_0a3cb_row74_col1" class="data row74 col1">Box Pierce</td>
<td id="T_0a3cb_row74_col2" class="data row74 col2">Detects autocorrelation in time-series data through the Box-Pierce test to validate model performance....</td>
<td id="T_0a3cb_row74_col3" class="data row74 col3">['dataset']</td>
<td id="T_0a3cb_row74_col4" class="data row74 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row75_col0" class="data row75 col0">validmind.model_validation.statsmodels.RegressionCoeffsPlot</td>
<td id="T_0a3cb_row75_col1" class="data row75 col1">Regression Coeffs Plot</td>
<td id="T_0a3cb_row75_col2" class="data row75 col2">Visualizes regression coefficients with 95% confidence intervals to assess predictor variables' impact on response...</td>
<td id="T_0a3cb_row75_col3" class="data row75 col3">['models']</td>
<td id="T_0a3cb_row75_col4" class="data row75 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row76_col0" class="data row76 col0">validmind.model_validation.statsmodels.RegressionModelSensitivityPlot</td>
<td id="T_0a3cb_row76_col1" class="data row76 col1">Regression Model Sensitivity Plot</td>
<td id="T_0a3cb_row76_col2" class="data row76 col2">Tests the sensitivity of a regression model to variations in independent variables by applying shocks and...</td>
<td id="T_0a3cb_row76_col3" class="data row76 col3">['models', 'datasets']</td>
<td id="T_0a3cb_row76_col4" class="data row76 col4">{'transformation': None, 'shocks': [0.1]}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row77_col0" class="data row77 col0">validmind.model_validation.statsmodels.RegressionModelForecastPlotLevels</td>
<td id="T_0a3cb_row77_col1" class="data row77 col1">Regression Model Forecast Plot Levels</td>
<td id="T_0a3cb_row77_col2" class="data row77 col2">Compares and visualizes forecasted and actual values of regression models on both raw and transformed datasets....</td>
<td id="T_0a3cb_row77_col3" class="data row77 col3">['models', 'datasets']</td>
<td id="T_0a3cb_row77_col4" class="data row77 col4">{'transformation': None}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row78_col0" class="data row78 col0">validmind.model_validation.statsmodels.ScorecardHistogram</td>
<td id="T_0a3cb_row78_col1" class="data row78 col1">Scorecard Histogram</td>
<td id="T_0a3cb_row78_col2" class="data row78 col2">Creates histograms of credit scores, from both default and non-default instances, generated by a credit-risk model....</td>
<td id="T_0a3cb_row78_col3" class="data row78 col3">['datasets']</td>
<td id="T_0a3cb_row78_col4" class="data row78 col4">{'title': 'Histogram of Scores', 'score_column': 'score'}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row79_col0" class="data row79 col0">validmind.model_validation.statsmodels.LJungBox</td>
<td id="T_0a3cb_row79_col1" class="data row79 col1">L Jung Box</td>
<td id="T_0a3cb_row79_col2" class="data row79 col2">Assesses autocorrelations in dataset features by performing a Ljung-Box test on each feature....</td>
<td id="T_0a3cb_row79_col3" class="data row79 col3">['dataset']</td>
<td id="T_0a3cb_row79_col4" class="data row79 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row80_col0" class="data row80 col0">validmind.model_validation.statsmodels.JarqueBera</td>
<td id="T_0a3cb_row80_col1" class="data row80 col1">Jarque Bera</td>
<td id="T_0a3cb_row80_col2" class="data row80 col2">Assesses normality of dataset features in an ML model using the Jarque-Bera test....</td>
<td id="T_0a3cb_row80_col3" class="data row80 col3">['dataset']</td>
<td id="T_0a3cb_row80_col4" class="data row80 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row81_col0" class="data row81 col0">validmind.model_validation.statsmodels.KolmogorovSmirnov</td>
<td id="T_0a3cb_row81_col1" class="data row81 col1">Kolmogorov Smirnov</td>
<td id="T_0a3cb_row81_col2" class="data row81 col2">Executes a feature-wise Kolmogorov-Smirnov test to evaluate alignment with normal distribution in datasets....</td>
<td id="T_0a3cb_row81_col3" class="data row81 col3">['dataset']</td>
<td id="T_0a3cb_row81_col4" class="data row81 col4">{'dist': 'norm'}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row82_col0" class="data row82 col0">validmind.model_validation.statsmodels.ShapiroWilk</td>
<td id="T_0a3cb_row82_col1" class="data row82 col1">Shapiro Wilk</td>
<td id="T_0a3cb_row82_col2" class="data row82 col2">Evaluates feature-wise normality of training data using the Shapiro-Wilk test....</td>
<td id="T_0a3cb_row82_col3" class="data row82 col3">['dataset']</td>
<td id="T_0a3cb_row82_col4" class="data row82 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row83_col0" class="data row83 col0">validmind.model_validation.statsmodels.CumulativePredictionProbabilities</td>
<td id="T_0a3cb_row83_col1" class="data row83 col1">Cumulative Prediction Probabilities</td>
<td id="T_0a3cb_row83_col2" class="data row83 col2">Visualizes cumulative probabilities of positive and negative classes for both training and testing in logistic...</td>
<td id="T_0a3cb_row83_col3" class="data row83 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row83_col4" class="data row83 col4">{'title': 'Cumulative Probabilities'}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row84_col0" class="data row84 col0">validmind.model_validation.statsmodels.RegressionFeatureSignificance</td>
<td id="T_0a3cb_row84_col1" class="data row84 col1">Regression Feature Significance</td>
<td id="T_0a3cb_row84_col2" class="data row84 col2">Assesses and visualizes the statistical significance of features in a set of regression models....</td>
<td id="T_0a3cb_row84_col3" class="data row84 col3">['models']</td>
<td id="T_0a3cb_row84_col4" class="data row84 col4">{'fontsize': 10, 'p_threshold': 0.05}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row85_col0" class="data row85 col0">validmind.model_validation.statsmodels.RegressionModelSummary</td>
<td id="T_0a3cb_row85_col1" class="data row85 col1">Regression Model Summary</td>
<td id="T_0a3cb_row85_col2" class="data row85 col2">Evaluates regression model performance using metrics including R-Squared, Adjusted R-Squared, MSE, and RMSE....</td>
<td id="T_0a3cb_row85_col3" class="data row85 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row85_col4" class="data row85 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row86_col0" class="data row86 col0">validmind.model_validation.statsmodels.Lilliefors</td>
<td id="T_0a3cb_row86_col1" class="data row86 col1">Lilliefors</td>
<td id="T_0a3cb_row86_col2" class="data row86 col2">Assesses the normality of feature distributions in an ML model's training dataset using the Lilliefors test....</td>
<td id="T_0a3cb_row86_col3" class="data row86 col3">['dataset']</td>
<td id="T_0a3cb_row86_col4" class="data row86 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row87_col0" class="data row87 col0">validmind.model_validation.statsmodels.RunsTest</td>
<td id="T_0a3cb_row87_col1" class="data row87 col1">Runs Test</td>
<td id="T_0a3cb_row87_col2" class="data row87 col2">Executes Runs Test on ML model to detect non-random patterns in output data sequence....</td>
<td id="T_0a3cb_row87_col3" class="data row87 col3">['dataset']</td>
<td id="T_0a3cb_row87_col4" class="data row87 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row88_col0" class="data row88 col0">validmind.model_validation.statsmodels.RegressionPermutationFeatureImportance</td>
<td id="T_0a3cb_row88_col1" class="data row88 col1">Regression Permutation Feature Importance</td>
<td id="T_0a3cb_row88_col2" class="data row88 col2">Assesses the significance of each feature in a model by evaluating the impact on model performance when feature...</td>
<td id="T_0a3cb_row88_col3" class="data row88 col3">['model', 'dataset']</td>
<td id="T_0a3cb_row88_col4" class="data row88 col4">{'fontsize': 12, 'figure_height': 500}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row89_col0" class="data row89 col0">validmind.model_validation.statsmodels.PredictionProbabilitiesHistogram</td>
<td id="T_0a3cb_row89_col1" class="data row89 col1">Prediction Probabilities Histogram</td>
<td id="T_0a3cb_row89_col2" class="data row89 col2">Generates and visualizes histograms of the Probability of Default predictions for both positive and negative...</td>
<td id="T_0a3cb_row89_col3" class="data row89 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row89_col4" class="data row89 col4">{'title': 'Histogram of Predictive Probabilities'}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row90_col0" class="data row90 col0">validmind.model_validation.statsmodels.AutoARIMA</td>
<td id="T_0a3cb_row90_col1" class="data row90 col1">Auto ARIMA</td>
<td id="T_0a3cb_row90_col2" class="data row90 col2">Evaluates ARIMA models for time-series forecasting, ranking them using Bayesian and Akaike Information Criteria....</td>
<td id="T_0a3cb_row90_col3" class="data row90 col3">['dataset']</td>
<td id="T_0a3cb_row90_col4" class="data row90 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row91_col0" class="data row91 col0">validmind.model_validation.statsmodels.GINITable</td>
<td id="T_0a3cb_row91_col1" class="data row91 col1">GINI Table</td>
<td id="T_0a3cb_row91_col2" class="data row91 col2">Evaluates classification model performance using AUC, GINI, and KS metrics for training and test datasets....</td>
<td id="T_0a3cb_row91_col3" class="data row91 col3">['model', 'datasets']</td>
<td id="T_0a3cb_row91_col4" class="data row91 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row92_col0" class="data row92 col0">validmind.model_validation.statsmodels.RegressionModelForecastPlot</td>
<td id="T_0a3cb_row92_col1" class="data row92 col1">Regression Model Forecast Plot</td>
<td id="T_0a3cb_row92_col2" class="data row92 col2">Generates plots to visually compare the forecasted outcomes of one or more regression models against actual...</td>
<td id="T_0a3cb_row92_col3" class="data row92 col3">['models', 'datasets']</td>
<td id="T_0a3cb_row92_col4" class="data row92 col4">{'start_date': None, 'end_date': None}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row93_col0" class="data row93 col0">validmind.model_validation.statsmodels.DurbinWatsonTest</td>
<td id="T_0a3cb_row93_col1" class="data row93 col1">Durbin Watson Test</td>
<td id="T_0a3cb_row93_col2" class="data row93 col2">Assesses autocorrelation in time series data features using the Durbin-Watson statistic....</td>
<td id="T_0a3cb_row93_col3" class="data row93 col3">['dataset']</td>
<td id="T_0a3cb_row93_col4" class="data row93 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row94_col0" class="data row94 col0">validmind.data_validation.MissingValuesRisk</td>
<td id="T_0a3cb_row94_col1" class="data row94 col1">Missing Values Risk</td>
<td id="T_0a3cb_row94_col2" class="data row94 col2">Assesses and quantifies the risk related to missing values in a dataset used for training an ML model....</td>
<td id="T_0a3cb_row94_col3" class="data row94 col3">['dataset']</td>
<td id="T_0a3cb_row94_col4" class="data row94 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row95_col0" class="data row95 col0">validmind.data_validation.IQROutliersTable</td>
<td id="T_0a3cb_row95_col1" class="data row95 col1">IQR Outliers Table</td>
<td id="T_0a3cb_row95_col2" class="data row95 col2">Determines and summarizes outliers in numerical features using Interquartile Range method....</td>
<td id="T_0a3cb_row95_col3" class="data row95 col3">['dataset']</td>
<td id="T_0a3cb_row95_col4" class="data row95 col4">{'features': None, 'threshold': 1.5}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row96_col0" class="data row96 col0">validmind.data_validation.BivariateFeaturesBarPlots</td>
<td id="T_0a3cb_row96_col1" class="data row96 col1">Bivariate Features Bar Plots</td>
<td id="T_0a3cb_row96_col2" class="data row96 col2">Generates visual bar plots to analyze the relationship between paired features within categorical data in the model....</td>
<td id="T_0a3cb_row96_col3" class="data row96 col3">['dataset']</td>
<td id="T_0a3cb_row96_col4" class="data row96 col4">{'features_pairs': None}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row97_col0" class="data row97 col0">validmind.data_validation.Skewness</td>
<td id="T_0a3cb_row97_col1" class="data row97 col1">Skewness</td>
<td id="T_0a3cb_row97_col2" class="data row97 col2">Evaluates the skewness of numerical data in a machine learning model and checks if it falls below a set maximum...</td>
<td id="T_0a3cb_row97_col3" class="data row97 col3">['dataset']</td>
<td id="T_0a3cb_row97_col4" class="data row97 col4">{'max_threshold': 1}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row98_col0" class="data row98 col0">validmind.data_validation.Duplicates</td>
<td id="T_0a3cb_row98_col1" class="data row98 col1">Duplicates</td>
<td id="T_0a3cb_row98_col2" class="data row98 col2">Tests dataset for duplicate entries, ensuring model reliability via data quality verification....</td>
<td id="T_0a3cb_row98_col3" class="data row98 col3">['dataset']</td>
<td id="T_0a3cb_row98_col4" class="data row98 col4">{'min_threshold': 1}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row99_col0" class="data row99 col0">validmind.data_validation.MissingValuesBarPlot</td>
<td id="T_0a3cb_row99_col1" class="data row99 col1">Missing Values Bar Plot</td>
<td id="T_0a3cb_row99_col2" class="data row99 col2">Creates a bar plot showcasing the percentage of missing values in each column of the dataset with risk...</td>
<td id="T_0a3cb_row99_col3" class="data row99 col3">['dataset']</td>
<td id="T_0a3cb_row99_col4" class="data row99 col4">{'threshold': 80, 'fig_height': 600}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row100_col0" class="data row100 col0">validmind.data_validation.DatasetDescription</td>
<td id="T_0a3cb_row100_col1" class="data row100 col1">Dataset Description</td>
<td id="T_0a3cb_row100_col2" class="data row100 col2">Provides comprehensive analysis and statistical summaries of each field in a machine learning model's dataset....</td>
<td id="T_0a3cb_row100_col3" class="data row100 col3">['dataset']</td>
<td id="T_0a3cb_row100_col4" class="data row100 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row101_col0" class="data row101 col0">validmind.data_validation.ZivotAndrewsArch</td>
<td id="T_0a3cb_row101_col1" class="data row101 col1">Zivot Andrews Arch</td>
<td id="T_0a3cb_row101_col2" class="data row101 col2">Evaluates the order of integration and stationarity of time series data using Zivot-Andrews unit root test....</td>
<td id="T_0a3cb_row101_col3" class="data row101 col3">['dataset']</td>
<td id="T_0a3cb_row101_col4" class="data row101 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row102_col0" class="data row102 col0">validmind.data_validation.ScatterPlot</td>
<td id="T_0a3cb_row102_col1" class="data row102 col1">Scatter Plot</td>
<td id="T_0a3cb_row102_col2" class="data row102 col2">Creates a scatter plot matrix to visually analyze feature relationships, patterns, and outliers in a dataset....</td>
<td id="T_0a3cb_row102_col3" class="data row102 col3">['dataset']</td>
<td id="T_0a3cb_row102_col4" class="data row102 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row103_col0" class="data row103 col0">validmind.data_validation.TimeSeriesOutliers</td>
<td id="T_0a3cb_row103_col1" class="data row103 col1">Time Series Outliers</td>
<td id="T_0a3cb_row103_col2" class="data row103 col2">Identifies and visualizes outliers in time-series data using z-score method....</td>
<td id="T_0a3cb_row103_col3" class="data row103 col3">['dataset']</td>
<td id="T_0a3cb_row103_col4" class="data row103 col4">{'zscore_threshold': 3}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row104_col0" class="data row104 col0">validmind.data_validation.TabularCategoricalBarPlots</td>
<td id="T_0a3cb_row104_col1" class="data row104 col1">Tabular Categorical Bar Plots</td>
<td id="T_0a3cb_row104_col2" class="data row104 col2">Generates and visualizes bar plots for each category in categorical features to evaluate dataset's composition....</td>
<td id="T_0a3cb_row104_col3" class="data row104 col3">['dataset']</td>
<td id="T_0a3cb_row104_col4" class="data row104 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row105_col0" class="data row105 col0">validmind.data_validation.AutoStationarity</td>
<td id="T_0a3cb_row105_col1" class="data row105 col1">Auto Stationarity</td>
<td id="T_0a3cb_row105_col2" class="data row105 col2">Automates Augmented Dickey-Fuller test to assess stationarity across multiple time series in a DataFrame....</td>
<td id="T_0a3cb_row105_col3" class="data row105 col3">['dataset']</td>
<td id="T_0a3cb_row105_col4" class="data row105 col4">{'max_order': 5, 'threshold': 0.05}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row106_col0" class="data row106 col0">validmind.data_validation.DescriptiveStatistics</td>
<td id="T_0a3cb_row106_col1" class="data row106 col1">Descriptive Statistics</td>
<td id="T_0a3cb_row106_col2" class="data row106 col2">Performs a detailed descriptive statistical analysis of both numerical and categorical data within a model's...</td>
<td id="T_0a3cb_row106_col3" class="data row106 col3">['dataset']</td>
<td id="T_0a3cb_row106_col4" class="data row106 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row107_col0" class="data row107 col0">validmind.data_validation.ANOVAOneWayTable</td>
<td id="T_0a3cb_row107_col1" class="data row107 col1">ANOVA One Way Table</td>
<td id="T_0a3cb_row107_col2" class="data row107 col2">Applies one-way ANOVA (Analysis of Variance) to identify statistically significant numerical features in the...</td>
<td id="T_0a3cb_row107_col3" class="data row107 col3">['dataset']</td>
<td id="T_0a3cb_row107_col4" class="data row107 col4">{'features': None, 'p_threshold': 0.05}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row108_col0" class="data row108 col0">validmind.data_validation.TargetRateBarPlots</td>
<td id="T_0a3cb_row108_col1" class="data row108 col1">Target Rate Bar Plots</td>
<td id="T_0a3cb_row108_col2" class="data row108 col2">Generates bar plots visualizing the default rates of categorical features for a classification machine learning...</td>
<td id="T_0a3cb_row108_col3" class="data row108 col3">['dataset']</td>
<td id="T_0a3cb_row108_col4" class="data row108 col4">{'default_column': None, 'columns': None}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row109_col0" class="data row109 col0">validmind.data_validation.PearsonCorrelationMatrix</td>
<td id="T_0a3cb_row109_col1" class="data row109 col1">Pearson Correlation Matrix</td>
<td id="T_0a3cb_row109_col2" class="data row109 col2">Evaluates linear dependency between numerical variables in a dataset via a Pearson Correlation coefficient heat map....</td>
<td id="T_0a3cb_row109_col3" class="data row109 col3">['dataset']</td>
<td id="T_0a3cb_row109_col4" class="data row109 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row110_col0" class="data row110 col0">validmind.data_validation.FeatureTargetCorrelationPlot</td>
<td id="T_0a3cb_row110_col1" class="data row110 col1">Feature Target Correlation Plot</td>
<td id="T_0a3cb_row110_col2" class="data row110 col2">Visualizes the correlation between input features and model's target output in a color-coded horizontal bar plot....</td>
<td id="T_0a3cb_row110_col3" class="data row110 col3">['dataset']</td>
<td id="T_0a3cb_row110_col4" class="data row110 col4">{'features': None, 'fig_height': 600}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row111_col0" class="data row111 col0">validmind.data_validation.TabularNumericalHistograms</td>
<td id="T_0a3cb_row111_col1" class="data row111 col1">Tabular Numerical Histograms</td>
<td id="T_0a3cb_row111_col2" class="data row111 col2">Generates histograms for each numerical feature in a dataset to provide visual insights into data distribution and...</td>
<td id="T_0a3cb_row111_col3" class="data row111 col3">['dataset']</td>
<td id="T_0a3cb_row111_col4" class="data row111 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row112_col0" class="data row112 col0">validmind.data_validation.IsolationForestOutliers</td>
<td id="T_0a3cb_row112_col1" class="data row112 col1">Isolation Forest Outliers</td>
<td id="T_0a3cb_row112_col2" class="data row112 col2">Detects outliers in a dataset using the Isolation Forest algorithm and visualizes results through scatter plots....</td>
<td id="T_0a3cb_row112_col3" class="data row112 col3">['dataset']</td>
<td id="T_0a3cb_row112_col4" class="data row112 col4">{'random_state': 0, 'contamination': 0.1, 'features_columns': None}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row113_col0" class="data row113 col0">validmind.data_validation.ChiSquaredFeaturesTable</td>
<td id="T_0a3cb_row113_col1" class="data row113 col1">Chi Squared Features Table</td>
<td id="T_0a3cb_row113_col2" class="data row113 col2">Executes Chi-Squared test for each categorical feature against a target column to assess significant association....</td>
<td id="T_0a3cb_row113_col3" class="data row113 col3">['dataset']</td>
<td id="T_0a3cb_row113_col4" class="data row113 col4">{'cat_features': None, 'p_threshold': 0.05}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row114_col0" class="data row114 col0">validmind.data_validation.HighCardinality</td>
<td id="T_0a3cb_row114_col1" class="data row114 col1">High Cardinality</td>
<td id="T_0a3cb_row114_col2" class="data row114 col2">Assesses the number of unique values in categorical columns to detect high cardinality and potential overfitting....</td>
<td id="T_0a3cb_row114_col3" class="data row114 col3">['dataset']</td>
<td id="T_0a3cb_row114_col4" class="data row114 col4">{'num_threshold': 100, 'percent_threshold': 0.1, 'threshold_type': 'percent'}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row115_col0" class="data row115 col0">validmind.data_validation.MissingValues</td>
<td id="T_0a3cb_row115_col1" class="data row115 col1">Missing Values</td>
<td id="T_0a3cb_row115_col2" class="data row115 col2">Evaluates dataset quality by ensuring missing value ratio across all features does not exceed a set threshold....</td>
<td id="T_0a3cb_row115_col3" class="data row115 col3">['dataset']</td>
<td id="T_0a3cb_row115_col4" class="data row115 col4">{'min_threshold': 1}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row116_col0" class="data row116 col0">validmind.data_validation.PhillipsPerronArch</td>
<td id="T_0a3cb_row116_col1" class="data row116 col1">Phillips Perron Arch</td>
<td id="T_0a3cb_row116_col2" class="data row116 col2">Executes Phillips-Perron test to assess the stationarity of time series data in each ML model feature....</td>
<td id="T_0a3cb_row116_col3" class="data row116 col3">['dataset']</td>
<td id="T_0a3cb_row116_col4" class="data row116 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row117_col0" class="data row117 col0">validmind.data_validation.RollingStatsPlot</td>
<td id="T_0a3cb_row117_col1" class="data row117 col1">Rolling Stats Plot</td>
<td id="T_0a3cb_row117_col2" class="data row117 col2">This test evaluates the stationarity of time series data by plotting its rolling mean and standard deviation....</td>
<td id="T_0a3cb_row117_col3" class="data row117 col3">['dataset']</td>
<td id="T_0a3cb_row117_col4" class="data row117 col4">{'window_size': 12}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row118_col0" class="data row118 col0">validmind.data_validation.TabularDescriptionTables</td>
<td id="T_0a3cb_row118_col1" class="data row118 col1">Tabular Description Tables</td>
<td id="T_0a3cb_row118_col2" class="data row118 col2">Summarizes key descriptive statistics for numerical, categorical, and datetime variables in a dataset....</td>
<td id="T_0a3cb_row118_col3" class="data row118 col3">['dataset']</td>
<td id="T_0a3cb_row118_col4" class="data row118 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row119_col0" class="data row119 col0">validmind.data_validation.AutoMA</td>
<td id="T_0a3cb_row119_col1" class="data row119 col1">Auto MA</td>
<td id="T_0a3cb_row119_col2" class="data row119 col2">Automatically selects the optimal Moving Average (MA) order for each variable in a time series dataset based on...</td>
<td id="T_0a3cb_row119_col3" class="data row119 col3">['dataset']</td>
<td id="T_0a3cb_row119_col4" class="data row119 col4">{'max_ma_order': 3}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row120_col0" class="data row120 col0">validmind.data_validation.UniqueRows</td>
<td id="T_0a3cb_row120_col1" class="data row120 col1">Unique Rows</td>
<td id="T_0a3cb_row120_col2" class="data row120 col2">Verifies the diversity of the dataset by ensuring that the count of unique rows exceeds a prescribed threshold....</td>
<td id="T_0a3cb_row120_col3" class="data row120 col3">['dataset']</td>
<td id="T_0a3cb_row120_col4" class="data row120 col4">{'min_percent_threshold': 1}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row121_col0" class="data row121 col0">validmind.data_validation.TooManyZeroValues</td>
<td id="T_0a3cb_row121_col1" class="data row121 col1">Too Many Zero Values</td>
<td id="T_0a3cb_row121_col2" class="data row121 col2">Identifies numerical columns in a dataset that contain an excessive number of zero values, defined by a threshold...</td>
<td id="T_0a3cb_row121_col3" class="data row121 col3">['dataset']</td>
<td id="T_0a3cb_row121_col4" class="data row121 col4">{'max_percent_threshold': 0.03}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row122_col0" class="data row122 col0">validmind.data_validation.HighPearsonCorrelation</td>
<td id="T_0a3cb_row122_col1" class="data row122 col1">High Pearson Correlation</td>
<td id="T_0a3cb_row122_col2" class="data row122 col2">Identifies highly correlated feature pairs in a dataset suggesting feature redundancy or multicollinearity....</td>
<td id="T_0a3cb_row122_col3" class="data row122 col3">['dataset']</td>
<td id="T_0a3cb_row122_col4" class="data row122 col4">{'max_threshold': 0.3}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row123_col0" class="data row123 col0">validmind.data_validation.ACFandPACFPlot</td>
<td id="T_0a3cb_row123_col1" class="data row123 col1">AC Fand PACF Plot</td>
<td id="T_0a3cb_row123_col2" class="data row123 col2">Analyzes time series data using Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots to...</td>
<td id="T_0a3cb_row123_col3" class="data row123 col3">['dataset']</td>
<td id="T_0a3cb_row123_col4" class="data row123 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row124_col0" class="data row124 col0">validmind.data_validation.BivariateHistograms</td>
<td id="T_0a3cb_row124_col1" class="data row124 col1">Bivariate Histograms</td>
<td id="T_0a3cb_row124_col2" class="data row124 col2">Generates bivariate histograms for paired features, aiding in visual inspection of categorical variables'...</td>
<td id="T_0a3cb_row124_col3" class="data row124 col3">['dataset']</td>
<td id="T_0a3cb_row124_col4" class="data row124 col4">{'features_pairs': None, 'target_filter': None}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row125_col0" class="data row125 col0">validmind.data_validation.WOEBinTable</td>
<td id="T_0a3cb_row125_col1" class="data row125 col1">WOE Bin Table</td>
<td id="T_0a3cb_row125_col2" class="data row125 col2">Calculates and assesses the Weight of Evidence (WoE) and Information Value (IV) of each feature in a ML model....</td>
<td id="T_0a3cb_row125_col3" class="data row125 col3">['dataset']</td>
<td id="T_0a3cb_row125_col4" class="data row125 col4">{'breaks_adj': None}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row126_col0" class="data row126 col0">validmind.data_validation.HeatmapFeatureCorrelations</td>
<td id="T_0a3cb_row126_col1" class="data row126 col1">Heatmap Feature Correlations</td>
<td id="T_0a3cb_row126_col2" class="data row126 col2">Creates a heatmap to visually represent correlation patterns between pairs of numerical features in a dataset....</td>
<td id="T_0a3cb_row126_col3" class="data row126 col3">['dataset']</td>
<td id="T_0a3cb_row126_col4" class="data row126 col4">{'declutter': None, 'fontsize': None, 'num_features': None}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row127_col0" class="data row127 col0">validmind.data_validation.TimeSeriesFrequency</td>
<td id="T_0a3cb_row127_col1" class="data row127 col1">Time Series Frequency</td>
<td id="T_0a3cb_row127_col2" class="data row127 col2">Evaluates consistency of time series data frequency and generates a frequency plot....</td>
<td id="T_0a3cb_row127_col3" class="data row127 col3">['dataset']</td>
<td id="T_0a3cb_row127_col4" class="data row127 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row128_col0" class="data row128 col0">validmind.data_validation.DatasetSplit</td>
<td id="T_0a3cb_row128_col1" class="data row128 col1">Dataset Split</td>
<td id="T_0a3cb_row128_col2" class="data row128 col2">Evaluates and visualizes the distribution proportions among training, testing, and validation datasets of an ML...</td>
<td id="T_0a3cb_row128_col3" class="data row128 col3">['datasets']</td>
<td id="T_0a3cb_row128_col4" class="data row128 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row129_col0" class="data row129 col0">validmind.data_validation.SpreadPlot</td>
<td id="T_0a3cb_row129_col1" class="data row129 col1">Spread Plot</td>
<td id="T_0a3cb_row129_col2" class="data row129 col2">Visualizes the spread relationship between pairs of time-series variables in a dataset, thereby aiding in...</td>
<td id="T_0a3cb_row129_col3" class="data row129 col3">['dataset']</td>
<td id="T_0a3cb_row129_col4" class="data row129 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row130_col0" class="data row130 col0">validmind.data_validation.TimeSeriesLinePlot</td>
<td id="T_0a3cb_row130_col1" class="data row130 col1">Time Series Line Plot</td>
<td id="T_0a3cb_row130_col2" class="data row130 col2">Generates and analyses time-series data through line plots revealing trends, patterns, anomalies over time....</td>
<td id="T_0a3cb_row130_col3" class="data row130 col3">['dataset']</td>
<td id="T_0a3cb_row130_col4" class="data row130 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row131_col0" class="data row131 col0">validmind.data_validation.KPSS</td>
<td id="T_0a3cb_row131_col1" class="data row131 col1">KPSS</td>
<td id="T_0a3cb_row131_col2" class="data row131 col2">Executes KPSS unit root test to validate stationarity of time-series data in machine learning model....</td>
<td id="T_0a3cb_row131_col3" class="data row131 col3">['dataset']</td>
<td id="T_0a3cb_row131_col4" class="data row131 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row132_col0" class="data row132 col0">validmind.data_validation.AutoSeasonality</td>
<td id="T_0a3cb_row132_col1" class="data row132 col1">Auto Seasonality</td>
<td id="T_0a3cb_row132_col2" class="data row132 col2">Automatically identifies and quantifies optimal seasonality in time series data to improve forecasting model...</td>
<td id="T_0a3cb_row132_col3" class="data row132 col3">['dataset']</td>
<td id="T_0a3cb_row132_col4" class="data row132 col4">{'min_period': 1, 'max_period': 4}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row133_col0" class="data row133 col0">validmind.data_validation.BivariateScatterPlots</td>
<td id="T_0a3cb_row133_col1" class="data row133 col1">Bivariate Scatter Plots</td>
<td id="T_0a3cb_row133_col2" class="data row133 col2">Generates bivariate scatterplots to visually inspect relationships between pairs of predictor variables in machine...</td>
<td id="T_0a3cb_row133_col3" class="data row133 col3">['dataset']</td>
<td id="T_0a3cb_row133_col4" class="data row133 col4">{'selected_columns': None}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row134_col0" class="data row134 col0">validmind.data_validation.EngleGrangerCoint</td>
<td id="T_0a3cb_row134_col1" class="data row134 col1">Engle Granger Coint</td>
<td id="T_0a3cb_row134_col2" class="data row134 col2">Validates co-integration in pairs of time series data using the Engle-Granger test and classifies them as...</td>
<td id="T_0a3cb_row134_col3" class="data row134 col3">['dataset']</td>
<td id="T_0a3cb_row134_col4" class="data row134 col4">{'threshold': 0.05}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row135_col0" class="data row135 col0">validmind.data_validation.TimeSeriesMissingValues</td>
<td id="T_0a3cb_row135_col1" class="data row135 col1">Time Series Missing Values</td>
<td id="T_0a3cb_row135_col2" class="data row135 col2">Validates time-series data quality by confirming the count of missing values is below a certain threshold....</td>
<td id="T_0a3cb_row135_col3" class="data row135 col3">['dataset']</td>
<td id="T_0a3cb_row135_col4" class="data row135 col4">{'min_threshold': 1}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row136_col0" class="data row136 col0">validmind.data_validation.TimeSeriesHistogram</td>
<td id="T_0a3cb_row136_col1" class="data row136 col1">Time Series Histogram</td>
<td id="T_0a3cb_row136_col2" class="data row136 col2">Visualizes distribution of time-series data using histograms and Kernel Density Estimation (KDE) lines....</td>
<td id="T_0a3cb_row136_col3" class="data row136 col3">['dataset']</td>
<td id="T_0a3cb_row136_col4" class="data row136 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row137_col0" class="data row137 col0">validmind.data_validation.LaggedCorrelationHeatmap</td>
<td id="T_0a3cb_row137_col1" class="data row137 col1">Lagged Correlation Heatmap</td>
<td id="T_0a3cb_row137_col2" class="data row137 col2">Assesses and visualizes correlation between target variable and lagged independent variables in a time-series...</td>
<td id="T_0a3cb_row137_col3" class="data row137 col3">['dataset']</td>
<td id="T_0a3cb_row137_col4" class="data row137 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row138_col0" class="data row138 col0">validmind.data_validation.SeasonalDecompose</td>
<td id="T_0a3cb_row138_col1" class="data row138 col1">Seasonal Decompose</td>
<td id="T_0a3cb_row138_col2" class="data row138 col2">Decomposes dataset features into observed, trend, seasonal, and residual components to identify patterns and...</td>
<td id="T_0a3cb_row138_col3" class="data row138 col3">['dataset']</td>
<td id="T_0a3cb_row138_col4" class="data row138 col4">{'seasonal_model': 'additive'}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row139_col0" class="data row139 col0">validmind.data_validation.WOEBinPlots</td>
<td id="T_0a3cb_row139_col1" class="data row139 col1">WOE Bin Plots</td>
<td id="T_0a3cb_row139_col2" class="data row139 col2">Generates visualizations of Weight of Evidence (WoE) and Information Value (IV) for understanding predictive power...</td>
<td id="T_0a3cb_row139_col3" class="data row139 col3">['dataset']</td>
<td id="T_0a3cb_row139_col4" class="data row139 col4">{'breaks_adj': None, 'fig_height': 600, 'fig_width': 500}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row140_col0" class="data row140 col0">validmind.data_validation.ClassImbalance</td>
<td id="T_0a3cb_row140_col1" class="data row140 col1">Class Imbalance</td>
<td id="T_0a3cb_row140_col2" class="data row140 col2">Evaluates and quantifies class distribution imbalance in a dataset used by a machine learning model....</td>
<td id="T_0a3cb_row140_col3" class="data row140 col3">['dataset']</td>
<td id="T_0a3cb_row140_col4" class="data row140 col4">{'min_percent_threshold': 10}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row141_col0" class="data row141 col0">validmind.data_validation.IQROutliersBarPlot</td>
<td id="T_0a3cb_row141_col1" class="data row141 col1">IQR Outliers Bar Plot</td>
<td id="T_0a3cb_row141_col2" class="data row141 col2">Visualizes outlier distribution across percentiles in numerical data using Interquartile Range (IQR) method....</td>
<td id="T_0a3cb_row141_col3" class="data row141 col3">['dataset']</td>
<td id="T_0a3cb_row141_col4" class="data row141 col4">{'threshold': 1.5, 'num_features': None, 'fig_width': 800}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row142_col0" class="data row142 col0">validmind.data_validation.DFGLSArch</td>
<td id="T_0a3cb_row142_col1" class="data row142 col1">DFGLS Arch</td>
<td id="T_0a3cb_row142_col2" class="data row142 col2">Executes Dickey-Fuller GLS metric to determine order of integration and check stationarity in time series data....</td>
<td id="T_0a3cb_row142_col3" class="data row142 col3">['dataset']</td>
<td id="T_0a3cb_row142_col4" class="data row142 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row143_col0" class="data row143 col0">validmind.data_validation.AutoAR</td>
<td id="T_0a3cb_row143_col1" class="data row143 col1">Auto AR</td>
<td id="T_0a3cb_row143_col2" class="data row143 col2">Automatically identifies the optimal Autoregressive (AR) order for a time series using BIC and AIC criteria....</td>
<td id="T_0a3cb_row143_col3" class="data row143 col3">['dataset']</td>
<td id="T_0a3cb_row143_col4" class="data row143 col4">{'max_ar_order': 3}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row144_col0" class="data row144 col0">validmind.data_validation.TabularDateTimeHistograms</td>
<td id="T_0a3cb_row144_col1" class="data row144 col1">Tabular Date Time Histograms</td>
<td id="T_0a3cb_row144_col2" class="data row144 col2">Generates histograms to provide graphical insight into the distribution of time intervals in model's datetime data....</td>
<td id="T_0a3cb_row144_col3" class="data row144 col3">['dataset']</td>
<td id="T_0a3cb_row144_col4" class="data row144 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row145_col0" class="data row145 col0">validmind.data_validation.ADF</td>
<td id="T_0a3cb_row145_col1" class="data row145 col1">ADF</td>
<td id="T_0a3cb_row145_col2" class="data row145 col2">Assesses the stationarity of a time series dataset using the Augmented Dickey-Fuller (ADF) test....</td>
<td id="T_0a3cb_row145_col3" class="data row145 col3">['dataset']</td>
<td id="T_0a3cb_row145_col4" class="data row145 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row146_col0" class="data row146 col0">validmind.data_validation.nlp.Toxicity</td>
<td id="T_0a3cb_row146_col1" class="data row146 col1">Toxicity</td>
<td id="T_0a3cb_row146_col2" class="data row146 col2">Analyzes the toxicity of text data within a dataset using a pre-trained toxicity model....</td>
<td id="T_0a3cb_row146_col3" class="data row146 col3">['dataset']</td>
<td id="T_0a3cb_row146_col4" class="data row146 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row147_col0" class="data row147 col0">validmind.data_validation.nlp.PolarityAndSubjectivity</td>
<td id="T_0a3cb_row147_col1" class="data row147 col1">Polarity And Subjectivity</td>
<td id="T_0a3cb_row147_col2" class="data row147 col2">Analyzes the polarity and subjectivity of text data within a dataset....</td>
<td id="T_0a3cb_row147_col3" class="data row147 col3">['dataset']</td>
<td id="T_0a3cb_row147_col4" class="data row147 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row148_col0" class="data row148 col0">validmind.data_validation.nlp.Punctuations</td>
<td id="T_0a3cb_row148_col1" class="data row148 col1">Punctuations</td>
<td id="T_0a3cb_row148_col2" class="data row148 col2">Analyzes and visualizes the frequency distribution of punctuation usage in a given text dataset....</td>
<td id="T_0a3cb_row148_col3" class="data row148 col3">['dataset']</td>
<td id="T_0a3cb_row148_col4" class="data row148 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row149_col0" class="data row149 col0">validmind.data_validation.nlp.Sentiment</td>
<td id="T_0a3cb_row149_col1" class="data row149 col1">Sentiment</td>
<td id="T_0a3cb_row149_col2" class="data row149 col2">Analyzes the sentiment of text data within a dataset using the VADER sentiment analysis tool....</td>
<td id="T_0a3cb_row149_col3" class="data row149 col3">['dataset']</td>
<td id="T_0a3cb_row149_col4" class="data row149 col4">{}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row150_col0" class="data row150 col0">validmind.data_validation.nlp.CommonWords</td>
<td id="T_0a3cb_row150_col1" class="data row150 col1">Common Words</td>
<td id="T_0a3cb_row150_col2" class="data row150 col2">Identifies and visualizes the 40 most frequent non-stopwords in a specified text column within a dataset....</td>
<td id="T_0a3cb_row150_col3" class="data row150 col3">['dataset']</td>
<td id="T_0a3cb_row150_col4" class="data row150 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row151_col0" class="data row151 col0">validmind.data_validation.nlp.Hashtags</td>
<td id="T_0a3cb_row151_col1" class="data row151 col1">Hashtags</td>
<td id="T_0a3cb_row151_col2" class="data row151 col2">Assesses hashtag frequency in a text column, highlighting usage trends and potential dataset bias or spam....</td>
<td id="T_0a3cb_row151_col3" class="data row151 col3">['dataset']</td>
<td id="T_0a3cb_row151_col4" class="data row151 col4">{'top_hashtags': 25}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row152_col0" class="data row152 col0">validmind.data_validation.nlp.LanguageDetection</td>
<td id="T_0a3cb_row152_col1" class="data row152 col1">Language Detection</td>
<td id="T_0a3cb_row152_col2" class="data row152 col2">Detects the language of each text entry in a dataset and visualizes the distribution of languages...</td>
<td id="T_0a3cb_row152_col3" class="data row152 col3">['dataset']</td>
<td id="T_0a3cb_row152_col4" class="data row152 col4">{}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row153_col0" class="data row153 col0">validmind.data_validation.nlp.Mentions</td>
<td id="T_0a3cb_row153_col1" class="data row153 col1">Mentions</td>
<td id="T_0a3cb_row153_col2" class="data row153 col2">Calculates and visualizes frequencies of '@' prefixed mentions in a text-based dataset for NLP model analysis....</td>
<td id="T_0a3cb_row153_col3" class="data row153 col3">['dataset']</td>
<td id="T_0a3cb_row153_col4" class="data row153 col4">{'top_mentions': 25}</td>
</tr>
<tr class="odd">
<td id="T_0a3cb_row154_col0" class="data row154 col0">validmind.data_validation.nlp.TextDescription</td>
<td id="T_0a3cb_row154_col1" class="data row154 col1">Text Description</td>
<td id="T_0a3cb_row154_col2" class="data row154 col2">Performs comprehensive textual analysis on a dataset using NLTK, evaluating various parameters and generating...</td>
<td id="T_0a3cb_row154_col3" class="data row154 col3">['dataset']</td>
<td id="T_0a3cb_row154_col4" class="data row154 col4">{'unwanted_tokens': {'s', 'us', 'dollar', "''", 'ms', "s'", 'mr', ' ', "'s", '``', 'mrs', 'dr'}, 'num_top_words': 3, 'lang': 'english'}</td>
</tr>
<tr class="even">
<td id="T_0a3cb_row155_col0" class="data row155 col0">validmind.data_validation.nlp.StopWords</td>
<td id="T_0a3cb_row155_col1" class="data row155 col1">Stop Words</td>
<td id="T_0a3cb_row155_col2" class="data row155 col2">Evaluates and visualizes the frequency of English stop words in a text dataset against a defined threshold....</td>
<td id="T_0a3cb_row155_col3" class="data row155 col3">['dataset']</td>
<td id="T_0a3cb_row155_col4" class="data row155 col4">{'min_percent_threshold': 0.5, 'num_words': 25}</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><a id="toc5_"></a></p>
</section>
</section>
<section id="start-the-model-development-process-with-raw-data-run-out-of-the-box-tests-and-add-evidence-to-model-documentation" class="level2">
<h2 class="anchored" data-anchor-id="start-the-model-development-process-with-raw-data-run-out-of-the-box-tests-and-add-evidence-to-model-documentation">2. Start the model development process with raw data, run out-of-the box tests, and add evidence to model documentation</h2>
<p>In this section you learn how to explore the individual tests available in ValidMind and how to run them and change parameters as necessary. You will use a public dataset from Kaggle that models a bank customer churn prediction use case. The target column, <code>Exited</code> has a value of <code>1</code> when a customer has churned and <code>0</code> otherwise.</p>
<p>You can find more information about this dataset <a href="https://www.kaggle.com/datasets/shantanudhakadd/bank-customer-churn-prediction">here</a>.</p>
<p>The ValidMind Developer Framework provides a wrapper to automatically load the dataset as a Pandas DataFrame object.</p>
<div id="cell-14" class="cell" data-metadata="{}" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> validmind.datasets.classification <span class="im">import</span> customer_churn <span class="im">as</span> demo_dataset</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f"Loaded demo dataset with: </span><span class="ch">\n\n\t</span><span class="ss">• Target column: '</span><span class="sc">{</span>demo_dataset<span class="sc">.</span>target_column<span class="sc">}</span><span class="ss">' </span><span class="ch">\n\t</span><span class="ss">• Class labels: </span><span class="sc">{</span>demo_dataset<span class="sc">.</span>class_labels<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>raw_df <span class="op">=</span> demo_dataset.load_data()</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>raw_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loaded demo dataset with: 

    • Target column: 'Exited' 
    • Class labels: {'0': 'Did not exit', '1': 'Exited'}</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CreditScore</th>
<th data-quarto-table-cell-role="th">Geography</th>
<th data-quarto-table-cell-role="th">Gender</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Tenure</th>
<th data-quarto-table-cell-role="th">Balance</th>
<th data-quarto-table-cell-role="th">NumOfProducts</th>
<th data-quarto-table-cell-role="th">HasCrCard</th>
<th data-quarto-table-cell-role="th">IsActiveMember</th>
<th data-quarto-table-cell-role="th">EstimatedSalary</th>
<th data-quarto-table-cell-role="th">Exited</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>619</td>
<td>France</td>
<td>Female</td>
<td>42</td>
<td>2</td>
<td>0.00</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>101348.88</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>608</td>
<td>Spain</td>
<td>Female</td>
<td>41</td>
<td>1</td>
<td>83807.86</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>112542.58</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>502</td>
<td>France</td>
<td>Female</td>
<td>42</td>
<td>8</td>
<td>159660.80</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>113931.57</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>699</td>
<td>France</td>
<td>Female</td>
<td>39</td>
<td>1</td>
<td>0.00</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>93826.63</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>850</td>
<td>Spain</td>
<td>Female</td>
<td>43</td>
<td>2</td>
<td>125510.82</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>79084.10</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Let’s do some data quality assessments by running a few individual tests related to data assessment. You will use the <code>vm.tests.list_tests()</code> function introduced above in combination with <code>vm.tests.list_tags()</code> and <code>vm.tests.list_task_types()</code> to find which prebuilt tests are relevant for data quality assessment.</p>
<div id="cell-16" class="cell" data-metadata="{}" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the list of available tags</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">sorted</span>(vm.tests.list_tags())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>['AUC',
 'anomaly_detection',
 'binary_classification',
 'categorical_data',
 'correlation',
 'credit_risk',
 'data_distribution',
 'data_quality',
 'data_validation',
 'dimensionality_reduction',
 'embeddings',
 'feature_importance',
 'few_shot',
 'forecasting',
 'frequency_analysis',
 'kmeans',
 'llm',
 'logistic_regression',
 'model_comparison',
 'model_diagnosis',
 'model_interpretation',
 'model_metadata',
 'model_performance',
 'model_selection',
 'multiclass_classification',
 'nlp',
 'numerical_data',
 'qualitative',
 'rag_performance',
 'ragas',
 'retrieval_performance',
 'risk_analysis',
 'seasonality',
 'senstivity_analysis',
 'sklearn',
 'stationarity',
 'statistical_test',
 'statsmodels',
 'tabular_data',
 'text_data',
 'text_embeddings',
 'time_series_data',
 'unit_root_test',
 'visualization',
 'zero_shot']</code></pre>
</div>
</div>
<div id="cell-17" class="cell" data-metadata="{}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the list of available task types</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">sorted</span>(vm.tests.list_task_types())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>['classification',
 'clustering',
 'feature_extraction',
 'nlp',
 'regression',
 'text_classification',
 'text_generation',
 'text_qa',
 'text_summarization']</code></pre>
</div>
</div>
<p>You can pass <code>tags</code> and <code>task_types</code> as parameters to the <code>vm.tests.list_tests()</code> function to filter the tests based on the tags and task types. For example, to find tests related to tabular data quality for classification models, you can call <code>list_tests()</code> like this:</p>
<div id="cell-19" class="cell" data-metadata="{}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>vm.tests.list_tests(task<span class="op">=</span><span class="st">"classification"</span>, tags<span class="op">=</span>[<span class="st">"tabular_data"</span>, <span class="st">"data_quality"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<style type="text/css">
#T_a081a th {
  text-align: left;
}
#T_a081a_row0_col0, #T_a081a_row0_col1, #T_a081a_row0_col2, #T_a081a_row0_col3, #T_a081a_row0_col4, #T_a081a_row1_col0, #T_a081a_row1_col1, #T_a081a_row1_col2, #T_a081a_row1_col3, #T_a081a_row1_col4, #T_a081a_row2_col0, #T_a081a_row2_col1, #T_a081a_row2_col2, #T_a081a_row2_col3, #T_a081a_row2_col4, #T_a081a_row3_col0, #T_a081a_row3_col1, #T_a081a_row3_col2, #T_a081a_row3_col3, #T_a081a_row3_col4, #T_a081a_row4_col0, #T_a081a_row4_col1, #T_a081a_row4_col2, #T_a081a_row4_col3, #T_a081a_row4_col4, #T_a081a_row5_col0, #T_a081a_row5_col1, #T_a081a_row5_col2, #T_a081a_row5_col3, #T_a081a_row5_col4, #T_a081a_row6_col0, #T_a081a_row6_col1, #T_a081a_row6_col2, #T_a081a_row6_col3, #T_a081a_row6_col4 {
  text-align: left;
}
</style>

<table id="T_a081a" class="caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th id="T_a081a_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">ID</th>
<th id="T_a081a_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">Name</th>
<th id="T_a081a_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">Description</th>
<th id="T_a081a_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">Required Inputs</th>
<th id="T_a081a_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">Params</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_a081a_row0_col0" class="data row0 col0">validmind.data_validation.MissingValuesRisk</td>
<td id="T_a081a_row0_col1" class="data row0 col1">Missing Values Risk</td>
<td id="T_a081a_row0_col2" class="data row0 col2">Assesses and quantifies the risk related to missing values in a dataset used for training an ML model....</td>
<td id="T_a081a_row0_col3" class="data row0 col3">['dataset']</td>
<td id="T_a081a_row0_col4" class="data row0 col4">{}</td>
</tr>
<tr class="even">
<td id="T_a081a_row1_col0" class="data row1 col0">validmind.data_validation.Skewness</td>
<td id="T_a081a_row1_col1" class="data row1 col1">Skewness</td>
<td id="T_a081a_row1_col2" class="data row1 col2">Evaluates the skewness of numerical data in a machine learning model and checks if it falls below a set maximum...</td>
<td id="T_a081a_row1_col3" class="data row1 col3">['dataset']</td>
<td id="T_a081a_row1_col4" class="data row1 col4">{'max_threshold': 1}</td>
</tr>
<tr class="odd">
<td id="T_a081a_row2_col0" class="data row2 col0">validmind.data_validation.Duplicates</td>
<td id="T_a081a_row2_col1" class="data row2 col1">Duplicates</td>
<td id="T_a081a_row2_col2" class="data row2 col2">Tests dataset for duplicate entries, ensuring model reliability via data quality verification....</td>
<td id="T_a081a_row2_col3" class="data row2 col3">['dataset']</td>
<td id="T_a081a_row2_col4" class="data row2 col4">{'min_threshold': 1}</td>
</tr>
<tr class="even">
<td id="T_a081a_row3_col0" class="data row3 col0">validmind.data_validation.MissingValuesBarPlot</td>
<td id="T_a081a_row3_col1" class="data row3 col1">Missing Values Bar Plot</td>
<td id="T_a081a_row3_col2" class="data row3 col2">Creates a bar plot showcasing the percentage of missing values in each column of the dataset with risk...</td>
<td id="T_a081a_row3_col3" class="data row3 col3">['dataset']</td>
<td id="T_a081a_row3_col4" class="data row3 col4">{'threshold': 80, 'fig_height': 600}</td>
</tr>
<tr class="odd">
<td id="T_a081a_row4_col0" class="data row4 col0">validmind.data_validation.HighCardinality</td>
<td id="T_a081a_row4_col1" class="data row4 col1">High Cardinality</td>
<td id="T_a081a_row4_col2" class="data row4 col2">Assesses the number of unique values in categorical columns to detect high cardinality and potential overfitting....</td>
<td id="T_a081a_row4_col3" class="data row4 col3">['dataset']</td>
<td id="T_a081a_row4_col4" class="data row4 col4">{'num_threshold': 100, 'percent_threshold': 0.1, 'threshold_type': 'percent'}</td>
</tr>
<tr class="even">
<td id="T_a081a_row5_col0" class="data row5 col0">validmind.data_validation.MissingValues</td>
<td id="T_a081a_row5_col1" class="data row5 col1">Missing Values</td>
<td id="T_a081a_row5_col2" class="data row5 col2">Evaluates dataset quality by ensuring missing value ratio across all features does not exceed a set threshold....</td>
<td id="T_a081a_row5_col3" class="data row5 col3">['dataset']</td>
<td id="T_a081a_row5_col4" class="data row5 col4">{'min_threshold': 1}</td>
</tr>
<tr class="odd">
<td id="T_a081a_row6_col0" class="data row6 col0">validmind.data_validation.HighPearsonCorrelation</td>
<td id="T_a081a_row6_col1" class="data row6 col1">High Pearson Correlation</td>
<td id="T_a081a_row6_col2" class="data row6 col2">Identifies highly correlated feature pairs in a dataset suggesting feature redundancy or multicollinearity....</td>
<td id="T_a081a_row6_col3" class="data row6 col3">['dataset']</td>
<td id="T_a081a_row6_col4" class="data row6 col4">{'max_threshold': 0.3}</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><a id="toc5_1_"></a></p>
<section id="initialize-the-validmind-datasets" class="level3">
<h3 class="anchored" data-anchor-id="initialize-the-validmind-datasets">Initialize the ValidMind datasets</h3>
<p>Now, assume we have identified some tests we want to run with regards to the data we are intending to use. The next step is to connect your data with a ValidMind <code>Dataset</code> object. This step is always necessary every time you want to connect a dataset to documentation and produce test results through ValidMind. You only need to do it one time per dataset.</p>
<p>You can initialize a ValidMind dataset object using the <a href="https://docs.validmind.ai/validmind/validmind.html#init_dataset"><code>init_dataset</code></a> function from the ValidMind (<code>vm</code>) module.</p>
<p>This function takes a number of arguments:</p>
<ul>
<li><code>dataset</code> — the raw dataset that you want to provide as input to tests</li>
<li><code>input_id</code> - a unique identifier that allows tracking what inputs are used when running each individual test</li>
<li><code>target_column</code> —&nbsp;a required argument if tests require access to true values. This is the name of the target column in the dataset</li>
</ul>
<div id="cell-21" class="cell" data-metadata="{}" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># vm_raw_dataset is now a VMDataset object that you can pass to any ValidMind test</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>vm_raw_dataset <span class="op">=</span> vm.init_dataset(</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>raw_df,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    input_id<span class="op">=</span><span class="st">"raw_dataset"</span>,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    target_column<span class="op">=</span><span class="st">"Exited"</span>,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-06-12 16:27:26,055 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...</code></pre>
</div>
</div>
<p><a id="toc5_2_"></a></p>
</section>
<section id="run-some-tabular-data-tests" class="level3">
<h3 class="anchored" data-anchor-id="run-some-tabular-data-tests">Run some tabular data tests</h3>
<p>Individual tests can be easily run by calling the <code>run_test</code> function provided by the <code>validmind.tests</code> module. The function takes the following arguments:</p>
<ul>
<li><code>test_id</code>: The ID of the test to run. To find a particular test and get its ID, refer to the <a href="../../notebooks/how_to/explore_tests.html">explore_tests</a> notebook. Look above for example after running ‘vm.test_suites.describe_suite’ as column ‘Test ID’ will contain the id.</li>
<li><code>params</code>: A dictionary of parameters for the test. These will override any <code>default_params</code> set in the test definition. Refer to the <a href="../../notebooks/how_to/explore_tests.html">explore_tests</a> notebook to find the default parameters for a test. See below for examples.</li>
</ul>
<p>The inputs expected by a test can also be found in the test definition. Let’s take <code>validmind.data_validation.DescriptiveStatistics</code> as an example. Note that the output of the <code>describe_test()</code> function below shows that this test expects a <code>dataset</code> as input:</p>
<div id="cell-23" class="cell" data-metadata="{}" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>vm.tests.describe_test(<span class="st">"validmind.data_validation.DescriptiveStatistics"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d9ed211c76a243568270c8769700f415","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p>Now, let’s run a few tests to assess the quality of the dataset.</p>
<div id="cell-25" class="cell" data-metadata="{}" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> vm.tests.run_test(</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    test_id<span class="op">=</span><span class="st">"validmind.data_validation.DescriptiveStatistics"</span>,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{<span class="st">"dataset"</span>: vm_raw_dataset},</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"88d636ab0e174737bbac86dde4c74ad7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<div id="cell-26" class="cell" data-metadata="{}" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>test2 <span class="op">=</span> vm.tests.run_test(</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    test_id<span class="op">=</span><span class="st">"validmind.data_validation.ClassImbalance"</span>,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{<span class="st">"dataset"</span>: vm_raw_dataset},</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>{<span class="st">"min_percent_threshold"</span>: <span class="dv">30</span>},</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c41b03e439ab4c09bb629f2f66c4b582","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p>You can see that the class imbalance test did not pass according to the value of <code>min_percent_threshold</code> we have set. Here is how you can re-run the test on some processed data to address this data quality issue. In this case we apply a very simple rebalancing technique to the dataset.</p>
<div id="cell-28" class="cell" data-metadata="{}" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>raw_copy_df <span class="op">=</span> raw_df.sample(frac<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Create a copy of the raw dataset</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a balanced dataset with the same number of exited and not exited customers</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>exited_df <span class="op">=</span> raw_copy_df.loc[raw_copy_df[<span class="st">"Exited"</span>] <span class="op">==</span> <span class="dv">1</span>]</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>not_exited_df <span class="op">=</span> raw_copy_df.loc[raw_copy_df[<span class="st">"Exited"</span>] <span class="op">==</span> <span class="dv">0</span>].sample(n<span class="op">=</span>exited_df.shape[<span class="dv">0</span>])</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>balanced_raw_df <span class="op">=</span> pd.concat([exited_df, not_exited_df])</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>balanced_raw_df <span class="op">=</span> balanced_raw_df.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With this new raw dataset, you can re-run the individual test to see if it passes the class imbalance test requirement. Remember to register new VM Dataset object since that is the type of input required by <code>run_test()</code>:</p>
<div id="cell-30" class="cell" data-metadata="{}" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Register new data and now 'balanced_raw_dataset' is the new dataset object of interest</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>vm_balanced_raw_dataset <span class="op">=</span> vm.init_dataset(</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>balanced_raw_df,</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    input_id<span class="op">=</span><span class="st">"balanced_raw_dataset"</span>,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    target_column<span class="op">=</span><span class="st">"Exited"</span>,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-06-12 16:27:27,909 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...</code></pre>
</div>
</div>
<div id="cell-31" class="cell" data-metadata="{}" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> vm.tests.run_test(</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    test_id<span class="op">=</span><span class="st">"validmind.data_validation.ClassImbalance"</span>,</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{<span class="st">"dataset"</span>: vm_balanced_raw_dataset},</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>{<span class="st">"min_percent_threshold"</span>: <span class="dv">30</span>},</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c8c1d99da50743f4ad54bafdd0cfc735","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p><a id="toc5_3_"></a></p>
</section>
<section id="utilize-test-output" class="level3">
<h3 class="anchored" data-anchor-id="utilize-test-output">Utilize test output</h3>
<p>Here is an example for how you can utilize the output from a ValidMind test for futher use, for example, if you want to remove highly correlated features. The example below shows how you can get the list of features with the highest correlation coefficients and use them to reduce the final list of features for modeling.</p>
<div id="cell-33" class="cell" data-metadata="{}" data-execution_count="16">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>corr_results <span class="op">=</span> vm.tests.run_test(</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    test_id<span class="op">=</span><span class="st">"validmind.data_validation.HighPearsonCorrelation"</span>,</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>{<span class="st">"max_threshold"</span>: <span class="fl">0.3</span>},</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{<span class="st">"dataset"</span>: vm_balanced_raw_dataset},</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a49b5aac778c4125bd6e01d565682ce9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p>Let’s assume we want to remove highly correlated features from the dataset. <code>corr_results</code> is an object of type <code>ThresholdTestResult</code> and we can inspects its individual <code>results</code> to get access to the features that failed the test. In general, all ValidMind tests can return two different types of results:</p>
<ul>
<li><a href="https://docs.validmind.ai/validmind/validmind/vm_models.html#MetricResult">MetricResult</a>: most tests return this type of result</li>
<li><a href="https://docs.validmind.ai/validmind/validmind/vm_models.html#ThresholdTest">ThresholdTestResult</a>: tests that compare a result to a threshold return this type of result</li>
</ul>
<div id="cell-35" class="cell" data-metadata="{}" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(corr_results.test_results)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"test_name: "</span>, corr_results.test_results.test_name)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"params: "</span>, corr_results.test_results.params)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"passed: "</span>, corr_results.test_results.passed)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"results: "</span>, corr_results.test_results.results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>ThresholdTestResults(test_name='validmind.data_validation.HighPearsonCorrelation', ref_id='66fcfd3b-d667-4a2c-a7f6-77bfebb5f6d0', params={'max_threshold': 0.3}, passed=False, results=[ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.32987190055041904}]}, test_name=None, column='Age', passed=False), ThresholdTestResult(values={'correlations': [{'column': 'IsActiveMember', 'correlation': -0.17699859336197596}]}, test_name=None, column='Exited', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.1728217891792664}]}, test_name=None, column='Balance', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.13965229528493148}]}, test_name=None, column='Balance', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.053514484820855523}]}, test_name=None, column='Exited', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.049416957601124856}]}, test_name=None, column='Age', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'EstimatedSalary', 'correlation': -0.048324129258115286}]}, test_name=None, column='CreditScore', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'HasCrCard', 'correlation': -0.045178201261452694}]}, test_name=None, column='Balance', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': 0.041301422736705}]}, test_name=None, column='IsActiveMember', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'Tenure', 'correlation': -0.03729272232434623}]}, test_name=None, column='IsActiveMember', passed=True)], summary=ResultSummary(results=[ResultTable(data=[{'Columns': '(Age, Exited)', 'Coefficient': 0.32987190055041904, 'Pass/Fail': 'Fail'}, {'Columns': '(Exited, IsActiveMember)', 'Coefficient': -0.17699859336197596, 'Pass/Fail': 'Pass'}, {'Columns': '(Balance, NumOfProducts)', 'Coefficient': -0.1728217891792664, 'Pass/Fail': 'Pass'}, {'Columns': '(Balance, Exited)', 'Coefficient': 0.13965229528493148, 'Pass/Fail': 'Pass'}, {'Columns': '(Exited, NumOfProducts)', 'Coefficient': -0.053514484820855523, 'Pass/Fail': 'Pass'}, {'Columns': '(Age, NumOfProducts)', 'Coefficient': -0.049416957601124856, 'Pass/Fail': 'Pass'}, {'Columns': '(CreditScore, EstimatedSalary)', 'Coefficient': -0.048324129258115286, 'Pass/Fail': 'Pass'}, {'Columns': '(Balance, HasCrCard)', 'Coefficient': -0.045178201261452694, 'Pass/Fail': 'Pass'}, {'Columns': '(IsActiveMember, NumOfProducts)', 'Coefficient': 0.041301422736705, 'Pass/Fail': 'Pass'}, {'Columns': '(IsActiveMember, Tenure)', 'Coefficient': -0.03729272232434623, 'Pass/Fail': 'Pass'}], type='table', metadata=ResultTableMetadata(title='High Pearson Correlation Results for Dataset'))]))
test_name:  validmind.data_validation.HighPearsonCorrelation
params:  {'max_threshold': 0.3}
passed:  False
results:  [ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.32987190055041904}]}, test_name=None, column='Age', passed=False), ThresholdTestResult(values={'correlations': [{'column': 'IsActiveMember', 'correlation': -0.17699859336197596}]}, test_name=None, column='Exited', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.1728217891792664}]}, test_name=None, column='Balance', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.13965229528493148}]}, test_name=None, column='Balance', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.053514484820855523}]}, test_name=None, column='Exited', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.049416957601124856}]}, test_name=None, column='Age', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'EstimatedSalary', 'correlation': -0.048324129258115286}]}, test_name=None, column='CreditScore', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'HasCrCard', 'correlation': -0.045178201261452694}]}, test_name=None, column='Balance', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': 0.041301422736705}]}, test_name=None, column='IsActiveMember', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'Tenure', 'correlation': -0.03729272232434623}]}, test_name=None, column='IsActiveMember', passed=True)]</code></pre>
</div>
</div>
<p>Let’s inspect the <code>results</code> and extract a list of features that failed the test:</p>
<div id="cell-37" class="cell" data-metadata="{}" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>corr_results.test_results.results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>[ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.32987190055041904}]}, test_name=None, column='Age', passed=False),
 ThresholdTestResult(values={'correlations': [{'column': 'IsActiveMember', 'correlation': -0.17699859336197596}]}, test_name=None, column='Exited', passed=True),
 ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.1728217891792664}]}, test_name=None, column='Balance', passed=True),
 ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.13965229528493148}]}, test_name=None, column='Balance', passed=True),
 ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.053514484820855523}]}, test_name=None, column='Exited', passed=True),
 ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.049416957601124856}]}, test_name=None, column='Age', passed=True),
 ThresholdTestResult(values={'correlations': [{'column': 'EstimatedSalary', 'correlation': -0.048324129258115286}]}, test_name=None, column='CreditScore', passed=True),
 ThresholdTestResult(values={'correlations': [{'column': 'HasCrCard', 'correlation': -0.045178201261452694}]}, test_name=None, column='Balance', passed=True),
 ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': 0.041301422736705}]}, test_name=None, column='IsActiveMember', passed=True),
 ThresholdTestResult(values={'correlations': [{'column': 'Tenure', 'correlation': -0.03729272232434623}]}, test_name=None, column='IsActiveMember', passed=True)]</code></pre>
</div>
</div>
<p>Remove the highly correlated features and create a new VM dataset object. Note the use of different <code>input_id</code>s. This allows tracking the inputs used when running each individual test.</p>
<div id="cell-39" class="cell" data-metadata="{}" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>high_correlation_features <span class="op">=</span> [</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    result.column</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> result <span class="kw">in</span> corr_results.test_results.results</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> result.passed <span class="op">==</span> <span class="va">False</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>high_correlation_features</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>['Age']</code></pre>
</div>
</div>
<div id="cell-40" class="cell" data-metadata="{}" data-execution_count="20">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the highly correlated features from the dataset</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>balanced_raw_no_age_df <span class="op">=</span> balanced_raw_df.drop(columns<span class="op">=</span>high_correlation_features)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-initialize the dataset object</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>vm_raw_dataset_preprocessed <span class="op">=</span> vm.init_dataset(</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>balanced_raw_no_age_df,</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    input_id<span class="op">=</span><span class="st">"raw_dataset_preprocessed"</span>,</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    target_column<span class="op">=</span><span class="st">"Exited"</span>,</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-06-12 16:27:28,764 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...</code></pre>
</div>
</div>
<p>Re-running the test with the reduced feature set should pass the test. You can also plot the correlation matrix to visualize the new correlation between features:</p>
<div id="cell-42" class="cell" data-metadata="{}" data-execution_count="21">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>corr_results <span class="op">=</span> vm.tests.run_test(</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    test_id<span class="op">=</span><span class="st">"validmind.data_validation.HighPearsonCorrelation"</span>,</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>{<span class="st">"max_threshold"</span>: <span class="fl">0.3</span>},</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{<span class="st">"dataset"</span>: vm_raw_dataset_preprocessed},</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a5ced0bf416544c9ac54ebde019cddab","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<div id="cell-43" class="cell" data-metadata="{}" data-execution_count="22">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>corr_results <span class="op">=</span> vm.tests.run_test(</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    test_id<span class="op">=</span><span class="st">"validmind.data_validation.PearsonCorrelationMatrix"</span>,</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{<span class="st">"dataset"</span>: vm_raw_dataset_preprocessed},</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"82b562c70488422ca8b610c495f53abe","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p><a id="toc5_4_"></a></p>
</section>
<section id="documenting-the-results-based-on-two-datasets" class="level3">
<h3 class="anchored" data-anchor-id="documenting-the-results-based-on-two-datasets">Documenting the results based on two datasets</h3>
<p>We have now done some analysis on two different datasets and we should able to document why certain things were done to the raw data with testing to support it. Every test result returned by the <code>run_test()</code> function has a <code>.log()</code> method that can be used to log the test results to ValidMind. When logging individual results to ValidMind you need to manually add those results in a specific section of the model documentation.</p>
<p>When using <code>run_documentation_tests()</code>, it’s possible to automatically populate a section with the results of all tests that were registered in the documentation template.</p>
<p>To show how to add individual results to any documentation section, we’re going to populate the entire <code>data_preparation</code> section of the documentation using the clean <code>vm_raw_dataset_preprocessed</code> dataset as input, and then we’re going to document an additional result for the highly correlated dataset <code>vm_balanced_raw_dataset</code>. The following two steps will accomplish this:</p>
<ol type="1">
<li>Run <code>run_documentation_tests()</code> using <code>vm_raw_dataset_preprocessed</code> as input. This populates the entire data preparation section for every test that is already part of the documentation template.</li>
<li>Log the individual result of the high correlation test that used <code>vm_balanced_raw_dataset</code> (that had a highly correlated <code>Age</code> column) as input</li>
</ol>
<p>After adding the result of step #2 to the documentation you will be able to explain the changes made to the raw data by editing the default description of the test result on the UI.</p>
<p><a id="toc5_4_1_"></a></p>
<section id="run-run_documentation_tests-using-vm_raw_dataset_preprocessed-as-input" class="level4">
<h4 class="anchored" data-anchor-id="run-run_documentation_tests-using-vm_raw_dataset_preprocessed-as-input">Run <code>run_documentation_tests()</code> using <code>vm_raw_dataset_preprocessed</code> as input</h4>
<p><code>run_documentation_tests()</code> allows you to run multiple tests at once and log the results to the documentation. The function takes the following arguments:</p>
<ul>
<li><code>inputs</code>: any inputs to be passed to the tests</li>
<li><code>config</code>: a dictionary <code>&lt;test_id&gt;:&lt;test_config&gt;</code> that allows configuring each test individually. Each test config has the following form:
<ul>
<li><code>params</code>: individual test parameters</li>
<li><code>inputs</code>: individual test inputs. When passed, this overrides any inputs passed from the <code>run_documentation_tests()</code> function</li>
</ul></li>
</ul>
<div id="cell-46" class="cell" data-metadata="{}" data-execution_count="23">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>test_config <span class="op">=</span> {</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.data_validation.ClassImbalance"</span>: {</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {<span class="st">"min_percent_threshold"</span>: <span class="dv">30</span>},</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.data_validation.HighPearsonCorrelation"</span>: {</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {<span class="st">"max_threshold"</span>: <span class="fl">0.3</span>},</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>tests_suite <span class="op">=</span> vm.run_documentation_tests(</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"dataset"</span>: vm_raw_dataset_preprocessed,</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>    config<span class="op">=</span>test_config,</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>    section<span class="op">=</span>[<span class="st">"data_preparation"</span>],</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"85e700ca3bc44f93b76c1f28648bc608","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e2d57efeacc14c959ce1c88c1c8180af","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p><a id="toc5_4_2_"></a></p>
</section>
<section id="log-the-individual-result-of-the-high-correlation-test-that-used-vm_balanced_raw_dataset-that-had-a-highly-correlated-age-column-as-input" class="level4">
<h4 class="anchored" data-anchor-id="log-the-individual-result-of-the-high-correlation-test-that-used-vm_balanced_raw_dataset-that-had-a-highly-correlated-age-column-as-input">Log the individual result of the high correlation test that used <code>vm_balanced_raw_dataset</code> (that had a highly correlated <code>Age</code> column) as input</h4>
<p>Here you can use a custom <code>result_id</code> to tag the individual result with a unique identifier. This <code>result_id</code> can be appended to <code>test_id</code> with a <code>:</code> separator. The <code>balanced_raw_dataset</code> result identifier will correspond to the <code>balanced_raw_dataset</code> input, the dataset that still has the <code>Age</code> column.</p>
<div id="cell-48" class="cell" data-metadata="{}" data-execution_count="24">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> vm.tests.run_test(</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    test_id<span class="op">=</span><span class="st">"validmind.data_validation.HighPearsonCorrelation:balanced_raw_dataset"</span>,</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>{<span class="st">"max_threshold"</span>: <span class="fl">0.3</span>},</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{<span class="st">"dataset"</span>: vm_balanced_raw_dataset},</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>result.log()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9974d98d0ce24c518222e1ea875d9fbb","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p><a id="toc5_5_"></a></p>
</section>
</section>
<section id="add-individual-test-results-to-model-documentation" class="level3">
<h3 class="anchored" data-anchor-id="add-individual-test-results-to-model-documentation">Add individual test results to model documentation</h3>
<p>You can now visit the documentation page for the model you connected to at the beginning of this notebook and add a new content block in the relevant section.</p>
<p>To do this, go to the documentation page of your model and navigate to the <code>Data Preparation</code> -&gt; <code>Correlations and Interactions</code> section. Then hover after the “Pearson Correlation Matrix” content block to reveal the <code>+</code> button as shown in the screenshot below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/insert-test-driven-block-correlations.png" class="img-fluid figure-img"></p>
<figcaption>screenshot showing insert button for test-driven blocks</figcaption>
</figure>
</div>
<p>Click on the <code>+</code> button and select <code>Test-Driven Block</code>. This will open a dialog where you can select <code>Threshold Test</code> as the type of the test-driven content block, and then select <code>High Pearson Correlation Vm Raw Dataset Test</code>. This will show a preview of the result and it should match the results shown above.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/selecting-high-pearson-correlation-test.png" class="img-fluid figure-img"></p>
<figcaption>screenshot showing the selected test result in the dialog</figcaption>
</figure>
</div>
<p>Finally, click on the <code>Insert block</code> button to add the test result to the documentation. You’ll now see two individual results for the high correlation test in the <code>Correlations and Interactions</code> section of the documentation. To finalize the documentation, you can edit the test result’s description block to explain the changes made to the raw data and the reasons behind them as we can see in the screenshot below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/high-pearson-correlation-block.png" class="img-fluid figure-img"></p>
<figcaption>screenshot showing the high pearson correlation block</figcaption>
</figure>
</div>
<p><a id="toc5_6_"></a></p>
</section>
<section id="model-testing" class="level3">
<h3 class="anchored" data-anchor-id="model-testing">Model Testing</h3>
<p>We have focused so far on the data assessment and pre-processing that usually occurs prior to any models being built. Now we are going to assume we have built a model and we want to incorporate some model results in our documentation.</p>
<p>Let’s train a simple logistic regression model on the dataset and evaluate its performance. You will use the <code>LogisticRegression</code> class from the <code>sklearn.linear_model</code> and use ValidMind tests to evaluate the model’s performance.</p>
<p>Before training the model, we need to encode the categorical features in the dataset. You will use the <code>OneHotEncoder</code> class from the <code>sklearn.preprocessing</code> module to encode the categorical features. The categorical features in the dataset are <code>Geography</code> and <code>Gender</code>.</p>
<div id="cell-51" class="cell" data-metadata="{}" data-execution_count="25">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>balanced_raw_no_age_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CreditScore</th>
<th data-quarto-table-cell-role="th">Geography</th>
<th data-quarto-table-cell-role="th">Gender</th>
<th data-quarto-table-cell-role="th">Tenure</th>
<th data-quarto-table-cell-role="th">Balance</th>
<th data-quarto-table-cell-role="th">NumOfProducts</th>
<th data-quarto-table-cell-role="th">HasCrCard</th>
<th data-quarto-table-cell-role="th">IsActiveMember</th>
<th data-quarto-table-cell-role="th">EstimatedSalary</th>
<th data-quarto-table-cell-role="th">Exited</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">2379</td>
<td>729</td>
<td>Spain</td>
<td>Female</td>
<td>7</td>
<td>91091.06</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>71133.12</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4104</td>
<td>651</td>
<td>Germany</td>
<td>Male</td>
<td>7</td>
<td>138008.06</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>129912.74</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7836</td>
<td>756</td>
<td>France</td>
<td>Male</td>
<td>1</td>
<td>94773.11</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>114279.63</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2735</td>
<td>731</td>
<td>Germany</td>
<td>Female</td>
<td>9</td>
<td>79120.27</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>548.52</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6118</td>
<td>535</td>
<td>Spain</td>
<td>Female</td>
<td>5</td>
<td>122924.75</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>62390.59</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-52" class="cell" data-metadata="{}" data-execution_count="26">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>balanced_raw_no_age_df <span class="op">=</span> pd.get_dummies(</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    balanced_raw_no_age_df, columns<span class="op">=</span>[<span class="st">"Geography"</span>, <span class="st">"Gender"</span>], drop_first<span class="op">=</span><span class="va">True</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>balanced_raw_no_age_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CreditScore</th>
<th data-quarto-table-cell-role="th">Tenure</th>
<th data-quarto-table-cell-role="th">Balance</th>
<th data-quarto-table-cell-role="th">NumOfProducts</th>
<th data-quarto-table-cell-role="th">HasCrCard</th>
<th data-quarto-table-cell-role="th">IsActiveMember</th>
<th data-quarto-table-cell-role="th">EstimatedSalary</th>
<th data-quarto-table-cell-role="th">Exited</th>
<th data-quarto-table-cell-role="th">Geography_Germany</th>
<th data-quarto-table-cell-role="th">Geography_Spain</th>
<th data-quarto-table-cell-role="th">Gender_Male</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">2379</td>
<td>729</td>
<td>7</td>
<td>91091.06</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>71133.12</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4104</td>
<td>651</td>
<td>7</td>
<td>138008.06</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>129912.74</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7836</td>
<td>756</td>
<td>1</td>
<td>94773.11</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>114279.63</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2735</td>
<td>731</td>
<td>9</td>
<td>79120.27</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>548.52</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6118</td>
<td>535</td>
<td>5</td>
<td>122924.75</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>62390.59</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-53" class="cell" data-metadata="{}" data-execution_count="27">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the input and target variables</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> balanced_raw_no_age_df.drop(<span class="st">"Exited"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> balanced_raw_no_age_df[<span class="st">"Exited"</span>]</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    X,</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    y,</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    test_size<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistic Regression grid params</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>log_reg_params <span class="op">=</span> {</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"penalty"</span>: [<span class="st">"l1"</span>, <span class="st">"l2"</span>],</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"C"</span>: [<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>],</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"solver"</span>: [<span class="st">"liblinear"</span>],</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid search for Logistic Regression</span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>grid_log_reg <span class="op">=</span> GridSearchCV(LogisticRegression(), log_reg_params)</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>grid_log_reg.fit(X_train, y_train)</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistic Regression best estimator</span></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>log_reg <span class="op">=</span> grid_log_reg.best_estimator_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a id="toc5_7_"></a></p>
</section>
<section id="initialize-model-evaluation-objects-and-assigning-predictions" class="level3">
<h3 class="anchored" data-anchor-id="initialize-model-evaluation-objects-and-assigning-predictions">Initialize model evaluation objects and assigning predictions</h3>
<p>The last step for evaluating the model’s performance is to initialize the ValidMind <code>Dataset</code> and <code>Model</code> objects and assign model predictions to each dataset. You will use the <code>init_dataset</code>, <code>init_model</code> and <code>assign_predictions</code> functions to initialize these objects.</p>
<div id="cell-55" class="cell" data-metadata="{}" data-execution_count="28">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> X_train</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"Exited"</span>] <span class="op">=</span> y_train</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> X_test</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"Exited"</span>] <span class="op">=</span> y_test</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>vm_train_ds <span class="op">=</span> vm.init_dataset(</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    input_id<span class="op">=</span><span class="st">"train_dataset_final"</span>,</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>train_df,</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    target_column<span class="op">=</span><span class="st">"Exited"</span>,</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>vm_test_ds <span class="op">=</span> vm.init_dataset(</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    input_id<span class="op">=</span><span class="st">"test_dataset_final"</span>,</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>test_df,</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>    target_column<span class="op">=</span><span class="st">"Exited"</span>,</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Register the model</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>vm_model <span class="op">=</span> vm.init_model(log_reg, input_id<span class="op">=</span><span class="st">"log_reg_model_v1"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-06-12 16:27:41,603 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...
2024-06-12 16:27:41,774 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...</code></pre>
</div>
</div>
<p>Once the model has been registered you can assign model predictions to the training and test datasets. The <code>assign_predictions()</code> method from the <code>Dataset</code> object can link existing predictions to any number of models. If no prediction values are passed, the method will compute predictions automatically:</p>
<div id="cell-57" class="cell" data-metadata="{}" data-execution_count="29">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>vm_train_ds.assign_predictions(model<span class="op">=</span>vm_model)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>vm_test_ds.assign_predictions(model<span class="op">=</span>vm_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-06-12 16:27:42,147 - INFO(validmind.vm_models.dataset.utils): Running predict_proba()... This may take a while
/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names

2024-06-12 16:27:42,154 - INFO(validmind.vm_models.dataset.utils): Done running predict_proba()
2024-06-12 16:27:42,175 - INFO(validmind.vm_models.dataset.utils): Running predict()... This may take a while
/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names

2024-06-12 16:27:42,222 - INFO(validmind.vm_models.dataset.utils): Done running predict()
2024-06-12 16:27:42,230 - INFO(validmind.vm_models.dataset.utils): Running predict_proba()... This may take a while
/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names

2024-06-12 16:27:42,236 - INFO(validmind.vm_models.dataset.utils): Done running predict_proba()
2024-06-12 16:27:42,239 - INFO(validmind.vm_models.dataset.utils): Running predict()... This may take a while
/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names

2024-06-12 16:27:42,244 - INFO(validmind.vm_models.dataset.utils): Done running predict()</code></pre>
</div>
</div>
<p><a id="toc5_8_"></a></p>
</section>
<section id="run-the-model-evaluation-tests" class="level3">
<h3 class="anchored" data-anchor-id="run-the-model-evaluation-tests">Run the model evaluation tests</h3>
<p>In this part, we focus on running the tests within the model development section of the model documentation. Only tests associated with this section will be executed, and the corresponding results will be updated in the model documentation. In the example below, you will focus on only running tests for the <code>model development</code> section of the document.</p>
<p>Note the additional config that is passed to <code>run_documentation_tests()</code>. This allows you to override inputs or params in certain tests. In our case, we want to explicitly use the <code>vm_train_ds</code> for the <code>validmind.model_validation.sklearn.ClassifierPerformance:in_sample</code> test, since it’s supposed to run on the training dataset and not the test dataset.</p>
<div id="cell-59" class="cell" data-metadata="{}" data-execution_count="30">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>test_config <span class="op">=</span> {</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.ClassifierPerformance:in_sample"</span>: {</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">"dataset"</span>: vm_train_ds,</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: vm_model,</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> vm.run_documentation_tests(</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    section<span class="op">=</span>[<span class="st">"model_development"</span>],</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"dataset"</span>: vm_test_ds,  <span class="co"># Any test that requires a single dataset will use vm_test_ds</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"model"</span>: vm_model,</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"datasets"</span>: (</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>            vm_train_ds,</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>            vm_test_ds,</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>        ),  <span class="co"># Any test that requires multiple datasets will use vm_train_ds and vm_test_ds</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>    config<span class="op">=</span>test_config,</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5e9f11f57d2b4e5989aa040149c81975","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names

/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names

/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"89d137eb48c64e42a6d56726b0f0a2c7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p><a id="toc6_"></a></p>
</section>
</section>
<section id="implementing-custom-tests" class="level2">
<h2 class="anchored" data-anchor-id="implementing-custom-tests">3. Implementing custom tests</h2>
<p>This section assumes that model developers already have a repository of custom made tests that they consider critical to include in the documentation. Here we provide details on how to easily integrate custom tests with ValidMind.</p>
<p>For a more in-depth introduction to custom tests, refer to this <a href="../../notebooks/code_samples/custom_tests/implement_custom_tests.html">notebook</a>.</p>
<p>A custom test is any function that takes a set of inputs and parameters as arguments and returns one or more outputs. The function can be as simple or as complex as you need it to be. It can use external libraries, make API calls, or do anything else that you can do in Python. The only requirement is that the function signature and return values can be “understood” and handled by the ValidMind Developer Framework. As such, custom tests offer added flexibility by extending the default tests provided by ValidMind, enabling you to document any type of model or use case.</p>
<p>In the following example, you will learn how to implement a custom <code>inline</code> test that calculates the confusion matrix for a binary classification model. You will see that the custom test function is just a regular Python function that can include and require any Python library as you see fit.</p>
<p><strong>NOTE</strong>: in the context of Jupyter notebooks, we will use the word <code>inline</code> to refer to functions (or code) defined in the same notebook where they are used (this one) and not in a separate file, as we will see later with test providers.</p>
<p><a id="toc6_1_"></a></p>
<section id="create-a-confusion-matrix-plot" class="level3">
<h3 class="anchored" data-anchor-id="create-a-confusion-matrix-plot">Create a confusion matrix plot</h3>
<p>To understand how to create a custom test from anything, let’s first create a confusion matrix plot using the <code>confusion_matrix</code> function from the <code>sklearn.metrics</code> module.</p>
<div id="cell-62" class="cell" data-metadata="{}" data-execution_count="31">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the predicted classes</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> log_reg.predict(vm_test_ds.x)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="op">=</span> metrics.confusion_matrix(y_test, y_pred)</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>cm_display <span class="op">=</span> metrics.ConfusionMatrixDisplay(</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>    confusion_matrix<span class="op">=</span>confusion_matrix, display_labels<span class="op">=</span>[<span class="va">False</span>, <span class="va">True</span>]</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>cm_display.plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="intro_for_model_developers_EXECUTED_files/figure-html/cell-32-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We will now create a <span class="citation" data-cites="vm.test">@vm.test</span> wrapper that will allow you to create a reusable test. Note the following changes in the code below:</p>
<ul>
<li>The function <code>confusion_matrix</code> takes two arguments <code>dataset</code> and <code>model</code>. This is a <code>VMDataset</code> and <code>VMModel</code> object respectively.
<ul>
<li><code>VMDataset</code> objects allow you to access the dataset’s true (target) values by accessing the <code>.y</code> attribute.</li>
<li><code>VMDataset</code> objects allow you to access the predictions for a given model by accessing the <code>.y_pred()</code> method.</li>
</ul></li>
<li>The function docstring provides a description of what the test does. This will be displayed along with the result in this notebook as well as in the ValidMind platform.</li>
<li>The function body calculates the confusion matrix using the <code>sklearn.metrics.confusion_matrix</code> function as we just did above.</li>
<li>The function then returns the <code>ConfusionMatrixDisplay.figure_</code> object - this is important as the ValidMind framework expects the output of the custom test to be a plot or a table.</li>
<li>The <code>@vm.test</code> decorator is doing the work of creating a wrapper around the function that will allow it to be run by the ValidMind framework. It also registers the test so it can be found by the ID <code>my_custom_tests.ConfusionMatrix</code> (see the section below on how test IDs work in ValidMind and why this format is important)</li>
</ul>
<div id="cell-64" class="cell" data-metadata="{}" data-execution_count="32">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="at">@vm.test</span>(<span class="st">"my_custom_tests.ConfusionMatrix"</span>)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> confusion_matrix(dataset, model):</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The confusion matrix is a table that is often used to describe the performance of a classification model on a set of data for which the true values are known.</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co">    The confusion matrix is a 2x2 table that contains 4 values:</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - True Positive (TP): the number of correct positive predictions</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - True Negative (TN): the number of correct negative predictions</span></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - False Positive (FP): the number of incorrect positive predictions</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - False Negative (FN): the number of incorrect negative predictions</span></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a><span class="co">    The confusion matrix can be used to assess the holistic performance of a classification model by showing the accuracy, precision, recall, and F1 score of the model on a single figure.</span></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>    y_true <span class="op">=</span> dataset.y</span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> dataset.y_pred(model<span class="op">=</span>model)</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>    confusion_matrix <span class="op">=</span> metrics.confusion_matrix(y_true, y_pred)</span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>    cm_display <span class="op">=</span> metrics.ConfusionMatrixDisplay(</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>        confusion_matrix<span class="op">=</span>confusion_matrix, display_labels<span class="op">=</span>[<span class="va">False</span>, <span class="va">True</span>]</span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a>    cm_display.plot()</span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a>    plt.close()  <span class="co"># close the plot to avoid displaying it</span></span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cm_display.figure_  <span class="co"># return the figure object itself</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can now run the newly created custom test on both the training and test datasets using the <code>run_test()</code> function:</p>
<div id="cell-66" class="cell" data-metadata="{}" data-execution_count="33">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Training dataset</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> vm.tests.run_test(</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"my_custom_tests.ConfusionMatrix:training_dataset"</span>,</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{<span class="st">"model"</span>: vm_model, <span class="st">"dataset"</span>: vm_train_ds},</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"aa6da0bbb8da42118f3f10d9053a1204","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<div id="cell-67" class="cell" data-metadata="{}" data-execution_count="34">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test dataset</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> vm.tests.run_test(</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"my_custom_tests.ConfusionMatrix:test_dataset"</span>,</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{<span class="st">"model"</span>: vm_model, <span class="st">"dataset"</span>: vm_test_ds},</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cb70a102d8554bbb8b3b171ff97bfb91","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p><a id="toc6_2_"></a></p>
</section>
<section id="add-parameters-to-custom-tests" class="level3">
<h3 class="anchored" data-anchor-id="add-parameters-to-custom-tests">Add parameters to custom tests</h3>
<p>Custom tests can take parameters just like any other function. Let’s modify the <code>confusion_matrix</code> function to take an additional parameter <code>normalize</code> that will allow you to normalize the confusion matrix.</p>
<div id="cell-69" class="cell" data-metadata="{}" data-execution_count="35">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="at">@vm.test</span>(<span class="st">"my_custom_tests.ConfusionMatrix"</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> confusion_matrix(dataset, model, normalize<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The confusion matrix is a table that is often used to describe the performance of a classification model on a set of data for which the true values are known.</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co">    The confusion matrix is a 2x2 table that contains 4 values:</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - True Positive (TP): the number of correct positive predictions</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - True Negative (TN): the number of correct negative predictions</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - False Positive (FP): the number of incorrect positive predictions</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - False Negative (FN): the number of incorrect negative predictions</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="co">    The confusion matrix can be used to assess the holistic performance of a classification model by showing the accuracy, precision, recall, and F1 score of the model on a single figure.</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>    y_true <span class="op">=</span> dataset.y</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> dataset.y_pred(model<span class="op">=</span>model)</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> normalize:</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>        confusion_matrix <span class="op">=</span> metrics.confusion_matrix(y_true, y_pred, normalize<span class="op">=</span><span class="st">"all"</span>)</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a>        confusion_matrix <span class="op">=</span> metrics.confusion_matrix(y_true, y_pred)</span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>    cm_display <span class="op">=</span> metrics.ConfusionMatrixDisplay(</span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a>        confusion_matrix<span class="op">=</span>confusion_matrix, display_labels<span class="op">=</span>[<span class="va">False</span>, <span class="va">True</span>]</span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a>    cm_display.plot()</span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a>    plt.close()  <span class="co"># close the plot to avoid displaying it</span></span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cm_display.figure_  <span class="co"># return the figure object itself</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a id="toc6_3_"></a></p>
</section>
<section id="pass-parameters-to-custom-tests" class="level3">
<h3 class="anchored" data-anchor-id="pass-parameters-to-custom-tests">Pass parameters to custom tests</h3>
<p>You can pass parameters to custom tests by providing a dictionary of parameters to the <code>run_test()</code> function. The parameters will override any default parameters set in the custom test definition. Note that <code>dataset</code> and <code>model</code> are still passed as <code>inputs</code>. Since these are <code>VMDataset</code> or <code>VMModel</code> inputs, they have a special meaning. When declaring a <code>dataset</code>, <code>model</code>, <code>datasets</code> or <code>models</code> argument in a custom test function, the Developer Framework will expect these get passed as <code>inputs</code> to <code>run_test()</code> (or <code>run_documentation_tests()</code> instead).</p>
<p>Re-running the confusion matrix with <code>normalize=True</code> looks like this:</p>
<div id="cell-71" class="cell" data-metadata="{}" data-execution_count="36">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test dataset with normalize=True</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> vm.tests.run_test(</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"my_custom_tests.ConfusionMatrix:test_dataset_normalized"</span>,</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{<span class="st">"model"</span>: vm_model, <span class="st">"dataset"</span>: vm_test_ds},</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>{<span class="st">"normalize"</span>: <span class="va">True</span>},</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"bc68d7db1a614c6cbcf3927f4dd8b851","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p><a id="toc6_4_"></a></p>
</section>
<section id="log-the-confusion-matrix-results" class="level3">
<h3 class="anchored" data-anchor-id="log-the-confusion-matrix-results">Log the confusion matrix results</h3>
<p>As you saw in the pearson correlation example, you can log any result to the ValidMind platform with the <code>.log()</code> method of the result object. This will allow you to add the result to the documentation.</p>
<p>You can now do the same for the confusion matrix results.</p>
<div id="cell-73" class="cell" data-metadata="{}" data-execution_count="37">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>result.log()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a id="toc6_5_"></a></p>
</section>
<section id="using-external-test-providers" class="level3">
<h3 class="anchored" data-anchor-id="using-external-test-providers">Using external test providers</h3>
<p>Creating inline custom tests with a function is a great way to customize your model documentation. However, sometimes you may want to reuse the same set of tests across multiple models and share them with developers in your organization. In this case, you can create a custom test provider that will allow you to load custom tests from a local folder or a git repository.</p>
<p>In this section you will learn how to declare a local filesystem test provider that allows loading tests from a local folder following these high level steps:</p>
<ol type="1">
<li>Create a folder of custom tests from existing, inline tests (tests that exists in your active Jupyter notebook)</li>
<li>Save an inline test to a file</li>
<li>Define and register a <code>LocalTestProvider</code> that points to that folder</li>
<li>Run test provider tests</li>
<li>Add the test results to your documentation</li>
</ol>
<p><a id="toc6_5_1_"></a></p>
<section id="create-a-folder-of-custom-tests-from-existing-inline-tests" class="level4">
<h4 class="anchored" data-anchor-id="create-a-folder-of-custom-tests-from-existing-inline-tests">Create a folder of custom tests from existing inline tests</h4>
<p>Here you will create a new folder that will contain reusable, custom tests. The following code snippet will create a new <code>my_tests</code> directory in the current working directory if it doesn’t exist.</p>
<div id="cell-76" class="cell" data-metadata="{}" data-execution_count="38">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>tests_folder <span class="op">=</span> <span class="st">"my_tests"</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="co"># create tests folder</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>os.makedirs(tests_folder, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a><span class="co"># remove existing tests</span></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> f <span class="kw">in</span> os.listdir(tests_folder):</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove files and pycache</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> f.endswith(<span class="st">".py"</span>) <span class="kw">or</span> f <span class="op">==</span> <span class="st">"__pycache__"</span>:</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>        os.system(<span class="ss">f"rm -rf </span><span class="sc">{</span>tests_folder<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>f<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After running the command above, you should see a new directory next to this notebook file:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/my_tests_directory.png" class="img-fluid figure-img"></p>
<figcaption>screenshot showing my_tests directory</figcaption>
</figure>
</div>
<p><a id="toc6_5_2_"></a></p>
</section>
<section id="save-an-inline-test-to-a-file" class="level4">
<h4 class="anchored" data-anchor-id="save-an-inline-test-to-a-file">Save an inline test to a file</h4>
<p>The <code>@vm.test</code> decorator that was used above to register these as one-off custom tests also adds a convenience method to the function object that allows you to simply call <code>&lt;func_name&gt;.save()</code> to save it to a file. This will save the function to a Python file to a path you specify. In this case, you can pass the variable <code>tests_folder</code> to save it to the custom tests folder we created.</p>
<p>Normally, this will get you started by creating the file and saving the function code with the correct name. But it won’t automatically add any import or other functions/variables outside of the function that are needed for the test to run. The <code>save()</code> method allows you to pass an optional <code>imports</code> argument that will ensure the necessary imports are added to the file.</p>
<p>For the <code>confusion_matrix</code> test, note the imports that are required for the function to run properly:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can pass these imports to the <code>save()</code> method to ensure they are included in the file with the following command:</p>
<div id="cell-79" class="cell" data-metadata="{}" data-execution_count="39">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>confusion_matrix.save(</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>    tests_folder,</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>    imports<span class="op">=</span>[<span class="st">"import matplotlib.pyplot as plt"</span>, <span class="st">"from sklearn import metrics"</span>],</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-06-12 16:28:17,053 - INFO(validmind.tests.decorator): Saved to /Users/beckchan/Documents/GitHub/validmind/developer-framework/notebooks/tutorials/my_tests/ConfusionMatrix.py!Be sure to add any necessary imports to the top of the file.
2024-06-12 16:28:17,054 - INFO(validmind.tests.decorator): This metric can be run with the ID: &lt;test_provider_namespace&gt;.ConfusionMatrix</code></pre>
</div>
</div>
<section id="what-happened" class="level5">
<h5 class="anchored" data-anchor-id="what-happened">What happened?</h5>
<p>The <code>save()</code> method saved the <code>confusion_matrix</code> function to a file named <code>ConfusionMatrix.py</code> in the <code>my_tests</code> folder. Note that the new file provides some context on the origin of the test, which is useful for traceability.</p>
<pre><code># Saved from __main__.confusion_matrix
# Original Test ID: my_custom_tests.ConfusionMatrix
# New Test ID: &lt;test_provider_namespace&gt;.ConfusionMatrix</code></pre>
<p>Additionally, the new test function has been stripped off its decorator, as it now resides in a file that will be loaded by the test provider:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ConfusionMatrix(dataset, model, normalize<span class="op">=</span><span class="va">False</span>):</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><a id="toc6_5_3_"></a></p>
</section>
</section>
<section id="define-and-register-a-localtestprovider-that-points-to-that-folder" class="level4">
<h4 class="anchored" data-anchor-id="define-and-register-a-localtestprovider-that-points-to-that-folder">Define and register a <code>LocalTestProvider</code> that points to that folder</h4>
<p>With the <code>my_tests</code> folder now having a sample custom test, you can now initialize a test provider that will tell the Developer Framework where to find these tests. ValidMind offers out-of-the-box test providers for local tests (i.e.&nbsp;tests in a folder) or a Github provider for tests in a Github repository. You can also create your own test provider by creating a class that has a <code>load_test</code> method that takes a test ID and returns the test function matching that ID.</p>
<p>The most important attribute for a test provider is its <code>namespace</code>. This is a string that will be used to prefix test IDs in model documentation. This allows you to have multiple test providers with tests that can even share the same ID, but are distinguished by their namespace.</p>
<p>An extended introduction to test providers can be found in <a href="../../notebooks/code_samples/custom_tests/integrate_external_test_providers.html">this</a> notebook.</p>
<p><a id="toc6_6_"></a></p>
</section>
</section>
<section id="initializing-a-local-test-provider" class="level3">
<h3 class="anchored" data-anchor-id="initializing-a-local-test-provider">Initializing a local test provider</h3>
<p>For most use-cases, the local test provider should be sufficient. This test provider allows you load custom tests from a designated directory. Let’s go ahead and see how we can do this with our custom tests.</p>
<div id="cell-82" class="cell" data-metadata="{}" data-execution_count="40">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> validmind.tests <span class="im">import</span> LocalTestProvider</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize the test provider with the tests folder we created earlier</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>my_test_provider <span class="op">=</span> LocalTestProvider(tests_folder)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>vm.tests.register_test_provider(</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    namespace<span class="op">=</span><span class="st">"my_test_provider"</span>,</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>    test_provider<span class="op">=</span>my_test_provider,</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a><span class="co"># `my_test_provider.load_test()` will be called for any test ID that starts with `my_test_provider`</span></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a><span class="co"># e.g. `my_test_provider.ConfusionMatrix` will look for a function named `ConfusionMatrix` in `my_tests/ConfusionMatrix.py` file</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a id="toc6_6_1_"></a></p>
<section id="run-test-provider-tests" class="level4">
<h4 class="anchored" data-anchor-id="run-test-provider-tests">Run test provider tests</h4>
<p>Now that you have set up the test provider, you can run any test that’s located in the tests folder by using the <code>run_test()</code> method as with any other test. For tests that reside in a test provider directory, the test ID will be the <code>namespace</code> specified when registering the provider, followed by the path to the test file relative to the tests folder. For example, the Confusion Matrix test we created earlier will have the test ID <code>my_test_provider.ConfusionMatrix</code>. You could organize the tests in subfolders, say <code>classification</code> and <code>regression</code>, and the test ID for the Confusion Matrix test would then be <code>my_test_provider.classification.ConfusionMatrix</code>.</p>
<p>Let’s go ahead and re-run the confusion matrix test by using the test ID <code>my_test_provider.ConfusionMatrix</code>. This should load the test from the test provider and run it as before.</p>
<div id="cell-84" class="cell" data-metadata="{}" data-execution_count="41">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> vm.tests.run_test(</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"my_test_provider.ConfusionMatrix"</span>,</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{<span class="st">"model"</span>: vm_model, <span class="st">"dataset"</span>: vm_test_ds},</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>{<span class="st">"normalize"</span>: <span class="va">True</span>},</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>result.log()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"677f67f8374a4602a88c361b4210f987","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p><a id="toc6_6_2_"></a></p>
</section>
<section id="add-the-test-results-to-your-documentation" class="level4">
<h4 class="anchored" data-anchor-id="add-the-test-results-to-your-documentation">Add the test results to your documentation</h4>
<p>You have already seen how to add individual results to the model documentation using the platform. Let’s repeat the process and add the confusion matrix to the <code>Model Development</code> -&gt; <code>Model Evaluation</code> section of the documentation. The “add test driven block” dialog should now show the new test result coming from the test provider:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/insert-test-driven-block-custom-confusion-matrix.png" class="img-fluid figure-img"></p>
<figcaption>screenshot showing confusion matrix result</figcaption>
</figure>
</div>
<p><a id="toc7_"></a></p>
</section>
</section>
</section>
<section id="finalize-testing-and-documentation" class="level2">
<h2 class="anchored" data-anchor-id="finalize-testing-and-documentation">4. Finalize testing and documentation</h2>
<p>In this section we cover how to finalize the testing and documentation of your model by focusing on:</p>
<ol type="1">
<li>Using <code>run_documentation_tests()</code> to ensure custom test results are included in your documentation</li>
<li>Viewing and updating the configuration for the entire model documentation template</li>
</ol>
<p><a id="toc7_1_"></a></p>
<section id="use-run_documentation_tests-to-ensure-custom-test-results-are-included-in-your-documentation" class="level3">
<h3 class="anchored" data-anchor-id="use-run_documentation_tests-to-ensure-custom-test-results-are-included-in-your-documentation">Use <code>run_documentation_tests()</code> to ensure custom test results are included in your documentation</h3>
<p>After adding test driven blocks to your model documentation, changes should persist and become available every time you call <code>vm.preview_template()</code>. However, you need to reload the connection to the ValidMind platform if you have added test driven blocks when the connection was already established.</p>
<div id="cell-88" class="cell" data-metadata="{}" data-execution_count="42">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>vm.<span class="bu">reload</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, run <code>preview_template()</code> and verify that the new confusion matrix test you added is included in the proper section.</p>
<div id="cell-90" class="cell" data-metadata="{}" data-execution_count="43">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>vm.preview_template()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"12cdbf47e81349458c81d1cec148327a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p>Since the test ID is now registered in the document you can now run tests for an entire section and all additional custom tests should be loaded without issues. Let’s run all tests in the <code>model_evaluation</code> section of the documentation. Note that we have been running the sample custom confusion matrix with <code>normalize=True</code> to demonstrate the ability to provide custom parameters.</p>
<p>In the <code>Run the model evaluation tests</code> section above you learned how to assign inputs to individual tests with <code>run_documentation_tests()</code>. Assigning parametesr is similar, you only need to provide assign a <code>params</code> dictionary to a given test ID, <code>my_test_provider.ConfusionMatrix</code> in this case.</p>
<div id="cell-92" class="cell" data-metadata="{}" data-execution_count="44">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>test_config <span class="op">=</span> {</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.ClassifierPerformance:in_sample"</span>: {</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">"dataset"</span>: vm_train_ds,</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: vm_model,</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"my_test_provider.ConfusionMatrix"</span>: {</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {<span class="st">"normalize"</span>: <span class="va">True</span>},</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> vm.run_documentation_tests(</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>    section<span class="op">=</span>[<span class="st">"model_evaluation"</span>],</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>{</span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"dataset"</span>: vm_test_ds,  <span class="co"># Any test that requires a single dataset will use vm_test_ds</span></span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"model"</span>: vm_model,</span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"datasets"</span>: (</span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a>            vm_train_ds,</span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a>            vm_test_ds,</span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a>        ),  <span class="co"># Any test that requires multiple datasets will use vm_train_ds and vm_test_ds</span></span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a>    config<span class="op">=</span>test_config,</span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-06-12 16:28:18,447 - WARNING(validmind.vm_models.test_suite.runner): Config key 'my_test_provider.ConfusionMatrix' does not match a test_id in the template.
    Ensure you registered a content block with the correct content_id in the template
    The configuration for this test will be ignored.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a83eb7bd8cc34e3d97007e02cf59acee","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"23b033c9b86a4c829228bb9c0b5abae0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p><a id="toc7_2_"></a></p>
</section>
<section id="viewing-and-updating-the-configuration-for-the-entire-model-documentation-template" class="level3">
<h3 class="anchored" data-anchor-id="viewing-and-updating-the-configuration-for-the-entire-model-documentation-template">Viewing and updating the configuration for the entire model documentation template</h3>
<p>The Developer Framework provides a utility function called <code>vm.get_test_suite().get_default_config()</code> that allows you to render the default configuration for the entire documentation template. This configuration will contain all the test IDs and their default parameters. You can then modify this configuration as needed and pass it to <code>run_documentation_tests()</code> to run all tests in the documentation template if needed. You also have the option to continue running tests for one section at a time, <code>get_default_config()</code> still provides a useful reference for providing default parametes to every test.</p>
<div id="cell-94" class="cell" data-metadata="{}" data-execution_count="45">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>project_test_suite <span class="op">=</span> vm.get_test_suite()</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> project_test_suite.get_default_config()</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Suite Config: </span><span class="ch">\n</span><span class="st">"</span>, json.dumps(config, indent<span class="op">=</span><span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Suite Config: 
 {
  "validmind.data_validation.DatasetDescription": {
    "inputs": {
      "dataset": null
    },
    "params": {}
  },
  "validmind.data_validation.ClassImbalance": {
    "inputs": {
      "dataset": null
    },
    "params": {
      "min_percent_threshold": 10
    }
  },
  "validmind.data_validation.Duplicates": {
    "inputs": {
      "dataset": null
    },
    "params": {
      "min_threshold": 1
    }
  },
  "validmind.data_validation.HighCardinality": {
    "inputs": {
      "dataset": null
    },
    "params": {
      "num_threshold": 100,
      "percent_threshold": 0.1,
      "threshold_type": "percent"
    }
  },
  "validmind.data_validation.MissingValues": {
    "inputs": {
      "dataset": null
    },
    "params": {
      "min_threshold": 1
    }
  },
  "validmind.data_validation.Skewness": {
    "inputs": {
      "dataset": null
    },
    "params": {
      "max_threshold": 1
    }
  },
  "validmind.data_validation.UniqueRows": {
    "inputs": {
      "dataset": null
    },
    "params": {
      "min_percent_threshold": 1
    }
  },
  "validmind.data_validation.TooManyZeroValues": {
    "inputs": {
      "dataset": null
    },
    "params": {
      "max_percent_threshold": 0.03
    }
  },
  "validmind.data_validation.IQROutliersTable": {
    "inputs": {
      "dataset": null
    },
    "params": {
      "features": null,
      "threshold": 1.5
    }
  },
  "validmind.data_validation.IQROutliersBarPlot": {
    "inputs": {
      "dataset": null
    },
    "params": {
      "threshold": 1.5,
      "num_features": null,
      "fig_width": 800
    }
  },
  "validmind.data_validation.DescriptiveStatistics": {
    "inputs": {
      "dataset": null
    },
    "params": {}
  },
  "validmind.data_validation.PearsonCorrelationMatrix": {
    "inputs": {
      "dataset": null
    },
    "params": {}
  },
  "validmind.data_validation.HighPearsonCorrelation": {
    "inputs": {
      "dataset": null
    },
    "params": {
      "max_threshold": 0.3
    }
  },
  "validmind.model_validation.ModelMetadata": {
    "inputs": {
      "model": null
    },
    "params": {}
  },
  "validmind.data_validation.DatasetSplit": {
    "inputs": {
      "datasets": null
    },
    "params": {}
  },
  "validmind.model_validation.sklearn.PopulationStabilityIndex": {
    "inputs": {
      "model": null,
      "datasets": null
    },
    "params": {
      "num_bins": 10,
      "mode": "fixed"
    }
  },
  "validmind.model_validation.sklearn.ConfusionMatrix": {
    "inputs": {
      "model": null,
      "dataset": null
    },
    "params": {}
  },
  "validmind.model_validation.sklearn.ClassifierPerformance:in_sample": {
    "inputs": {
      "model": null,
      "dataset": null
    },
    "params": {}
  },
  "validmind.model_validation.sklearn.ClassifierPerformance:out_of_sample": {
    "inputs": {
      "model": null,
      "dataset": null
    },
    "params": {}
  },
  "validmind.model_validation.sklearn.PrecisionRecallCurve": {
    "inputs": {
      "model": null,
      "dataset": null
    },
    "params": {}
  },
  "validmind.model_validation.sklearn.ROCCurve": {
    "inputs": {
      "model": null,
      "dataset": null
    },
    "params": {}
  },
  "validmind.model_validation.sklearn.TrainingTestDegradation": {
    "inputs": {
      "model": null,
      "datasets": null
    },
    "params": {
      "metrics": [
        "accuracy",
        "precision",
        "recall",
        "f1"
      ],
      "max_threshold": 0.1
    }
  },
  "validmind.model_validation.sklearn.MinimumAccuracy": {
    "inputs": {
      "model": null,
      "dataset": null
    },
    "params": {
      "min_threshold": 0.7
    }
  },
  "validmind.model_validation.sklearn.MinimumF1Score": {
    "inputs": {
      "model": null,
      "dataset": null
    },
    "params": {
      "min_threshold": 0.5
    }
  },
  "validmind.model_validation.sklearn.MinimumROCAUCScore": {
    "inputs": {
      "model": null,
      "dataset": null
    },
    "params": {
      "min_threshold": 0.5
    }
  },
  "validmind.model_validation.sklearn.PermutationFeatureImportance": {
    "inputs": {
      "model": null,
      "dataset": null
    },
    "params": {
      "fontsize": null,
      "figure_height": 1000
    }
  },
  "validmind.model_validation.sklearn.SHAPGlobalImportance": {
    "inputs": {
      "model": null,
      "dataset": null
    },
    "params": {
      "kernel_explainer_samples": 10,
      "tree_or_linear_explainer_samples": 200
    }
  },
  "validmind.model_validation.sklearn.WeakspotsDiagnosis": {
    "inputs": {
      "model": null,
      "datasets": null
    },
    "params": {
      "features_columns": null,
      "thresholds": {
        "accuracy": 0.75,
        "precision": 0.5,
        "recall": 0.5,
        "f1": 0.7
      }
    }
  },
  "validmind.model_validation.sklearn.OverfitDiagnosis": {
    "inputs": {
      "model": null,
      "datasets": null
    },
    "params": {
      "features_columns": null,
      "cut_off_percentage": 4
    }
  },
  "validmind.model_validation.sklearn.RobustnessDiagnosis": {
    "inputs": {
      "model": null,
      "datasets": null
    },
    "params": {
      "features_columns": null,
      "scaling_factor_std_dev_list": [
        0.0,
        0.1,
        0.2,
        0.3,
        0.4,
        0.5
      ],
      "accuracy_decay_threshold": 4
    }
  }
}</code></pre>
</div>
</div>
<p><a id="toc7_2_1_"></a></p>
<section id="update-the-config" class="level4">
<h4 class="anchored" data-anchor-id="update-the-config">Update the config</h4>
<p>Note that the default config does not assign any inputs to a test, this is expected. You can assign inputs to individual tests as needed, depending on the datasets and models you want to pass to individual tests. The <code>config</code> dictionary, as a mapping of test IDs to test configurations, allows you to do this.</p>
<p>For this particular documentation template (binary classification), the Developer Framework provides a sample configuration that can be used to populate the entire model documentation using the following inputs as placeholders:</p>
<ul>
<li>A <code>raw_dataset</code> raw dataset</li>
<li>A <code>train_dataset</code> training dataset</li>
<li>A <code>test_dataset</code> test dataset</li>
<li>A trained <code>model</code> instance</li>
</ul>
<p>As part of updating the <code>config</code> you will need to ensure the correct <code>input_id</code>s are used in the final config passed to <code>run_documentation_tests()</code>.</p>
<div id="cell-96" class="cell" data-metadata="{}" data-execution_count="46">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> validmind.datasets.classification <span class="im">import</span> customer_churn</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> validmind.utils <span class="im">import</span> preview_test_config</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>test_config <span class="op">=</span> customer_churn.get_demo_test_config()</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>preview_test_config(test_config)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

    <script>
    function toggleOutput() {
        var content = document.getElementById("collapsibleContent");
        if (content.style.display === "none") {
            content.style.display = "block";
        } else {
            content.style.display = "none";
        }
    }
    </script>
    <button onclick="toggleOutput()">Preview Config</button>
    <div id="collapsibleContent" style="display:none;"><pre>{
    "validmind.data_validation.DatasetDescription": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {}
    },
    "validmind.data_validation.ClassImbalance": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {
            "min_percent_threshold": 10
        }
    },
    "validmind.data_validation.Duplicates": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {
            "min_threshold": 1
        }
    },
    "validmind.data_validation.HighCardinality": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {
            "num_threshold": 100,
            "percent_threshold": 0.1,
            "threshold_type": "percent"
        }
    },
    "validmind.data_validation.MissingValues": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {
            "min_threshold": 1
        }
    },
    "validmind.data_validation.Skewness": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {
            "max_threshold": 1
        }
    },
    "validmind.data_validation.UniqueRows": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {
            "min_percent_threshold": 1
        }
    },
    "validmind.data_validation.TooManyZeroValues": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {
            "max_percent_threshold": 0.03
        }
    },
    "validmind.data_validation.IQROutliersTable": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {
            "features": null,
            "threshold": 1.5
        }
    },
    "validmind.data_validation.IQROutliersBarPlot": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {
            "threshold": 1.5,
            "num_features": null,
            "fig_width": 800
        }
    },
    "validmind.data_validation.DescriptiveStatistics": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {}
    },
    "validmind.data_validation.PearsonCorrelationMatrix": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {}
    },
    "validmind.data_validation.HighPearsonCorrelation": {
        "inputs": {
            "dataset": "raw_dataset"
        },
        "params": {
            "max_threshold": 0.3
        }
    },
    "validmind.model_validation.ModelMetadata": {
        "inputs": {
            "model": "model"
        },
        "params": {}
    },
    "validmind.data_validation.DatasetSplit": {
        "inputs": {
            "datasets": [
                "train_dataset",
                "test_dataset"
            ]
        },
        "params": {}
    },
    "validmind.model_validation.sklearn.PopulationStabilityIndex": {
        "inputs": {
            "model": "model",
            "datasets": [
                "train_dataset",
                "test_dataset"
            ]
        },
        "params": {
            "num_bins": 10,
            "mode": "fixed"
        }
    },
    "validmind.model_validation.sklearn.ConfusionMatrix": {
        "inputs": {
            "model": "model",
            "dataset": "test_dataset"
        },
        "params": {}
    },
    "validmind.model_validation.sklearn.ClassifierPerformance:in_sample": {
        "inputs": {
            "model": "model",
            "dataset": "train_dataset"
        }
    },
    "validmind.model_validation.sklearn.ClassifierPerformance:out_of_sample": {
        "inputs": {
            "model": "model",
            "dataset": "test_dataset"
        }
    },
    "validmind.model_validation.sklearn.PrecisionRecallCurve": {
        "inputs": {
            "model": "model",
            "dataset": "test_dataset"
        },
        "params": {}
    },
    "validmind.model_validation.sklearn.ROCCurve": {
        "inputs": {
            "model": "model",
            "dataset": "test_dataset"
        },
        "params": {}
    },
    "validmind.model_validation.sklearn.TrainingTestDegradation": {
        "inputs": {
            "model": "model",
            "datasets": [
                "train_dataset",
                "test_dataset"
            ]
        },
        "params": {
            "metrics": [
                "accuracy",
                "precision",
                "recall",
                "f1"
            ],
            "max_threshold": 0.1
        }
    },
    "validmind.model_validation.sklearn.MinimumAccuracy": {
        "inputs": {
            "model": "model",
            "dataset": "test_dataset"
        },
        "params": {
            "min_threshold": 0.7
        }
    },
    "validmind.model_validation.sklearn.MinimumF1Score": {
        "inputs": {
            "model": "model",
            "dataset": "test_dataset"
        },
        "params": {
            "min_threshold": 0.5
        }
    },
    "validmind.model_validation.sklearn.MinimumROCAUCScore": {
        "inputs": {
            "model": "model",
            "dataset": "test_dataset"
        },
        "params": {
            "min_threshold": 0.5
        }
    },
    "validmind.model_validation.sklearn.PermutationFeatureImportance": {
        "inputs": {
            "model": "model",
            "dataset": "test_dataset"
        },
        "params": {
            "fontsize": null,
            "figure_height": 1000
        }
    },
    "validmind.model_validation.sklearn.SHAPGlobalImportance": {
        "inputs": {
            "model": "model",
            "dataset": "test_dataset"
        },
        "params": {
            "kernel_explainer_samples": 10,
            "tree_or_linear_explainer_samples": 200
        }
    },
    "validmind.model_validation.sklearn.WeakspotsDiagnosis": {
        "inputs": {
            "model": "model",
            "datasets": [
                "train_dataset",
                "test_dataset"
            ]
        },
        "params": {
            "features_columns": null,
            "thresholds": {
                "accuracy": 0.75,
                "precision": 0.5,
                "recall": 0.5,
                "f1": 0.7
            }
        }
    },
    "validmind.model_validation.sklearn.OverfitDiagnosis": {
        "inputs": {
            "model": "model",
            "datasets": [
                "train_dataset",
                "test_dataset"
            ]
        },
        "params": {
            "features_columns": null,
            "cut_off_percentage": 4
        }
    },
    "validmind.model_validation.sklearn.RobustnessDiagnosis": {
        "inputs": {
            "model": "model",
            "datasets": [
                "train_dataset",
                "test_dataset"
            ]
        },
        "params": {
            "features_columns": null,
            "scaling_factor_std_dev_list": [
                0.0,
                0.1,
                0.2,
                0.3,
                0.4,
                0.5
            ],
            "accuracy_decay_threshold": 4
        }
    }
}</pre></div>
    
</div>
</div>
<p>Using this sample configuration, let’s finish populating model documentation by running all tests for the <code>model_development</code> section of the documentation. Recall that the training and test datasets in our exercise have the following <code>input_id</code> values:</p>
<ul>
<li><code>train_dataset_final</code> for the training dataset</li>
<li><code>test_dataset_final</code> for the test dataset</li>
</ul>
<div id="cell-98" class="cell" data-metadata="{}" data-execution_count="47">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> {</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.ModelMetadata"</span>: {</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>},</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.data_validation.DatasetSplit"</span>: {</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"datasets"</span>: [<span class="st">"train_dataset_final"</span>, <span class="st">"test_dataset_final"</span>]},</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.PopulationStabilityIndex"</span>: {</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>,</span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>            <span class="st">"datasets"</span>: [<span class="st">"train_dataset_final"</span>, <span class="st">"test_dataset_final"</span>],</span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {<span class="st">"num_bins"</span>: <span class="dv">10</span>, <span class="st">"mode"</span>: <span class="st">"fixed"</span>},</span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.ConfusionMatrix"</span>: {</span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>, <span class="st">"dataset"</span>: <span class="st">"test_dataset_final"</span>},</span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"my_test_provider.ConfusionMatrix"</span>: {</span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"dataset"</span>: <span class="st">"test_dataset_final"</span>, <span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>},</span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.ClassifierPerformance:in_sample"</span>: {</span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>, <span class="st">"dataset"</span>: <span class="st">"train_dataset_final"</span>}</span>
<span id="cb69-23"><a href="#cb69-23" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-24"><a href="#cb69-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.ClassifierPerformance:out_of_sample"</span>: {</span>
<span id="cb69-25"><a href="#cb69-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>, <span class="st">"dataset"</span>: <span class="st">"test_dataset_final"</span>}</span>
<span id="cb69-26"><a href="#cb69-26" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-27"><a href="#cb69-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.PrecisionRecallCurve"</span>: {</span>
<span id="cb69-28"><a href="#cb69-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>, <span class="st">"dataset"</span>: <span class="st">"test_dataset_final"</span>},</span>
<span id="cb69-29"><a href="#cb69-29" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-30"><a href="#cb69-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.ROCCurve"</span>: {</span>
<span id="cb69-31"><a href="#cb69-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>, <span class="st">"dataset"</span>: <span class="st">"test_dataset_final"</span>},</span>
<span id="cb69-32"><a href="#cb69-32" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-33"><a href="#cb69-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.TrainingTestDegradation"</span>: {</span>
<span id="cb69-34"><a href="#cb69-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {</span>
<span id="cb69-35"><a href="#cb69-35" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>,</span>
<span id="cb69-36"><a href="#cb69-36" aria-hidden="true" tabindex="-1"></a>            <span class="st">"datasets"</span>: [<span class="st">"train_dataset_final"</span>, <span class="st">"test_dataset_final"</span>],</span>
<span id="cb69-37"><a href="#cb69-37" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb69-38"><a href="#cb69-38" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {</span>
<span id="cb69-39"><a href="#cb69-39" aria-hidden="true" tabindex="-1"></a>            <span class="st">"metrics"</span>: [<span class="st">"accuracy"</span>, <span class="st">"precision"</span>, <span class="st">"recall"</span>, <span class="st">"f1"</span>],</span>
<span id="cb69-40"><a href="#cb69-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">"max_threshold"</span>: <span class="fl">0.1</span>,</span>
<span id="cb69-41"><a href="#cb69-41" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb69-42"><a href="#cb69-42" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-43"><a href="#cb69-43" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.MinimumAccuracy"</span>: {</span>
<span id="cb69-44"><a href="#cb69-44" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>, <span class="st">"dataset"</span>: <span class="st">"test_dataset_final"</span>},</span>
<span id="cb69-45"><a href="#cb69-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {<span class="st">"min_threshold"</span>: <span class="fl">0.7</span>},</span>
<span id="cb69-46"><a href="#cb69-46" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-47"><a href="#cb69-47" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.MinimumF1Score"</span>: {</span>
<span id="cb69-48"><a href="#cb69-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>, <span class="st">"dataset"</span>: <span class="st">"test_dataset_final"</span>},</span>
<span id="cb69-49"><a href="#cb69-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {<span class="st">"min_threshold"</span>: <span class="fl">0.5</span>},</span>
<span id="cb69-50"><a href="#cb69-50" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-51"><a href="#cb69-51" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.MinimumROCAUCScore"</span>: {</span>
<span id="cb69-52"><a href="#cb69-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>, <span class="st">"dataset"</span>: <span class="st">"test_dataset_final"</span>},</span>
<span id="cb69-53"><a href="#cb69-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {<span class="st">"min_threshold"</span>: <span class="fl">0.5</span>},</span>
<span id="cb69-54"><a href="#cb69-54" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-55"><a href="#cb69-55" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.PermutationFeatureImportance"</span>: {</span>
<span id="cb69-56"><a href="#cb69-56" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>, <span class="st">"dataset"</span>: <span class="st">"test_dataset_final"</span>},</span>
<span id="cb69-57"><a href="#cb69-57" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-58"><a href="#cb69-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.SHAPGlobalImportance"</span>: {</span>
<span id="cb69-59"><a href="#cb69-59" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {<span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>, <span class="st">"dataset"</span>: <span class="st">"test_dataset_final"</span>},</span>
<span id="cb69-60"><a href="#cb69-60" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {<span class="st">"kernel_explainer_samples"</span>: <span class="dv">10</span>},</span>
<span id="cb69-61"><a href="#cb69-61" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-62"><a href="#cb69-62" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.WeakspotsDiagnosis"</span>: {</span>
<span id="cb69-63"><a href="#cb69-63" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {</span>
<span id="cb69-64"><a href="#cb69-64" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>,</span>
<span id="cb69-65"><a href="#cb69-65" aria-hidden="true" tabindex="-1"></a>            <span class="st">"datasets"</span>: [<span class="st">"train_dataset_final"</span>, <span class="st">"test_dataset_final"</span>],</span>
<span id="cb69-66"><a href="#cb69-66" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb69-67"><a href="#cb69-67" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {</span>
<span id="cb69-68"><a href="#cb69-68" aria-hidden="true" tabindex="-1"></a>            <span class="st">"thresholds"</span>: {<span class="st">"accuracy"</span>: <span class="fl">0.75</span>, <span class="st">"precision"</span>: <span class="fl">0.5</span>, <span class="st">"recall"</span>: <span class="fl">0.5</span>, <span class="st">"f1"</span>: <span class="fl">0.7</span>}</span>
<span id="cb69-69"><a href="#cb69-69" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb69-70"><a href="#cb69-70" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-71"><a href="#cb69-71" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.OverfitDiagnosis"</span>: {</span>
<span id="cb69-72"><a href="#cb69-72" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {</span>
<span id="cb69-73"><a href="#cb69-73" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>,</span>
<span id="cb69-74"><a href="#cb69-74" aria-hidden="true" tabindex="-1"></a>            <span class="st">"datasets"</span>: [<span class="st">"train_dataset_final"</span>, <span class="st">"test_dataset_final"</span>],</span>
<span id="cb69-75"><a href="#cb69-75" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb69-76"><a href="#cb69-76" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {<span class="st">"cut_off_percentage"</span>: <span class="dv">4</span>},</span>
<span id="cb69-77"><a href="#cb69-77" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-78"><a href="#cb69-78" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validmind.model_validation.sklearn.RobustnessDiagnosis"</span>: {</span>
<span id="cb69-79"><a href="#cb69-79" aria-hidden="true" tabindex="-1"></a>        <span class="st">"inputs"</span>: {</span>
<span id="cb69-80"><a href="#cb69-80" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="st">"log_reg_model_v1"</span>,</span>
<span id="cb69-81"><a href="#cb69-81" aria-hidden="true" tabindex="-1"></a>            <span class="st">"datasets"</span>: [<span class="st">"train_dataset_final"</span>, <span class="st">"test_dataset_final"</span>],</span>
<span id="cb69-82"><a href="#cb69-82" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb69-83"><a href="#cb69-83" aria-hidden="true" tabindex="-1"></a>        <span class="st">"params"</span>: {</span>
<span id="cb69-84"><a href="#cb69-84" aria-hidden="true" tabindex="-1"></a>            <span class="st">"scaling_factor_std_dev_list"</span>: [<span class="fl">0.0</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span>, <span class="fl">0.5</span>],</span>
<span id="cb69-85"><a href="#cb69-85" aria-hidden="true" tabindex="-1"></a>            <span class="st">"accuracy_decay_threshold"</span>: <span class="dv">4</span>,</span>
<span id="cb69-86"><a href="#cb69-86" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb69-87"><a href="#cb69-87" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb69-88"><a href="#cb69-88" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-89"><a href="#cb69-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-90"><a href="#cb69-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-91"><a href="#cb69-91" aria-hidden="true" tabindex="-1"></a>full_suite <span class="op">=</span> vm.run_documentation_tests(</span>
<span id="cb69-92"><a href="#cb69-92" aria-hidden="true" tabindex="-1"></a>    section<span class="op">=</span><span class="st">"model_development"</span>,</span>
<span id="cb69-93"><a href="#cb69-93" aria-hidden="true" tabindex="-1"></a>    config<span class="op">=</span>config,</span>
<span id="cb69-94"><a href="#cb69-94" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-06-12 16:28:23,699 - WARNING(validmind.vm_models.test_suite.runner): Config key 'my_test_provider.ConfusionMatrix' does not match a test_id in the template.
    Ensure you registered a content block with the correct content_id in the template
    The configuration for this test will be ignored.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8406238610ca48898c98f3e27a1350f1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names

/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names

/Users/beckchan/Library/Caches/pypoetry/virtualenvs/validmind-PDdiQnuU-py3.10/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning:

X does not have valid feature names, but LogisticRegression was fitted with feature names
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"67e9c65c4b124c368359fbb528a5850d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<script defer="" type="module">
import hljs from 'https://unpkg.com/@highlightjs/cdn-assets@11.9.0/es/highlight.min.js';
import python from 'https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/es/languages/python.min.js';

hljs.registerLanguage('python', python);
hljs.highlightAll();
</script>
</div>
<div class="cell-output cell-output-display">

<script>
window.MathJax = {
    tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreClass: ".*",
        processClass: "math"
    }
};
setTimeout(function () {
    var script = document.createElement('script');
    script.type = 'text/javascript';
    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML';
    document.head.appendChild(script);
}, 300);
</script>
</div>
</div>
<p><a id="toc8_"></a></p>
</section>
</section>
</section>
<section id="where-to-go-from-here" class="level2">
<h2 class="anchored" data-anchor-id="where-to-go-from-here">Where to go from here</h2>
<p>In this notebook you have learned the end-to-end process to document a model with the ValidMind Developer Framework, running through some very common scenarios in a typical model development setting:</p>
<ul>
<li>Running out-of-the-box tests</li>
<li>Documenting your model by adding evidence to model documentation</li>
<li>Extending the capabilities of the Developer Framework by implementing custom tests</li>
<li>Ensuring that the documentation is complete by running all tests in the documentation template</li>
</ul>
<p>As a next step, you can explore the following notebooks to get a deeper understanding on how the developer framework allows you generate model documentation for any use case:</p>
<p><a id="toc8_1_"></a></p>
<section id="use-cases" class="level3">
<h3 class="anchored" data-anchor-id="use-cases">Use cases</h3>
<ul>
<li><a href="../../notebooks/code_samples/credit_risk/application_scorecard_demo.html">Application scorecard demo</a></li>
<li><a href="../../notebooks/code_samples/regression/quickstart_regression_full_suite.html">Linear regression documentation demo</a></li>
<li><a href="../code_samples/nlp_and_llm/foundation_models_integration_demo.ipynb">LLM model documentation demo</a></li>
</ul>
<p><a id="toc8_2_"></a></p>
</section>
<section id="more-how-to-guides-and-code-samples" class="level3">
<h3 class="anchored" data-anchor-id="more-how-to-guides-and-code-samples">More how-to guides and code samples</h3>
<ul>
<li><a href="../../notebooks/how_to/explore_tests.html">Explore available tests in detail</a></li>
<li><a href="../../notebooks/code_samples/custom_tests/implement_custom_tests.html">In-depth guide for implementing custom tests</a></li>
<li><a href="../../notebooks/code_samples/custom_tests/integrate_external_test_providers.html">In-depth guide to external test providers</a></li>
<li><a href="../../notebooks/how_to/configure_dataset_features.html">Configuring dataset features</a></li>
<li><a href="../../notebooks/how_to/run_unit_metrics.html">Introduction to unit and composite metrics</a></li>
</ul>
<p><a id="toc8_3_"></a></p>
</section>
<section id="discover-more-learning-resources" class="level3">
<h3 class="anchored" data-anchor-id="discover-more-learning-resources">Discover more learning resources</h3>
<p>All notebook samples can be found in the following directories of the Developer Framework GitHub repository:</p>
<ul>
<li><a href="https://github.com/validmind/developer-framework/tree/main/notebooks/code_samples">Code samples</a></li>
<li><a href="https://github.com/validmind/developer-framework/tree/main/notebooks/how_to">How-to guides</a></li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2023-2024 ValidMind Inc.&nbsp;All Rights Reserved.</p>
</div>   
    <div class="nav-footer-center">

<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/validmind/documentation/blob/main/site/notebooks/tutorials/intro_for_model_developers_EXECUTED.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/validmind/documentation/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://validmind.com/" target="_blank">
<p>validmind.com <i class="fa-solid fa-external-link" aria-label="external-link"></i></p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://validmind.com/privacy-policy/">
<p>Privacy Policy</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://validmind.com/terms-of-use/">
<p>Terms of Use</p>
</a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/validmind/documentation">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/company/validmind/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>