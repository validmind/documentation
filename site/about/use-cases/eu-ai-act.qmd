---
title: "EU AI Act"
date: last-modified
---

This guide provides detailed, step-by-step guidance on implementing EU AI Act compliance using {{< var vm.product >}}. 

The documentation will:

1. Walk you through the practical steps required to implement what is shown in the demo.

2. Link to existing documentation for specific product features.

3. Focus on actionable implementation rather than just explaining requirements.

4. Link to training resources where relevant.

## Overview

The EU AI Act establishes requirements across six key areas for high-risk AI systems. This guide is organized around these requirements to help you set up {{< var vm.product >}} for compliance.

### Quick reference to risk classifications

The EU AI Act categorizes AI systems by risk level:

- **Prohibited** — AI systems that pose unacceptable risks (e.g., social scoring, real-time biometric identification in public spaces).

- **High-risk** — AI systems in critical areas requiring strict compliance (e.g., employment, credit scoring, law enforcement).

- **Limited risk** — AI systems with transparency obligations (e.g., chatbots, emotion recognition).

- **Minimal risk** — AI systems with no specific requirements.

### Harmonization with other standards

The EU AI Act requirements overlap with existing model risk management frameworks. Organizations already following SR 11-7, SS1/23, or E-23 can leverage existing documentation and controls.

---

## 1. Risk management system implementation (Article 9)

**Purpose:** Set up a risk management system in {{< var vm.product >}} to identify, evaluate, and mitigate risks at all stages of the AI system's lifecycle.

### Steps

1. Complete the risk classification questionnaire:
   - Configure custom inventory fields to capture EU AI Act risk classification.
   - Set up fields for prohibited, high-risk, limited-risk, and minimal-risk categories.

2. Map fields to EU AI Act requirements:
   - Create custom fields aligned to Article 9 requirements.
   - Document risk assessment criteria and thresholds.

3. Set up custom workflows for different risk levels:
   - Configure approval workflows based on risk classification.
   - High-risk systems require additional review gates.

::: {.callout title="Related documentation"}
- [Manage model inventory fields](/guide/model-inventory/manage-model-inventory-fields.qmd)
- [Configure workflows](/guide/workflows/configure-workflows.qmd)
:::

---

## 2. Data governance setup (Article 10)

**Purpose:** Implement data quality controls and bias detection to meet Article 10 requirements for training, validation, and testing data.

### Steps

1. Initialize the {{< var vm.developer >}}:
   - Set up the developer environment for data quality testing.
   - Connect to your data sources.

2. Implement out-of-the-box data quality tests:
   - Run automated tests for data completeness, accuracy, and relevance.
   - Document data quality metrics.

3. Create custom tests for your specific data requirements:
   - Extend the test framework for domain-specific quality checks.
   - Implement bias detection tests.

4. Centralize governance for oversight:
   - Configure dashboards to monitor data quality across systems.
   - Set up alerts for data quality issues.

::: {.callout title="Related documentation"}
- [Run tests](/developer/model-testing/run-tests.qmd)
- [Create custom tests](/developer/model-testing/create-custom-tests.qmd)
:::

---

## 3. Technical documentation management (Article 11)

**Purpose:** Generate and customize required model documentation to meet Article 11 requirements for technical documentation.

### Steps

1. Work with documentation templates:
   - Select or create templates aligned to EU AI Act requirements.
   - Configure sections for system description, design, and compliance.

2. Discover and use tests:
   - Map available tests to Article 11 documentation requirements.
   - Run tests to generate evidence

3. Customize sections for specific use cases:
   - Add custom sections for AI system-specific requirements.
   - Document intended purpose, design choices, and limitations.

4. Leverage AI-assisted documentation features:
   - Use document generation to accelerate documentation.
   - Review and refine AI-generated content.

5. Add content blocks:
   - Insert additional evidence and documentation, as needed.
   - Link artifacts to documentation sections.

::: {.callout title="Related documentation"}
- [Work with document templates](/guide/templates/working-with-document-templates.qmd)
- [Discover and use tests](/developer/model-testing/discover-and-use-tests.qmd)
:::

---

## 4. Accuracy and robustness validation (Article 15)

**Purpose:** Validate model accuracy and demonstrate robustness to meet Article 15 requirements.

### Steps

1. Prepare validation reports:
   - Set up validation report templates
   - Configure validation workflows

2. Link evidence to compliance requirements:
   - Map test results to Article 15 requirements
   - Document accuracy metrics and thresholds

3. Create and document challenger models:
   - Implement challenger model workflows
   - Compare performance across models

4. Record findings and remediations:
   - Track validation findings
   - Document remediation actions

5. Assess compliance:
   - Generate compliance summaries
   - Review against Article 15 criteria

::: {.callout title="Related documentation"}
- [Prepare validation reports](/guide/model-validation/preparing-validation-reports.qmd)
- [Work with findings](/guide/model-validation/working-with-findings.qmd)
:::

---

## 5. Transparency implementation (Article 13)

**Purpose:** Set up transparent reporting and decision explanations to meet Article 13 requirements.

### Steps

1. Work with analytics for non-technical stakeholders:
   - Configure dashboards for business users
   - Create accessible summaries of AI system behavior

2. Set up custom dashboards:
   - Build dashboards showing key transparency metrics
   - Include interpretability information

3. Set up decision explanation frameworks:
   - Document how AI systems make decisions
   - Implement explainability features

::: {.callout title="Related documentation"}
- [Work with analytics](/guide/reporting/working-with-analytics.qmd)
- [Customize your dashboard](/guide/configuration/customize-your-dashboard.qmd)
:::

---

## 6. Human oversight configuration (Article 14)

**Purpose:** Implement human oversight capabilities to meet Article 14 requirements.

### Steps

1. Configure ongoing monitoring:
   - Set up monitoring workflows
   - Define monitoring metrics and thresholds

2. Set up alerts and thresholds:
   - Configure alerts for performance degradation
   - Establish escalation procedures

3. Create human review workflows:
   - Implement review gates for high-risk decisions
   - Document human-in-the-loop processes

4. Document intervention processes:
   - Define procedures for human override
   - Track intervention decisions

::: {.callout title="Related documentation"}
- [Set up ongoing monitoring](/guide/monitoring/set-up-ongoing-monitoring.qmd)
- [Configure workflows](/guide/workflows/configure-workflows.qmd)
:::

---

## 7. Compliance workflow implementation

**Purpose:** Integrate all components into a complete compliance workflow addressing Articles 43, 60, 61, and 62.

### Steps

1. Set up the conformity assessment process (Article 43):
   - Configure end-to-end compliance workflows
   - Document conformity assessment procedures

2. Register high-risk systems (Article 60):
   - Maintain EU database registration information
   - Track registration status

3. Implement post-market monitoring (Article 61):
   - Set up ongoing monitoring for deployed systems
   - Configure incident detection

4. Establish incident reporting procedures (Article 62):
   - Define incident reporting workflows
   - Document escalation procedures

::: {.callout title="Related documentation"}
- [Configure workflows](/guide/workflows/configure-workflows.qmd)
- [Set up ongoing monitoring](/guide/monitoring/set-up-ongoing-monitoring.qmd)
:::
