---
title: "EU AI Act"
date: last-modified
---

Implement EU AI Act compliance using {{< var vm.product >}}.

{{< include _use-case-summary.qmd >}}

## Overview

The EU AI Act[^1] establishes requirements across six key areas for high-risk AI systems. This guide is organized around these requirements to help you set up {{< var vm.product >}} for compliance.

### Quick reference to risk classifications

The EU AI Act categorizes AI systems by risk level:

- **Prohibited** — AI systems that pose unacceptable risks (e.g., social scoring, real-time biometric identification in public spaces).

- **High-risk** — AI systems in critical areas requiring strict compliance (e.g., employment, credit scoring, law enforcement).

- **Limited risk** — AI systems with transparency obligations (e.g., chatbots, emotion recognition).

- **Minimal risk** — AI systems with no specific requirements.

### Harmonization with other standards

The EU AI Act requirements overlap with existing model risk management frameworks. Organizations already following SR 11-7, SS1/23, or E-23 can  leverage existing documentation and controls but must also comply with the EU AI Act requirements.

## 1. Risk management system implementation (Article 9)

#### Purpose
Set up a risk management system in the {{< var validmind.platform >}} to identify, evaluate, and mitigate risks at all stages of the AI system's lifecycle.

### Steps

1. Complete the risk classification questionnaire:

   - Configure custom inventory fields[^2] to capture EU AI Act risk classification.
   - Set up fields for prohibited, high-risk, limited-risk, and minimal-risk categories.

2. Map fields to EU AI Act requirements:

   - Create custom fields aligned to Article 9 requirements.
   - Document risk assessment criteria and thresholds.

3. Set up custom workflows[^3] for different risk levels:

   - Configure approval workflows based on risk classification.
   - High-risk systems require additional review gates.

## 2. Data governance setup (Article 10)

#### Purpose
Implement data quality controls and bias detection to meet Article 10 requirements for training, validation, and testing data.

### Steps

1. Initialize the {{< var validmind.developer >}}:[^4]

   - Set up the developer environment for data quality testing.
   - Connect to your data sources.

2. Implement out-of-the-box data quality tests:[^5]

   - Run automated tests for data completeness, accuracy, and relevance.
   - Document data quality metrics.

3. Create custom tests for your specific data requirements:

   - Extend the test framework for domain-specific quality checks.
   - Implement bias detection tests.

4. Centralize governance for oversight:

   - Configure dashboards to monitor data quality across systems.
   - Set up alerts for data quality issues.

## 3. Technical documentation management (Article 11)

#### Purpose
Generate and customize required model documentation to meet Article 11 requirements for technical documentation.

### Steps

1. Work with documentation templates:[^6]

   - Select or create templates aligned to EU AI Act requirements.
   - Configure sections for system description, design, and compliance.

2. Discover and use tests:[^7]

   - Map available tests to Article 11 documentation requirements.
   - Run tests to generate evidence

3. Customize sections for specific use cases:

   - Add custom sections for AI system-specific requirements.
   - Document intended purpose, design choices, and limitations.

4. Leverage AI-assisted documentation features:

   - Use document generation to accelerate documentation.
   - Review and refine AI-generated content.

5. Add content blocks:[^8]

   - Insert additional evidence and documentation, as needed.
   - Link artifacts to documentation sections.

## 4. Accuracy and robustness validation (Article 15)

#### Purpose
Validate model accuracy and demonstrate robustness to meet Article 15 requirements.

### Steps

1. Prepare validation reports:[^9]

   - Set up validation report templates
   - Configure validation workflows

2. Link evidence to compliance requirements:

   - Map test results to Article 15 requirements
   - Document accuracy metrics and thresholds

3. Create and document challenger models:

   - Implement challenger model workflows
   - Compare performance across models

4. Record findings and remediations:[^10]

   - Track validation findings
   - Document remediation actions

5. Assess compliance:

   - Generate compliance summaries
   - Review against Article 15 criteria

## 5. Transparency implementation (Article 13)

#### Purpose
Set up transparent reporting and decision explanations to meet Article 13 requirements.

### Steps

1. Work with analytics[^11] for non-technical stakeholders:

   - Configure dashboards for business users
   - Create accessible summaries of AI system behavior

2. Set up custom dashboards:[^12]

   - Build dashboards showing key transparency metrics
   - Include interpretability information

3. Set up decision explanation frameworks:

   - Document how AI systems make decisions
   - Implement explainability features

## 6. Human oversight configuration (Article 14)

#### Purpose
Implement human oversight capabilities to meet Article 14 requirements.

### Steps

1. Configure ongoing monitoring:[^13]

   - Set up monitoring workflows
   - Define monitoring metrics and thresholds

2. Set up alerts and thresholds:

   - Configure alerts for performance degradation
   - Establish escalation procedures

3. Create human review workflows:

   - Implement review gates for high-risk decisions
   - Document human-in-the-loop processes

4. Document intervention processes:

   - Define procedures for human override
   - Track intervention decisions

## 7. Compliance workflow implementation

#### Purpose
Integrate all components into a complete compliance workflow addressing Articles 43, 60, 61, and 62.

### Steps

1. Set up the conformity assessment process (Article 43):

   - Configure end-to-end compliance workflows[^14]
   - Document conformity assessment procedures[^15]

2. Register high-risk systems (Article 60):[^16]

   - Maintain EU database registration information
   - Track registration status

3. Implement post-market monitoring (Article 61):[^17]

   - Set up ongoing monitoring for deployed systems
   - Configure incident detection

4. Establish incident reporting procedures (Article 62):

   - Define incident reporting workflows
   - Document escalation procedures


<!-- FOOTNOTES -->
[^1]:

   **EUR-Lex:**<br>
   [EU AI Act (Regulation (EU) 2024/1689)](https://eur-lex.europa.eu/eli/reg/2024/1689)

[^2]: [Manage model inventory fields](/guide/model-inventory/manage-model-inventory-fields.qmd)

[^3]: [Setting up workflows](/guide/workflows/setting-up-workflows.qmd)

[^4]: [Install and initialize the {{< var validmind.developer >}}](/developer/model-documentation/install-and-initialize-validmind-library.qmd)

 [^5]:
[Run tests and test suites](/developer/model-testing/testing-overview.qmd)

[^6]: [Work with document templates](/guide/templates/working-with-document-templates.qmd)

[^7]: [Test descriptions](/developer/model-testing/test-descriptions.qmd)

[^8]: [Work with content blocks](/guide/model-documentation/work-with-content-blocks.qmd)

[^9]: [Prepare validation reports](/guide/model-validation/preparing-validation-reports.qmd)

[^10]: [Work with artifacts](/guide/model-validation/working-with-artifacts.qmd)

[^11]: [Work with analytics](/guide/reporting/working-with-analytics.qmd)

[^12]: [Customize your dashboard](/guide/configuration/customize-your-dashboard.qmd)

[^13]: [Ongoing monitoring](/guide/monitoring/ongoing-monitoring.qmd)

[^14]: [Setting up workflows](/guide/workflows/setting-up-workflows.qmd)

[^15]: [Working with model documentation](/guide/model-documentation/working-with-model-documentation.qmd)

[^16]: [Working with the model inventory](/guide/model-inventory/working-with-model-inventory.qmd)

[^17]: [Ongoing monitoring](/guide/monitoring/ongoing-monitoring.qmd)

