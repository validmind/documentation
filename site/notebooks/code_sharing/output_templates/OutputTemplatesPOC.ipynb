{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Output Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser\n",
    "from jinja2 import Environment, Template\n",
    "\n",
    "\n",
    "def format_date(value, format='%Y-%m-%d'):\n",
    "    if value is None:\n",
    "        return None\n",
    "\n",
    "    if isinstance(value, datetime):\n",
    "        return value.strftime(format)\n",
    "\n",
    "    return parser.parse(value).strftime(format)\n",
    "\n",
    "\n",
    "def format_number(value, format='{:,.2f}'):\n",
    "    return format.format(value)\n",
    "\n",
    "env = Environment()\n",
    "env.filters['date'] = format_date\n",
    "env.filters['number'] = format_number\n",
    "\n",
    "\n",
    "def template_to_react_tables(template_string, metric_data, metric_data_historical):\n",
    "    # Render the template with Jinja\n",
    "    template = env.from_string(template_string)\n",
    "    rendered_html = template.render(value=metric_data, metric_history=metric_data_historical)\n",
    "\n",
    "    return parse_html_to_react_table(rendered_html)\n",
    "\n",
    "\n",
    "def parse_html_to_react_table(rendered_html):\n",
    "    soup = BeautifulSoup(rendered_html, 'html.parser')\n",
    "\n",
    "    # find all `<MetricTable>` elements\n",
    "    tables = soup.find_all('metrictable')\n",
    "    tables_data = []\n",
    "\n",
    "    for table in tables:\n",
    "        # Extract columns\n",
    "        columns = []\n",
    "        headers = table.find_all('th')\n",
    "        for header in headers:\n",
    "            columns.append({\n",
    "                \"Header\": header.text,\n",
    "                \"accessor\": header.text.lower().replace(\" \", \"_\")\n",
    "            })\n",
    "\n",
    "        # Extract data\n",
    "        data = []\n",
    "        rows = table.find('tbody').find_all('tr')\n",
    "        for row in rows:\n",
    "            row_data = {}\n",
    "            for idx, cell in enumerate(row.find_all('td')):\n",
    "                accessor = columns[idx][\"accessor\"]\n",
    "                row_data[accessor] = cell.text\n",
    "            data.append(row_data)\n",
    "\n",
    "        tables_data.append((data, columns))\n",
    "\n",
    "    return tables_data\n",
    "\n",
    "def parse_summary_from_html(rendered_template_html):\n",
    "    soup = BeautifulSoup(rendered_template_html, \"html.parser\")\n",
    "\n",
    "    # find all `<table>` elements\n",
    "    tables = soup.find_all(\"table\")\n",
    "    tables_data = []\n",
    "\n",
    "    for table in tables:\n",
    "        headers = [cell.text for cell in table.find_all(\"th\")]\n",
    "\n",
    "        tables_data.append({\n",
    "            \"type\": \"table\",\n",
    "            \"data\": [\n",
    "                {\n",
    "                    headers[i]: cell.text\n",
    "                    for i, cell in enumerate(row.find_all(\"td\"))\n",
    "                }\n",
    "                for row in table.find_all(\"tr\")\n",
    "            ],\n",
    "            \"metadata\": {\"title\": \"\"}, # TODO: add title\n",
    "        })\n",
    "\n",
    "    return tables_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "output_template = \"\"\"\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Accuracy</th>\n",
    "            <th>Precision</th>\n",
    "            <th>Recall</th>\n",
    "            <th>F1 Score</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>{{ value[\"accuracy\"] }}</td>\n",
    "            <td>{{ value[\"weighted avg\"][\"precision\"] }}</td>\n",
    "            <td>{{ value[\"weighted avg\"][\"recall\"] }}</td>\n",
    "            <td>{{ value[\"weighted avg\"][\"f1-score\"] }}</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"class_perf_value.json\") as f:\n",
    "    metric_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, columns = template_to_react_tables(output_template, metric_data, [])[0]\n",
    "\n",
    "print(json.dumps(data, indent=2))\n",
    "print()\n",
    "print(json.dumps(columns, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.from_string(output_template).render(value=metric_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Data in HTML Output Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_metric_template = \"\"\"\n",
    "<MetricTable>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Date</th>\n",
    "            <th>Accuracy</th>\n",
    "            <th>Precision</th>\n",
    "            <th>Recall</th>\n",
    "            <th>F1 Score</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        {% for item in metric_history %}\n",
    "        <tr>\n",
    "            <td>{{ item[\"metadata\"][\"created_at\"] | date }}</td>\n",
    "            <td>{{ item[\"value\"][\"accuracy\"] | number }}</td>\n",
    "            <td>{{ item[\"value\"][\"weighted avg\"][\"precision\"] }}</td>\n",
    "            <td>{{ item[\"value\"][\"weighted avg\"][\"recall\"] }}</td>\n",
    "            <td>{{ item[\"value\"][\"weighted avg\"][\"f1-score\"] }}</td>\n",
    "        </tr>\n",
    "        {% endfor %}\n",
    "    </tbody>\n",
    "</MetricTable>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"class_perf_value_history.json\") as f:\n",
    "    metric_data_historical = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = template_to_react_tables(monitoring_metric_template, metric_data_historical[0][\"value\"], metric_data_historical)\n",
    "\n",
    "for table in tables:\n",
    "    data, columns = table\n",
    "    print(json.dumps(data, indent=2))\n",
    "    print()\n",
    "    print(json.dumps(columns, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Summary Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_template_to_summary(template, data):\n",
    "    rendered = Template(template).render(value=data)\n",
    "    return json.loads(rendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_json_template = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"type\": \"table\",\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"Accuracy\": \"{{ value['accuracy'] }}\",\n",
    "                \"Precision\": \"{{ value['weighted avg']['precision'] }}\",\n",
    "                \"Recall\": \"{{ value['weighted avg']['recall'] }}\",\n",
    "                \"F1 Score\": \"{{ value['weighted avg']['f1-score'] }}\"\n",
    "            }\n",
    "        ],\n",
    "        \"metadata\": {\n",
    "            \"title\": \"Custom Classifier Performance\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = json_template_to_summary(simple_json_template, metric_data)\n",
    "\n",
    "print(json.dumps(summary, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_json_template = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"type\": \"table\",\n",
    "        \"data\": [\n",
    "            {% for row in value %}\n",
    "                {\n",
    "                    \"Bin\": \"{{ row['bin'] }}\",\n",
    "                    \"PSI\": \"{{ row['psi'] }}\"\n",
    "                }{% if not loop.last %},{% endif %}\n",
    "            {% endfor %}\n",
    "        ],\n",
    "        \"metadata\": {\n",
    "            \"title\": \"Custom Classifier Performance\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"psi_value.json\") as f:\n",
    "    metric_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = json_template_to_summary(complex_json_template, metric_data)\n",
    "\n",
    "print(json.dumps(summary, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Query Language for Output Templates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-backend-QxegaiB7-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
