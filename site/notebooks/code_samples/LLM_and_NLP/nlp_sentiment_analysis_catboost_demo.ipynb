{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Sentiment Analysis with CatBoost\n",
    "\n",
    "This notebook introduces model developers to documenting a natural language processing (NLP) model with the ValidMind Developer Framework. The use case is sentiment analysis of COVID-19-related tweets, categorized as positive or negative. The model employs binary text classification using the CatBoost library. The notebook guides you through setting up the ValidMind Developer Framework, initializing the client library, and loading a sample dataset for training. It then runs the framework's model validation tests to generate documentation on the data and model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ValidMind at a glance\n",
    "\n",
    "ValidMind's platform enables organizations to identify, document, and manage model risks for all types of models, including AI/ML models, LLMs, and statistical models. As a model developer, you use the ValidMind Developer Framework to automate documentation and validation tests, and then use the ValidMind AI Risk Platform UI to collaborate on documentation projects. Together, these products simplify model risk management, facilitate compliance with regulations and institutional standards, and enhance collaboration between yourself and model validators.\n",
    "\n",
    "If this is your first time trying out ValidMind, we recommend going through the following resources first:\n",
    "\n",
    "- [Get started](https://docs.validmind.ai/guide/get-started.html) — The basics, including key concepts, and how our products work\n",
    "- [Get started with the ValidMind Developer Framework](https://docs.validmind.ai/guide/get-started-developer-framework.html) —  The path for developers, more code samples, and our developer reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "::: {.callout-tip}\n",
    "### New to ValidMind? \n",
    "For access to all features available in this notebook, create a free ValidMind account. \n",
    "\n",
    "Signing up is FREE — [**Sign up now**](https://app.prod.validmind.ai)\n",
    ":::\n",
    "\n",
    "If you encounter errors due to missing modules in your Python environment, install the modules with `pip install`, and then re-run the notebook. For more help, refer to [Installing Python Modules](https://docs.python.org/3/installing/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the client library\n",
    "\n",
    "The client library provides Python support for the ValidMind Developer Framework. To install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q validmind"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "Every documentation project in the Platform UI comes with a _code snippet_ that lets the client library associate your documentation and tests with the right project on the Platform UI when you run this notebook.\n",
    "\n",
    "Get your code snippet by creating a documentation project:\n",
    "\n",
    "1. In a browser, log into the [Platform UI](https://app.prod.validmind.ai).\n",
    "\n",
    "2. Go to Go to **Documentation Projects** and click **Create new project**.\n",
    "\n",
    "<!--- NR TO DO this model doesn't exist in the inventory --->\n",
    "3. Select **`NLP-based Text Classification`** and **`Initial Validation`** for the model name and type, give the project a unique  name to make it yours, and then click **Create project**.\n",
    "\n",
    "4. Go to **Documentation Projects** > **YOUR_UNIQUE_PROJECT_NAME** > **Getting Started** and click **Copy snippet to clipboard**.\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace with code snippet from your documentation project ##\n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"https://api.prod.validmind.ai/api/v1/tracking\",\n",
    "  api_key = \"...\",\n",
    "  api_secret = \"...\",\n",
    "  project = \"...\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explorary data analysis of COVID-19 tweets data\n",
    "The emphasis in this section is on the in-depth analysis and preprocessing of the text data (tweets). In this section, we introduce the manually tagged COVID-19 tweets, which range from Highly Negative to Highly Positive, representing five distinct classes. In this Exploratory Data Analysis (EDA), these five classes will be simplified to two classes: Positive and Negative.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Python environment\n",
    "\n",
    "Next, let's initialize the environment and imports libraries for data manipulation, machine learning, and plotting, followed by configuring PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env PYTORCH_MPS_HIGH_WATERMARK_RATIO 0.8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "train_model = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load COVID-19 tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.datasets.nlp import twitter_covid_19 as demo_data\n",
    "df = demo_data.load_data()\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run text data quality test suite\n",
    "In this section, we use the ValidMind Developer Framework to run various data quality checks on the dataset, and send the results to the model document on the ValidMind Platform UI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_ds = vm.init_dataset(dataset=df, type=\"generic\", text_column='OriginalTweet', target_column=\"Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"class_imbalance\":{\"min_percent_threshold\": 3}\n",
    "}\n",
    "text_data_test_suite = vm.run_test_suite(\"text_data_quality\",\n",
    "                                       inputs = {\"dataset\":vm_ds},\n",
    "                                       config=config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle class bias \n",
    "\n",
    "One way to handle class bias is to merge a specific class data with related class. Here, we copy the text and class lables in separate columns so that the original text is also there for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Classes:\", df.Sentiment.unique())\n",
    "\n",
    "df['text'] = df.OriginalTweet\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "def classes_def(x):\n",
    "    if x ==  \"Extremely Positive\":\n",
    "        return \"positive\"\n",
    "    elif x == \"Extremely Negative\":\n",
    "        return \"negative\"\n",
    "    elif x == \"Negative\":\n",
    "        return \"negative\"\n",
    "    elif x ==  \"Positive\":\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "df['sentiment']=df['Sentiment'].apply(lambda x:classes_def(x))\n",
    "target=df['sentiment']\n",
    "\n",
    "print(df.sentiment.value_counts(normalize= True))\n",
    "print(\"Modified Classes:\", df.sentiment.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove sentiments that are neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"sentiment\"] != \"neutral\"]\n",
    "print(df.sentiment.unique())\n",
    "print(df.sentiment.value_counts(normalize= True))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove URLs and HTML links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_remove = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_remove.sub(r'', text)\n",
    "\n",
    "df['text']=df['text'].apply(lambda x:remove_urls(x))\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "df['text']=df['text'].apply(lambda x:remove_html(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert text to lower case \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(text):\n",
    "    low_text= text.lower()\n",
    "    return low_text\n",
    "df['text']=df['text'].apply(lambda x:lower(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_num(text):\n",
    "    remove= re.sub(r'\\d+', '', text)\n",
    "    return remove\n",
    "df['text']=df['text'].apply(lambda x:remove_num(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "df['text']=df['text'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punct_remove(text):\n",
    "    punct = re.sub(r\"[^\\w\\s\\d]\",\"\", text)\n",
    "    return punct\n",
    "df['text']=df['text'].apply(lambda x:punct_remove(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove mentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mention(x):\n",
    "    text=re.sub(r'@\\w+','',x)\n",
    "    return text\n",
    "df['text']=df['text'].apply(lambda x:remove_mention(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove hashtags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hash(x):\n",
    "    text=re.sub(r'#\\w+','',x)\n",
    "    return text\n",
    "df['text']=df['text'].apply(lambda x:remove_hash(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove extra whitespace left while removing other text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space(text):\n",
    "    space_remove = re.sub(r\"\\s+\",\" \",text).strip()\n",
    "    return space_remove\n",
    "df['text']=df['text'].apply(lambda x:remove_space(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run text data quality tests again\n",
    "Here, we are checking the quality of the data again by running the data quality tests again to verify that we have preprocessed the data to a sufficient standard and that tests are passing according to our requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_ds = vm.init_dataset(dataset=df, type=\"generic\", text_column='text', target_column=\"sentiment\")\n",
    "\n",
    "config = {\n",
    "    \"class_imbalance\":{\"min_percent_threshold\": 3}\n",
    "}\n",
    "text_data_test_suite = vm.run_test_suite(\"text_data_quality\",\n",
    "                                       inputs = {\"dataset\":vm_ds},\n",
    "                                       config=config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training, validation, and test data sets\n",
    "\n",
    "With our data in nice shape, we'll split it into training, validation, and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[df['sentiment'] != \"neutral\"]\n",
    "df.loc[df['sentiment'] == \"positive\", 'sentiment'] = 1\n",
    "df.loc[df['sentiment'] == \"negative\", 'sentiment'] = 0\n",
    "print(np.unique(df['sentiment']))\n",
    "\n",
    "print(df.head())\n",
    "train, test = train_test_split(df[['text','sentiment']], test_size=0.33, random_state=42)\n",
    "train = train[['text','sentiment']]\n",
    "test = test[['text','sentiment']]\n",
    "\n",
    "train, valid = train_test_split(\n",
    "    train,\n",
    "    train_size=0.7,\n",
    "    random_state=0,\n",
    "    stratify=train['sentiment'])\n",
    "y_train, X_train = \\\n",
    "    train['sentiment'], train.drop(['sentiment'], axis=1)\n",
    "y_valid, X_valid = \\\n",
    "    valid['sentiment'], valid.drop(['sentiment'], axis=1)\n",
    "y_test, X_test= \\\n",
    "    test['sentiment'], test.drop(['sentiment'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X_train, y_train,val_data, **kwargs):\n",
    "    model = CatBoostClassifier(\n",
    "        task_type='CPU',\n",
    "        iterations=5000,\n",
    "        eval_metric='Accuracy',\n",
    "        od_type='Iter',\n",
    "        od_wait=500,\n",
    "        **kwargs\n",
    "    )\n",
    "    return model.fit(\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        eval_set=val_data,\n",
    "        verbose=100,\n",
    "        plot=True,\n",
    "        use_best_model=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_model(\n",
    "    X_train, y_train,\n",
    "    val_data=(X_valid,y_valid),\n",
    "    text_features=['text'],\n",
    "    learning_rate=0.35,\n",
    "    tokenizers=[\n",
    "        {\n",
    "            'tokenizer_id': 'Sense',\n",
    "            'separator_type': 'BySense',\n",
    "            'lowercasing': 'True',\n",
    "            'token_types':['Word', 'Number', 'SentenceBreak'],\n",
    "            'sub_tokens_policy':'SeveralTokens'\n",
    "        }\n",
    "    ],\n",
    "    dictionaries = [\n",
    "        {\n",
    "            'dictionary_id': 'Word',\n",
    "            'max_dictionary_size': '5000'\n",
    "        }\n",
    "    ],\n",
    "    feature_calcers = [\n",
    "        'BoW:top_tokens_count=10000'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ValidMind objects\n",
    "\n",
    "With the model ready, we can now initialize the training and testing datasets, as well as the model, for sentiment analysis using [`vm.init_dataset()`](https://docs.validmind.ai/validmind/validmind.html#init_dataset) and [`vm.init_model`](https://docs.validmind.ai/validmind/validmind.html#init_model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds = vm.init_dataset(dataset=pd.concat([X_train, y_train], axis=1), type=\"generic\", target_column=\"sentiment\")\n",
    "vm_test_ds = vm.init_dataset(dataset=pd.concat([X_test, y_test], axis=1), type=\"generic\",target_column=\"sentiment\")\n",
    "vm_model = vm.init_model(model, train_ds=vm_train_ds, test_ds=vm_test_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model metrics test suite\n",
    "\n",
    "Next, we run the `binary_classifier_metrics` test suite on the initialized model to collect performance metrics for binary classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_test_suite = vm.run_test_suite(\"classifier_metrics\",\n",
    "                                             inputs = {\"model\":vm_model}\n",
    "                                            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model validation test suite\n",
    "\n",
    "And finally, let's runs the `binary_classifier_validation` test suite on the initialized model to validate the model's binary classification performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validation_test_suite = vm.run_test_suite(\n",
    "    \"classifier_validation\",\n",
    "    inputs = {\n",
    "        \"model\":vm_model,\n",
    "        \"models\":[vm_model]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "You can look at the results of this test suite right in the notebook where you ran the code, as you would expect. But there is a better way: view the prompt validation test results as part of your model documentation right in the ValidMind Platform UI: \n",
    "\n",
    "1. Log back into the [Platform UI](https://app.prod.validmind.ai) \n",
    "\n",
    "2. Go to **Documentation Projects** > **YOUR_DOCUMENTATION_PROJECT** > **Documentation**.\n",
    "\n",
    "3. Expand **3. Model Development** > **3.2. Prompt Evaluation**.\n",
    "\n",
    "What you can see now is a more easily consumable version of the prompt validation testing you just performed, along with other parts of your documentation project that still need to be completed. \n",
    "\n",
    "If you want to learn more about where you are in the model documentation process, take a look at [How do I use the framework?](https://docs.validmind.ai/guide/get-started-developer-framework.html#how-do-i-use-the-framework).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Developer Framework",
   "language": "python",
   "name": "dev-framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
