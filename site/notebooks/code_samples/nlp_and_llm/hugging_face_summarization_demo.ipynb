{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Summarization of financial data using Hugging Face NLP models\n",
                "\n",
                "This notebook aims to provide an introduction to documenting an NLP model using the ValidMind Developer Framework. The use case presented is a summarization of financial news (https://huggingface.co/datasets/cnn_dailymail).\n",
                "\n",
                "- Initializing the ValidMind Developer Framework\n",
                "- Running a test various tests to quickly generate document about the data and model\n",
                "\n",
                "## Before you begin\n",
                "\n",
                "To use the ValidMind Developer Framework with a Jupyter notebook, you need to install and initialize the client library first, along with getting your Python environment ready.\n",
                "\n",
                "If you don't already have one, you should also [create a documentation project](https://docs.validmind.ai/guide/create-your-first-documentation-project.html) on the ValidMind platform. You will use this project to upload your documentation and test results.\n",
                "\n",
                "## Install the client library"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install -q validmind"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize the client library\n",
                "\n",
                "In a browser, go to the **Client Integration** page of your documentation project and click **Copy to clipboard** next to the code snippet. This code snippet gives you the API key, API secret, and project identifier to link your notebook to your documentation project.\n",
                "\n",
                "::: {.column-margin}\n",
                "::: {.callout-tip}\n",
                "This step requires a documentation project. [Learn how you can create one](https://docs.validmind.ai/guide/create-your-first-documentation-project.html).\n",
                ":::\n",
                ":::\n",
                "\n",
                "Next, replace this placeholder with your own code snippet:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Replace the code below with the code snippet from your project ## \n",
                "\n",
                "import validmind as vm\n",
                "\n",
                "vm.init(\n",
                "  api_host = \"....\",\n",
                "  api_key = \"...\",\n",
                "  api_secret = \"...\",\n",
                "  project = \"...\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Preview the template\n",
                "\n",
                "A template predefines sections for your documentation project and provides a general outline to follow, making the documentation process much easier.\n",
                "\n",
                "You will upload documentation and test results into this template later on. For now, take a look at the structure that the template provides with the vm.preview_template() function from the ValidMind library and note the empty sections:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm.preview_template()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Helper functions\n",
                "\n",
                "Let's define the following functions to help visualize datasets with long text fields."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import textwrap\n",
                "\n",
                "from IPython.display import display, HTML\n",
                "from tabulate import tabulate\n",
                "\n",
                "def _format_cell_text(text, width=50):  \n",
                "    \"\"\"Private function to format a cell's text.\"\"\"\n",
                "    return '\\n'.join([textwrap.fill(line, width=width) for line in text.split('\\n')])\n",
                "\n",
                "def _format_dataframe_for_tabulate(df):\n",
                "    \"\"\"Private function to format the entire DataFrame for tabulation.\"\"\"\n",
                "    df_out = df.copy()\n",
                "    \n",
                "    # Format all string columns\n",
                "    for column in df_out.columns:\n",
                "        if df_out[column].dtype == object:  # Check if column is of type object (likely strings)\n",
                "            df_out[column] = df_out[column].apply(_format_cell_text)\n",
                "    return df_out\n",
                "\n",
                "def _dataframe_to_html_table(df):\n",
                "    \"\"\"Private function to convert a DataFrame to an HTML table.\"\"\"\n",
                "    headers = df.columns.tolist()\n",
                "    table_data = df.values.tolist()\n",
                "    return tabulate(table_data, headers=headers, tablefmt=\"html\")\n",
                "\n",
                "def display_formatted_dataframe(df, num_rows=None):\n",
                "    \"\"\"Primary function to format and display a DataFrame.\"\"\"\n",
                "    if num_rows is not None:\n",
                "        df = df.head(num_rows)\n",
                "    formatted_df = _format_dataframe_for_tabulate(df)\n",
                "    html_table = _dataframe_to_html_table(formatted_df)\n",
                "    display(HTML(html_table))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### CNN dataset\n",
                "\n",
                "The CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import load_dataset\n",
                "\n",
                "cnn_dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
                "train_df = cnn_dataset.data['train'].to_pandas()\n",
                "val_df = cnn_dataset.data['validation'].to_pandas()\n",
                "test_df = cnn_dataset.data['test'].to_pandas()\n",
                "train_df = train_df[['article','highlights']]\n",
                "train_df = train_df.head(20)\n",
                "\n",
                "display_formatted_dataframe(train_df, num_rows=5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = train_df.head(100)\n",
                "# Load a test dataset with 100 rows only\n",
                "vm_ds = vm.init_dataset(\n",
                "    dataset=df,\n",
                "    text_column=\"article\",\n",
                "    target_column=\"highlights\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## NLP data quality tests\n",
                "\n",
                "Before we proceed with the analysis, it's crucial to ensure the quality of our NLP data. We can run the \"data preparation\" section of the template to validate the data's integrity and suitability."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "text_data_test_plan = vm.run_documentation_tests(section=\"data_preparation\", dataset=vm_ds)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration\n",
                "\n",
                "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
                "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
                "\n",
                "summarizer_model = pipeline(\n",
                "    task=\"summarization\",\n",
                "    model=model,\n",
                "    tokenizer = tokenizer,\n",
                "    min_length=0,\n",
                "    max_length=60,\n",
                "    truncation=True,\n",
                "    model_kwargs={\"cache_dir\": '/Documents/Huggin_Face/'},\n",
                ")  # Note: We specify cache_dir to use predownloaded models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_test = df.head(10)\n",
                "\n",
                "vm_test_ds = vm.init_dataset(\n",
                "    dataset=train_df,\n",
                "    text_column=\"article\",\n",
                "    target_column=\"highlights\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm_model = vm.init_model(\n",
                "    summarizer_model,\n",
                "    test_ds=vm_test_ds,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Run model validation tests\n",
                "\n",
                "It's possible to run a subset of tests on the documentation template by passing a `section` parameter to `run_documentation_tests()`. Let's run the tests that evaluate the model's overall performance (including summarization metrics), by selecting the \"model development\" section of the template."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config={\n",
                "    \"rouge_metric\": {\n",
                "        \"rouge_metrics\": [\"rouge-1\",\"rouge-2\", \"rouge-l\"],\n",
                "    },\n",
                "}\n",
                "summarization_results = vm.run_documentation_tests(\n",
                "    section=\"model_development\", \n",
                "    model=vm_model,\n",
                "    config=config,\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Dev Framework 3.9.16",
            "language": "python",
            "name": "dev-framework-3.9"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
