{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Time Series Data Validation Full Suite"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Time Series Data Validation Demo notebook aims to demonstrate the application of various data validation tests using the **ValidMind MRM Platform** and **Developer Framework**. Ensuring the quality and an a robust exploratory data analysis of time series data is essential for accurate model predictions and robust decision-making processes.\n",
        "\n",
        "In this demo, we will walk through different **data validation suites of tests** tailored for time series data, showcasing how these tools can assist you in identifying potential issues and inconsistencies in the data. \n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup \n",
        "\n",
        "Prepare the environment for our analysis. First, **import** all necessary libraries and modules required for our analysis. Next, **connect** to the ValidMind MRM platform, which provides a comprehensive suite of tools and services for model validation.\n",
        "\n",
        "Finally, define and **configure** the specific use case we are working on by setting up any required parameters, data sources, or other settings that will be used throughout the analysis. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load API key and secret from environment variables\n",
        "%load_ext dotenv\n",
        "%dotenv .env\n",
        "\n",
        "# ValidMind libraries \n",
        "import validmind as vm\n",
        "from validmind.datasets.regression import (\n",
        "    identify_frequencies, \n",
        "    resample_to_common_frequency\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Connect to the ValidMind Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm.init(\n",
        "  api_host = \"http://localhost:3000/api/v1/tracking\",\n",
        "  project = \"clhhz04x40000wcy6shay2oco\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Find All Test Suites and Plans Available in the Developer Framework"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can find all the **test suites** and **test plans** available in the developer framework by calling the following functions:\n",
        "\n",
        "- All test suites: `vm.test_suites.list_suites()`\n",
        "- All test plans: `vm.test_plans.list_plans()`\n",
        "- Describe a test plan: `vm.test_plans.describe_plan(\"time_series_data_quality\")`\n",
        "- List all available tests: `vm.test_plans.list_tests()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm.test_suites.list_suites()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm.test_plans.list_plans()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conigure your use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from validmind.datasets.classification import lending_club as demo_dataset\n",
        "from validmind.datasets.regression import fred as demo_dataset\n",
        "\n",
        "target_column = demo_dataset.target_column\n",
        "feature_columns = demo_dataset.feature_columns\n",
        "\n",
        "# Split the dataset into test and training \n",
        "df = demo_dataset.load_data()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Validation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### User Configuration of Test Suite "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Users can input the configuration to a test suite using **`config`**, allowing fine-tuning the suite according to their specific data requirements. \n",
        "\n",
        "**Time Series Data Quality params**\n",
        "- `time_series_outliers` is set to identify outliers using a specific Z-score threshold\n",
        "- `time_series_missing_values` defines a minimum threshold to identify missing data points.\n",
        "\n",
        "**Time Series Univariate params**\n",
        "- *Visualization*: `time_series_line_plot` and `time_series_histogram` are designed to generate line and histogram plots respectively for each column in a DataFrame.\n",
        "\n",
        "- *Seasonality*:  `seasonal_decompose` and `auto_seasonality` are dedicated to analyzing the seasonal component of the time series. `seasonal_decompose` performs a seasonal decomposition of the data, while `auto_seasonality` aids in the automatic detection of seasonality.\n",
        "\n",
        "- *Stationarity*: `window_size` determines the number of consecutive data points used for calculating the rolling mean and standard deviation.\n",
        "\n",
        "- *ARIMA*: `acf_pacf_plot`, `auto_ar`, and `auto_ma` are part of the ARIMA (Autoregressive Integrated Moving Average) model analysis. `acf_pacf_plot` generates autocorrelation and partial autocorrelation plots, `auto_ar` determines the order of the autoregressive part of the model, and `auto_ma` does the same for the moving average part.\n",
        "\n",
        "\n",
        "**Time Series Multivariate params**\n",
        "- *Visualization*: `scatter_plot` is used to create scatter plots for each column in the DataFrame, offering a visual tool to understand the relationship between different variables in the dataset.\n",
        "\n",
        "- *Correlation*: `lagged_correlation_heatmap` facilitates the creation of a heatmap, which visually represents the lagged correlation between the target column and the feature columns of a demo dataset. This provides a convenient way to examine the time-delayed correlation between different series.\n",
        "\n",
        "- *Cointegration*: `engle_granger_coint` sets a threshold for conducting the Engle-Granger cointegration test, which is a statistical method used to identify the long-term correlation between two or more time series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config={\n",
        "    \n",
        "    # TIME SERIES DATA QUALITY PARAMS\n",
        "    \"time_series_outliers\": {\n",
        "        \"zscore_threshold\": 3,\n",
        "    },\n",
        "    \"time_series_missing_values\":{\n",
        "        \"min_threshold\": 2,\n",
        "    },\n",
        "    \n",
        "    # TIME SERIES UNIVARIATE PARAMS \n",
        "    \"rolling_stats_plot\": {\n",
        "        \"window_size\": 12    \n",
        "    },\n",
        "     \"seasonal_decompose\": {\n",
        "        \"seasonal_model\": 'additive'\n",
        "    },\n",
        "     \"auto_seasonality\": {\n",
        "        \"min_period\": 1,\n",
        "        \"max_period\": 3\n",
        "    },\n",
        "      \"auto_stationarity\": {\n",
        "        \"max_order\": 3,\n",
        "        \"threshold\": 0.05\n",
        "    },\n",
        "    \"auto_ar\": {\n",
        "        \"max_ar_order\": 4\n",
        "    },\n",
        "    \"auto_ma\": {\n",
        "        \"max_ma_order\": 3\n",
        "    },\n",
        "\n",
        "    # TIME SERIES MULTIVARIATE PARAMS \n",
        "    \"lagged_correlation_heatmap\": {\n",
        "        \"target_col\": demo_dataset.target_column,\n",
        "        \"independent_vars\": demo_dataset.feature_columns\n",
        "    },\n",
        "    \"engle_granger_coint\": {\n",
        "        \"threshold\": 0.05\n",
        "    },\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation of Raw Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Run the Time Series Dataset Test Suite**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm_dataset = vm.init_dataset(\n",
        "    dataset=df,\n",
        "    target_column=demo_dataset.target_column,\n",
        ")\n",
        "\n",
        "full_suite = vm.run_test_suite(\n",
        "    \"time_series_dataset\",\n",
        "    dataset=vm_dataset,\n",
        "    config = config,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handle Dataset Frequencies"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the frequencies of each variable in the raw dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frequencies = identify_frequencies(df)\n",
        "display(frequencies)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Handle frequencies by resampling all variables to a common frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessed_df = resample_to_common_frequency(df, common_frequency=demo_dataset.frequency)\n",
        "frequencies = identify_frequencies(preprocessed_df)\n",
        "display(frequencies)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Run the Time Series Dataset Test Suite**\n",
        "\n",
        "Run the same suite again after handling frequencies.     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm_dataset = vm.init_dataset(\n",
        "    dataset=preprocessed_df,\n",
        "    target_column=demo_dataset.target_column,\n",
        ")\n",
        "\n",
        "full_suite = vm.run_test_suite(\n",
        "    \"time_series_dataset\",\n",
        "    dataset=vm_dataset,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handle Missing Values"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Handle the missing values by droping all the `nan` values. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessed_df = preprocessed_df.dropna()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Run the Time Series Dataset Test Suite**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the same test suite to check there are no missing values and frequencies of all variables are the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm_dataset = vm.init_dataset(\n",
        "    dataset=preprocessed_df,\n",
        "    target_column=demo_dataset.target_column,\n",
        ")\n",
        "\n",
        "full_suite = vm.run_test_suite(\n",
        "    \"time_series_dataset\",\n",
        "    dataset=vm_dataset,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handle Stationarity"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Handle stationarity by taking the first difference. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessed_df = preprocessed_df.diff().fillna(method='bfill')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Run the Time Series Dataset Test Suite**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm_dataset = vm.init_dataset(\n",
        "    dataset=preprocessed_df,\n",
        "    target_column=demo_dataset.target_column,\n",
        ")\n",
        "\n",
        "full_suite = vm.run_test_suite(\n",
        "    \"time_series_dataset\",\n",
        "    dataset=vm_dataset,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "validmind-eEL8LtKG-py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
