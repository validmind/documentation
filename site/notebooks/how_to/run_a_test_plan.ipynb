{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running an Individual Test Plan\n",
    "\n",
    "This notebook shows how to run an individual test plan and pass custom config parameters for the tests."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "To use the ValidMind Developer Framework with a Jupyter notebook, you need to install and initialize the client library first, along with getting your Python environment ready.\n",
    "\n",
    "If you don't already have one, you should also [create a documentation project](https://docs.validmind.ai/guide/create-your-first-documentation-project.html) on the ValidMind platform. You will use this project to upload your documentation and test results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade validmind"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "In a browser, go to the **Client Integration** page of your documentation project and click **Copy to clipboard** next to the code snippet. This code snippet gives you the API key, API secret, and project identifier to link your notebook to your documentation project.\n",
    "\n",
    "::: {.column-margin}\n",
    "::: {.callout-tip}\n",
    "This step requires a documentation project. [Learn how you can create one](https://docs.validmind.ai/guide/create-your-first-documentation-project.html).\n",
    ":::\n",
    ":::\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace with code snippet from your documentation project ##\n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "    api_host=\"https://api.prod.validmind.ai/api/v1/tracking\",\n",
    "    api_key=\"...\",\n",
    "    api_secret=\"...\",\n",
    "    project=\"...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Demo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also import customer_churn like this:\n",
    "from validmind.datasets.classification import customer_churn as demo_dataset\n",
    "# from validmind.datasets.classification import taiwan_credit as demo_dataset\n",
    "\n",
    "df = demo_dataset.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepocess the Raw Dataset\n",
    "We will need to preprocess the dataset and produce the training, test and validation splits first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = demo_dataset.preprocess(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model for Testing\n",
    "\n",
    "We train a simple customer churn model for our test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop(demo_dataset.target_column, axis=1)\n",
    "y_train = train_df[demo_dataset.target_column]\n",
    "x_val = validation_df.drop(demo_dataset.target_column, axis=1)\n",
    "y_val = validation_df[demo_dataset.target_column]\n",
    "\n",
    "model = xgb.XGBClassifier(early_stopping_rounds=10)\n",
    "model.set_params(\n",
    "    eval_metric=[\"error\", \"logloss\", \"auc\"],\n",
    ")\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    eval_set=[(x_val, y_val)],\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Run the Individual Test Plan\n",
    "\n",
    "### Initialize ValidMind objects\n",
    "\n",
    "We initize the objects required to run test plans using the ValidMind framework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds = vm.init_dataset(\n",
    "    dataset=train_df,\n",
    "    type=\"generic\",\n",
    "    target_column=demo_dataset.target_column\n",
    ")\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=test_df,\n",
    "    type=\"generic\",\n",
    "    target_column=demo_dataset.target_column\n",
    ")\n",
    "\n",
    "vm_model = vm.init_model(\n",
    "    model,\n",
    "    train_ds=vm_train_ds,\n",
    "    test_ds=vm_test_ds,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of available Test Plans\n",
    "The interface to show list of test plans available in the ValidMind development framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.test_plans.list_plans()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Detail of an individual Test Plan\n",
    "The interface will get detail of a specific test plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.test_plans.describe_plan(\"binary_classifier_model_diagnosis\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the required config parameters\n",
    "The config can be apply to specific test to override the default configuration parameters.\n",
    "\n",
    "The format of a config is:\n",
    "```\n",
    "config = {\n",
    "    \"<test1_id>\": {\n",
    "        \"<default_param_1>\": value,\n",
    "        \"<default_param_2>\": value,\n",
    "    },\n",
    "     \"<test2_id>\": {\n",
    "        \"<default_param_1>\": value,\n",
    "        \"<default_param_2>\": value,\n",
    "    },\n",
    "}\n",
    "```\n",
    "\n",
    "Users can input the configuration to test plan using **`config`**, allowing fine-tuning the suite according to their specific data requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    \"overfit_regions\": {\n",
    "        \"cut_off_percentage\": 3,\n",
    "        \"feature_columns\": [\"Age\", \"Balance\", \"Tenure\", \"NumOfProducts\"]\n",
    "    },\n",
    "    \"weak_spots\":{\n",
    "        \"features_columns\": [\"Age\", \"Balance\"],\n",
    "        \"accuracy_gap_threshold\": 85,\n",
    "    },\n",
    "    \"robustness\":{\n",
    "        \"features_columns\": [ \"Balance\", \"Tenure\"],\n",
    "        \"scaling_factor_std_dev_list\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        \"accuracy_decay_threshold\": 4,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the test plan and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diagnosis_test_plan = vm.run_test_plan(\"binary_classifier_model_diagnosis\", \n",
    "                                             model=vm_model,\n",
    "                                             config=config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the test plan results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access all the results of the test plan, including subtest plans using `test_plan.get_results()`.\n",
    "\n",
    "- `test_plan.get_results()`: With no arguments, this returns a list of all results\n",
    "- `test_plan.get_results(test_id)`: If provided with a test id, this returns the all results that match the given test id\n",
    "\n",
    "By default, get_results() returns a list, in case there are multiple tests with the same id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diagnosis_test_plan.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_robustness = model_diagnosis_test_plan.get_results(\"robustness\")[0]\n",
    "model_robustness.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
