{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R Customer Churn Model\n",
    "This notebook demonstrates the process of creating a customer churn model using R. We will use the XGBoost and logistic regression algorithms to create two separate models and compare their performance.\n",
    "\n",
    "The dataset used in this notebook is located at `../datasets/bank_customer_churn.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Requisites:\n",
    "\n",
    "#### install R using homebrew if you don't have it already:\n",
    "\n",
    "```bash\n",
    "brew install r\n",
    "```\n",
    "\n",
    "You additionally might need the following packages to run this notebook if you run into errors:\n",
    "\n",
    "```bash\n",
    "brew install harfbuzz fribidi libtiff libomp\n",
    "```\n",
    "\n",
    "#### Install the following packages in an R console:\n",
    "\n",
    "```R\n",
    "install.packages(\"xgboost\")\n",
    "install.packages(\"caret\")\n",
    "install.packages(\"pROC\")\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries\n",
    "First, we load the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# load the required libraries\n",
    "library(xgboost)\n",
    "library(dplyr)\n",
    "library(caret)\n",
    "library(pROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess Dataset\n",
    "Now, we import the dataset and preprocess it by removing irrelevant columns, converting categorical variables, and one-hot encoding certain columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " GeographyFrance  GeographyGermany     Gender            Age       \n",
       " Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :18.00  \n",
       " 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:32.00  \n",
       " Median :1.0000   Median :0.0000   Median :1.0000   Median :37.00  \n",
       " Mean   :0.5012   Mean   :0.2511   Mean   :0.5495   Mean   :38.95  \n",
       " 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:44.00  \n",
       " Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :92.00  \n",
       "     Tenure          Balance       NumOfProducts     HasCrCard     \n",
       " Min.   : 0.000   Min.   :     0   Min.   :1.000   Min.   :0.0000  \n",
       " 1st Qu.: 3.000   1st Qu.:     0   1st Qu.:1.000   1st Qu.:0.0000  \n",
       " Median : 5.000   Median : 97264   Median :1.000   Median :1.0000  \n",
       " Mean   : 5.034   Mean   : 76434   Mean   :1.532   Mean   :0.7026  \n",
       " 3rd Qu.: 8.000   3rd Qu.:128045   3rd Qu.:2.000   3rd Qu.:1.0000  \n",
       " Max.   :10.000   Max.   :250898   Max.   :4.000   Max.   :1.0000  \n",
       " IsActiveMember   EstimatedSalary         Exited     \n",
       " Min.   :0.0000   Min.   :    11.58   Min.   :0.000  \n",
       " 1st Qu.:0.0000   1st Qu.: 50857.10   1st Qu.:0.000  \n",
       " Median :1.0000   Median : 99504.89   Median :0.000  \n",
       " Mean   :0.5199   Mean   : 99790.19   Mean   :0.202  \n",
       " 3rd Qu.:1.0000   3rd Qu.:149216.32   3rd Qu.:0.000  \n",
       " Max.   :1.0000   Max.   :199992.48   Max.   :1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the dataset\n",
    "df <- read.csv(\"../datasets/bank_customer_churn.csv\", header = TRUE)\n",
    "\n",
    "# remove irrelevant columns\n",
    "df <- df %>% select(-c(RowNumber, CustomerId, Surname, CreditScore))\n",
    "\n",
    "# Convert the 'Gender' column to 0 or 1 (assuming \"Female\" should be 0 and \"Male\" should be 1)\n",
    "df$Gender <- ifelse(df$Gender == \"Female\", 0, 1)\n",
    "\n",
    "# one-hot encode categorical columns with caret\n",
    "df <- dummyVars(\" ~ .\", data = df) %>% predict(df)\n",
    "\n",
    "# remove GeographySpain since it causes multicollinearity\n",
    "df <- subset(df, select = -GeographySpain)\n",
    "\n",
    "summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data\n",
    "Next, we split the data into training\n",
    "and testing sets using a 70/30 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "set.seed(123)\n",
    "train_index <- sample(1:nrow(df), size = round(0.7*nrow(df)), replace = FALSE)\n",
    "df_train <- df[train_index, ]\n",
    "df_test <- df[-train_index, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train and Test Datasets\n",
    "We save the train and test datasets as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# save the train and test datasets as csv files\n",
    "write.csv(df_train, file = \"r_churn_train.csv\", row.names = FALSE)\n",
    "write.csv(df_test, file = \"r_churn_test.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data to DMatrix Format\n",
    "We convert the data into DMatrix format, which is required by the XGBoost library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# convert data into DMatrix format\n",
    "dtrain <- xgb.DMatrix(data = df_train[,-c(11)], label = df_train[,\"Exited\"])\n",
    "dtest <- xgb.DMatrix(data = df_test[,-c(11)], label = df_test[,\"Exited\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up XGBoost Parameters\n",
    "We set up the XGBoost parameters to be used during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# set up XGBoost parameters\n",
    "params <- list(\n",
    "  objective = \"binary:logistic\",\n",
    "  eval_metric = \"auc\",\n",
    "  max_depth = 3,\n",
    "  eta = 0.1,\n",
    "  gamma = 0.5,\n",
    "  subsample = 0.8,\n",
    "  colsample_bytree = 0.8,\n",
    "  min_child_weight = 1,\n",
    "  nthread = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the XGBoost Model\n",
    "We train the XGBoost model using the parameters and data prepared earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-auc:0.795105\ttest-auc:0.793822 \n",
      "Multiple eval metrics are present. Will use test_auc for early stopping.\n",
      "Will train until test_auc hasn't improved in 10 rounds.\n",
      "\n",
      "[2]\ttrain-auc:0.820697\ttest-auc:0.808123 \n",
      "[3]\ttrain-auc:0.823965\ttest-auc:0.811294 \n",
      "[4]\ttrain-auc:0.837212\ttest-auc:0.823692 \n",
      "[5]\ttrain-auc:0.839206\ttest-auc:0.827146 \n",
      "[6]\ttrain-auc:0.843781\ttest-auc:0.832219 \n",
      "[7]\ttrain-auc:0.853531\ttest-auc:0.836494 \n",
      "[8]\ttrain-auc:0.857080\ttest-auc:0.838679 \n",
      "[9]\ttrain-auc:0.857191\ttest-auc:0.839732 \n",
      "[10]\ttrain-auc:0.856166\ttest-auc:0.840575 \n",
      "[11]\ttrain-auc:0.857386\ttest-auc:0.841168 \n",
      "[12]\ttrain-auc:0.857084\ttest-auc:0.841385 \n",
      "[13]\ttrain-auc:0.856794\ttest-auc:0.842336 \n",
      "[14]\ttrain-auc:0.857827\ttest-auc:0.841208 \n",
      "[15]\ttrain-auc:0.858503\ttest-auc:0.842312 \n",
      "[16]\ttrain-auc:0.860074\ttest-auc:0.843007 \n",
      "[17]\ttrain-auc:0.858916\ttest-auc:0.843317 \n",
      "[18]\ttrain-auc:0.858676\ttest-auc:0.843113 \n",
      "[19]\ttrain-auc:0.858821\ttest-auc:0.843309 \n",
      "[20]\ttrain-auc:0.859816\ttest-auc:0.845118 \n",
      "[21]\ttrain-auc:0.860960\ttest-auc:0.845355 \n",
      "[22]\ttrain-auc:0.860677\ttest-auc:0.845800 \n",
      "[23]\ttrain-auc:0.862110\ttest-auc:0.848165 \n",
      "[24]\ttrain-auc:0.863008\ttest-auc:0.847703 \n",
      "[25]\ttrain-auc:0.863292\ttest-auc:0.848459 \n",
      "[26]\ttrain-auc:0.864104\ttest-auc:0.849124 \n",
      "[27]\ttrain-auc:0.863918\ttest-auc:0.848931 \n",
      "[28]\ttrain-auc:0.864840\ttest-auc:0.849988 \n",
      "[29]\ttrain-auc:0.867052\ttest-auc:0.850861 \n",
      "[30]\ttrain-auc:0.867307\ttest-auc:0.851330 \n",
      "[31]\ttrain-auc:0.867691\ttest-auc:0.851321 \n",
      "[32]\ttrain-auc:0.868384\ttest-auc:0.852436 \n",
      "[33]\ttrain-auc:0.870037\ttest-auc:0.854785 \n",
      "[34]\ttrain-auc:0.870912\ttest-auc:0.855056 \n",
      "[35]\ttrain-auc:0.871229\ttest-auc:0.855566 \n",
      "[36]\ttrain-auc:0.871868\ttest-auc:0.855823 \n",
      "[37]\ttrain-auc:0.872831\ttest-auc:0.857390 \n",
      "[38]\ttrain-auc:0.873618\ttest-auc:0.856942 \n",
      "[39]\ttrain-auc:0.874207\ttest-auc:0.858250 \n",
      "[40]\ttrain-auc:0.874417\ttest-auc:0.858442 \n",
      "[41]\ttrain-auc:0.874423\ttest-auc:0.858399 \n",
      "[42]\ttrain-auc:0.875082\ttest-auc:0.858565 \n",
      "[43]\ttrain-auc:0.876418\ttest-auc:0.858693 \n",
      "[44]\ttrain-auc:0.876752\ttest-auc:0.858042 \n",
      "[45]\ttrain-auc:0.877068\ttest-auc:0.857847 \n",
      "[46]\ttrain-auc:0.877774\ttest-auc:0.857960 \n",
      "[47]\ttrain-auc:0.879001\ttest-auc:0.858793 \n",
      "[48]\ttrain-auc:0.879490\ttest-auc:0.858593 \n",
      "[49]\ttrain-auc:0.880067\ttest-auc:0.859837 \n",
      "[50]\ttrain-auc:0.880651\ttest-auc:0.860296 \n",
      "[51]\ttrain-auc:0.880768\ttest-auc:0.860439 \n",
      "[52]\ttrain-auc:0.881091\ttest-auc:0.861333 \n",
      "[53]\ttrain-auc:0.881637\ttest-auc:0.861322 \n",
      "[54]\ttrain-auc:0.881942\ttest-auc:0.861473 \n",
      "[55]\ttrain-auc:0.882016\ttest-auc:0.861432 \n",
      "[56]\ttrain-auc:0.882721\ttest-auc:0.861169 \n",
      "[57]\ttrain-auc:0.882949\ttest-auc:0.861621 \n",
      "[58]\ttrain-auc:0.883306\ttest-auc:0.861810 \n",
      "[59]\ttrain-auc:0.883506\ttest-auc:0.861506 \n",
      "[60]\ttrain-auc:0.883632\ttest-auc:0.861516 \n",
      "[61]\ttrain-auc:0.883968\ttest-auc:0.861404 \n",
      "[62]\ttrain-auc:0.884255\ttest-auc:0.861261 \n",
      "[63]\ttrain-auc:0.884719\ttest-auc:0.861073 \n",
      "[64]\ttrain-auc:0.885060\ttest-auc:0.861043 \n",
      "[65]\ttrain-auc:0.885252\ttest-auc:0.861357 \n",
      "[66]\ttrain-auc:0.885285\ttest-auc:0.861367 \n",
      "[67]\ttrain-auc:0.885594\ttest-auc:0.860972 \n",
      "[68]\ttrain-auc:0.886119\ttest-auc:0.860755 \n",
      "Stopping. Best iteration:\n",
      "[58]\ttrain-auc:0.883306\ttest-auc:0.861810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the XGBoost model\n",
    "model <- xgb.train(\n",
    "  params = params,\n",
    "  data = dtrain,\n",
    "  nrounds = 100,\n",
    "  watchlist = list(train = dtrain, test = dtest),\n",
    "  early_stopping_rounds = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "We display a summary of the trained XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                Length Class              Mode       \n",
       "handle              1  xgb.Booster.handle externalptr\n",
       "raw             81624  -none-             raw        \n",
       "best_iteration      1  -none-             numeric    \n",
       "best_ntreelimit     1  -none-             numeric    \n",
       "best_score          1  -none-             numeric    \n",
       "best_msg            1  -none-             character  \n",
       "niter               1  -none-             numeric    \n",
       "evaluation_log      3  data.table         list       \n",
       "call                6  -none-             call       \n",
       "params             10  -none-             list       \n",
       "callbacks           3  -none-             list       \n",
       "feature_names      10  -none-             character  \n",
       "nfeatures           1  -none-             numeric    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Data\n",
    "We make predictions on the test data and calculate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.860416666666667"
      ],
      "text/latex": [
       "0.860416666666667"
      ],
      "text/markdown": [
       "0.860416666666667"
      ],
      "text/plain": [
       "[1] 0.8604167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on test data\n",
    "test_preds <- predict(model, dtest)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "test_preds_binary <- ifelse(test_preds > 0.5, 1, 0)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "accuracy <- sum(test_preds_binary == df_test[,\"Exited\"])/nrow(df_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics\n",
    "We calculate the confusion matrix, precision, recall, F1 score, and ROC AUC for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7687075 \n",
      "Recall: 0.4584178 \n",
      "F1 Score: 0.5743329 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.86181 \n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm <- confusionMatrix(as.factor(test_preds_binary), as.factor(df_test[,\"Exited\"]))\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision <- cm$table[2, 2] / (cm$table[2, 2] + cm$table[2, 1])\n",
    "recall <- cm$table[2, 2] / (cm$table[2, 2] + cm$table[1, 2])\n",
    "f1_score <- 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "cat(\"Precision:\", precision, \"\\n\")\n",
    "cat(\"Recall:\", recall, \"\\n\")\n",
    "cat(\"F1 Score:\", f1_score, \"\\n\")\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_obj <- roc(df_test[,\"Exited\"], test_preds)\n",
    "roc_auc <- auc(roc_obj)\n",
    "cat(\"ROC AUC:\", roc_auc, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "We save the trained XGBoost model as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save the model (notice the .json extension, we could also save it as .bin)\n",
    "# this ensures compatibility with the ValidMind sdk\n",
    "xgb.save(model, \"r_xgb_churn_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Simple Logistic Regression Model\n",
    "As a comparison, we train a simple logistic regression model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# now lets train a simple logistic regression model\n",
    "lg_reg_model <- glm(Exited ~ ., data = as.data.frame(df_train), family = \"binomial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "We display a summary of the trained logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Exited ~ ., family = \"binomial\", data = as.data.frame(df_train))\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.3284  -0.6470  -0.4563  -0.2781   2.8954  \n",
       "\n",
       "Coefficients:\n",
       "                   Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)      -3.732e+00  2.305e-01 -16.187  < 2e-16 ***\n",
       "GeographyFrance  -1.113e-01  9.474e-02  -1.174 0.240252    \n",
       "GeographyGermany  7.394e-01  1.054e-01   7.018 2.25e-12 ***\n",
       "Gender           -4.974e-01  7.319e-02  -6.796 1.07e-11 ***\n",
       "Age               7.142e-02  3.433e-03  20.803  < 2e-16 ***\n",
       "Tenure           -1.170e-02  1.263e-02  -0.926 0.354301    \n",
       "Balance           2.525e-06  6.995e-07   3.610 0.000306 ***\n",
       "NumOfProducts    -1.300e-01  6.475e-02  -2.008 0.044643 *  \n",
       "HasCrCard        -1.468e-02  8.025e-02  -0.183 0.854836    \n",
       "IsActiveMember   -9.979e-01  7.682e-02 -12.989  < 2e-16 ***\n",
       "EstimatedSalary   2.248e-07  6.337e-07   0.355 0.722854    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 5612.8  on 5599  degrees of freedom\n",
       "Residual deviance: 4760.6  on 5589  degrees of freedom\n",
       "AIC: 4782.6\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lg_reg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>-3.73163074444561</dd><dt>GeographyFrance</dt><dd>-0.111254692545161</dd><dt>GeographyGermany</dt><dd>0.73938562185064</dd><dt>Gender</dt><dd>-0.497380970370031</dd><dt>Age</dt><dd>0.0714194308317766</dd><dt>Tenure</dt><dd>-0.0116956480620419</dd><dt>Balance</dt><dd>2.52544411990314e-06</dd><dt>NumOfProducts</dt><dd>-0.130015233022276</dd><dt>HasCrCard</dt><dd>-0.0146825015464598</dd><dt>IsActiveMember</dt><dd>-0.997861450907317</dd><dt>EstimatedSalary</dt><dd>2.24751413745725e-07</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] -3.73163074444561\n",
       "\\item[GeographyFrance] -0.111254692545161\n",
       "\\item[GeographyGermany] 0.73938562185064\n",
       "\\item[Gender] -0.497380970370031\n",
       "\\item[Age] 0.0714194308317766\n",
       "\\item[Tenure] -0.0116956480620419\n",
       "\\item[Balance] 2.52544411990314e-06\n",
       "\\item[NumOfProducts] -0.130015233022276\n",
       "\\item[HasCrCard] -0.0146825015464598\n",
       "\\item[IsActiveMember] -0.997861450907317\n",
       "\\item[EstimatedSalary] 2.24751413745725e-07\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   -3.73163074444561GeographyFrance\n",
       ":   -0.111254692545161GeographyGermany\n",
       ":   0.73938562185064Gender\n",
       ":   -0.497380970370031Age\n",
       ":   0.0714194308317766Tenure\n",
       ":   -0.0116956480620419Balance\n",
       ":   2.52544411990314e-06NumOfProducts\n",
       ":   -0.130015233022276HasCrCard\n",
       ":   -0.0146825015464598IsActiveMember\n",
       ":   -0.997861450907317EstimatedSalary\n",
       ":   2.24751413745725e-07\n",
       "\n"
      ],
      "text/plain": [
       "     (Intercept)  GeographyFrance GeographyGermany           Gender \n",
       "   -3.731631e+00    -1.112547e-01     7.393856e-01    -4.973810e-01 \n",
       "             Age           Tenure          Balance    NumOfProducts \n",
       "    7.141943e-02    -1.169565e-02     2.525444e-06    -1.300152e-01 \n",
       "       HasCrCard   IsActiveMember  EstimatedSalary \n",
       "   -1.468250e-02    -9.978615e-01     2.247514e-07 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef(lg_reg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Data\n",
    "We make predictions on the test data and calculate the accuracy of the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.805416666666667"
      ],
      "text/latex": [
       "0.805416666666667"
      ],
      "text/markdown": [
       "0.805416666666667"
      ],
      "text/plain": [
       "[1] 0.8054167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "test_preds <- predict(lg_reg_model, newdata = as.data.frame(df_test), type = \"response\")\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "test_preds_binary <- ifelse(test_preds > 0.5, 1, 0)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "accuracy <- sum(test_preds_binary == df_test[,\"Exited\"])/nrow(df_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics\n",
    "We calculate the confusion matrix, precision, recall, F1 score, and ROC AUC for the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5890411 \n",
      "Recall: 0.1744422 \n",
      "F1 Score: 0.2691706 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7616043 \n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm <- confusionMatrix(as.factor(test_preds_binary), as.factor(df_test[,\"Exited\"]))\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision <- cm$table[2, 2] / (cm$table[2, 2] + cm$table[2, 1])\n",
    "recall <- cm$table[2, 2] / (cm$table[2, 2] + cm$table[1, 2])\n",
    "f1_score <- 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "cat(\"Precision:\", precision, \"\\n\")\n",
    "cat(\"Recall:\", recall, \"\\n\")\n",
    "cat(\"F1 Score:\", f1_score, \"\\n\")\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_obj <- roc(df_test[,\"Exited\"], test_preds)\n",
    "roc_auc <- auc(roc_obj)\n",
    "cat(\"ROC AUC:\", roc_auc, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "We save the trained logistic regression model as an RDS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "saveRDS(lg_reg_model, \"r_log_reg_churn_model.rds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
