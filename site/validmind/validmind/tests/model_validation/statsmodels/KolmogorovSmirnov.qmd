---
title: "[validmind](/validmind/validmind.qmd).KolmogorovSmirnov"
sidebar: validmind-reference
toc-depth: 4
toc-expand: 4
# module.qmd.jinja2
---

<!-- function.qmd.jinja2 -->

## KolmogorovSmirnov<span class="suffix"></span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="decorators"><span class="decorator">@<span class="n">tags(<span class="s">'tabular_data'</span>, <span class="s">'data_distribution'</span>, <span class="s">'statistical_test'</span>, <span class="s">'statsmodels'</span>)</span></span>

<span class="decorator">@<span class="n">tasks(<span class="s">'classification'</span>, <span class="s">'regression'</span>)</span></span> </span>

<span class="kw">def</span><span class="name">KolmogorovSmirnov</span>(<span class="params"><span class="n">model</span><span class="p">:</span><a href="/validmind/validmind/vm_models.qmd#vmmodel">validmind.vm_models.VMModel</a><span class="muted">,</span></span><span class="params"><span class="n">dataset</span><span class="p">:</span><a href="/validmind/validmind/vm_models.qmd#vmdataset">validmind.vm_models.VMDataset</a><span class="muted">,</span></span><span class="params"><span class="n">dist</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">'norm'</span></span>)<span class="p"> â†’ </span><span class="return-annotation"><span class="n">Tuple</span><span class="p">\[</span><span class="n">List</span><span class="p">\[</span><span class="n">Dict</span><span class="p">\[</span><span class="nb">str</span><span class="p">, </span><span class="nb">float</span><span class="p">\]</span><span class="p">\]</span><span class="p">, </span><a href="/validmind/validmind/vm_models.qmd#rawdata">validmind.vm_models.RawData</a><span class="p">\]</span></span>:

:::

<!-- docstring.jinja2 -->

Assesses whether each feature in the dataset aligns with a normal distribution using the Kolmogorov-Smirnov test.

### Purpose

The Kolmogorov-Smirnov (KS) test evaluates the distribution of features in a dataset to determine their alignment with a normal distribution. This is important because many statistical methods and machine learning models assume normality in the data distribution.

### Test Mechanism

This test calculates the KS statistic and corresponding p-value for each feature in the dataset. It does so by comparing the cumulative distribution function of the feature with an ideal normal distribution. The KS statistic and p-value for each feature are then stored in a dictionary. The p-value threshold to reject the normal distribution hypothesis is not preset, providing flexibility for different applications.

### Signs of High Risk

- Elevated KS statistic for a feature combined with a low p-value, indicating a significant divergence from a normal distribution.
- Features with notable deviations that could create problems if the model assumes normality in data distribution.

### Strengths

- The KS test is sensitive to differences in the location and shape of empirical cumulative distribution functions.
- It is non-parametric and adaptable to various datasets, as it does not assume any specific data distribution.
- Provides detailed insights into the distribution of individual features.

### Limitations

- The test's sensitivity to disparities in the tails of data distribution might cause false alarms about non-normality.
- Less effective for multivariate distributions, as it is designed for univariate distributions.
- Does not identify specific types of non-normality, such as skewness or kurtosis, which could impact model fitting.
