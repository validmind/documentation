---
title: "[validmind](/validmind/validmind.qmd).WeakspotsDiagnosis"
sidebar: validmind-reference
toc-depth: 4
toc-expand: 4
# module.qmd.jinja2
---

<!-- function.qmd.jinja2 -->

## WeakspotsDiagnosis<span class="suffix"></span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="decorators"><span class="decorator">@<span class="n">tags(<span class="s">'sklearn'</span>, <span class="s">'binary_classification'</span>, <span class="s">'multiclass_classification'</span>, <span class="s">'model_diagnosis'</span>, <span class="s">'visualization'</span>)</span></span><span class="decorator">@<span class="n">tasks(<span class="s">'classification'</span>, <span class="s">'text_classification'</span>)</span></span></span>

<span class="kw">def</span><span class="name">WeakspotsDiagnosis</span>(<span class="params"><span class="n">datasets</span><span class="p">:</span><span class="n">List</span><span class="p">\[</span><a href="/validmind/validmind/vm_models.qmd#vmdataset">validmind.vm_models.VMDataset</a><span class="p">\]</span><span class="muted">,</span></span><span class="params"><span class="n">model</span><span class="p">:</span><a href="/validmind/validmind/vm_models.qmd#vmmodel">validmind.vm_models.VMModel</a><span class="muted">,</span></span><span class="params"><span class="n">features_columns</span><span class="p">:</span><span class="n">Union</span><span class="p">\[</span><span class="n">List</span><span class="p">\[</span><span class="nb">str</span><span class="p">\]</span><span class="p">, </span><span class="n">None</span><span class="p">\]</span><span class="o">=</span><span class="kc">None</span><span class="muted">,</span></span><span class="params"><span class="n">metrics</span><span class="p">:</span><span class="n">Union</span><span class="p">\[</span><span class="n">Dict</span><span class="p">\[</span><span class="nb">str</span><span class="p">, </span><span class="n">Callable</span><span class="p">\]</span><span class="p">, </span><span class="n">None</span><span class="p">\]</span><span class="o">=</span><span class="kc">None</span><span class="muted">,</span></span><span class="params"><span class="n">thresholds</span><span class="p">:</span><span class="n">Union</span><span class="p">\[</span><span class="n">Dict</span><span class="p">\[</span><span class="nb">str</span><span class="p">, </span><span class="nb">float</span><span class="p">\]</span><span class="p">, </span><span class="n">None</span><span class="p">\]</span><span class="o">=</span><span class="kc">None</span></span>):

:::

<!-- docstring.jinja2 -->

Identifies and visualizes weak spots in a machine learning model's performance across various sections of the feature space.

### Purpose

The weak spots test is applied to evaluate the performance of a machine learning model within specific regions of its feature space. This test slices the feature space into various sections, evaluating the model's outputs within each section against specific performance metrics (e.g., accuracy, precision, recall, and F1 scores). The ultimate aim is to identify areas where the model's performance falls below the set thresholds, thereby exposing its possible weaknesses and limitations.

### Test Mechanism

The test mechanism adopts an approach of dividing the feature space of the training dataset into numerous bins. The model's performance metrics (accuracy, precision, recall, F1 scores) are then computed for each bin on both the training and test datasets. A "weak spot" is identified if any of the performance metrics fall below a predetermined threshold for a particular bin on the test dataset. The test results are visually plotted as bar charts for each performance metric, indicating the bins which fail to meet the established threshold.

### Signs of High Risk

- Any performance metric of the model dropping below the set thresholds.
- Significant disparity in performance between the training and test datasets within a bin could be an indication of overfitting.
- Regions or slices with consistently low performance metrics. Such instances could mean that the model struggles to handle specific types of input data adequately, resulting in potentially inaccurate predictions.

### Strengths

- The test helps pinpoint precise regions of the feature space where the model's performance is below par, allowing for more targeted improvements to the model.
- The graphical presentation of the performance metrics offers an intuitive way to understand the model's performance across different feature areas.
- The test exhibits flexibility, letting users set different thresholds for various performance metrics according to the specific requirements of the application.

### Limitations

- The binning system utilized for the feature space in the test could over-simplify the model's behavior within each bin. The granularity of this slicing depends on the chosen 'bins' parameter and can sometimes be arbitrary.
- The effectiveness of this test largely hinges on the selection of thresholds for the performance metrics, which may not hold universally applicable and could be subjected to the specifications of a particular model and application.
- The test is unable to handle datasets with a text column, limiting its application to numerical or categorical data types only.
- Despite its usefulness in highlighting problematic regions, the test does not offer direct suggestions for model improvement.
