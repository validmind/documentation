---
title: "[validmind](/validmind/validmind.qmd).MinimumROCAUCScore"
sidebar: validmind-reference
toc-depth: 4
toc-expand: 4
# module.qmd.jinja2
---

<!-- function.qmd.jinja2 -->

## MinimumROCAUCScore<span class="suffix"></span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="decorators"><span class="decorator">@<span class="n">tags(<span class="s">'sklearn'</span>, <span class="s">'binary_classification'</span>, <span class="s">'multiclass_classification'</span>, <span class="s">'model_performance'</span>)</span></span>

<span class="decorator">@<span class="n">tasks(<span class="s">'classification'</span>, <span class="s">'text_classification'</span>)</span></span> </span>

<span class="kw">def</span><span class="name">MinimumROCAUCScore</span>(<span class="params"><span class="n">dataset</span><span class="p">:</span><a href="/validmind/validmind/vm_models.qmd#vmdataset">validmind.vm_models.VMDataset</a><span class="muted">,</span></span><span class="params"><span class="n">model</span><span class="p">:</span><a href="/validmind/validmind/vm_models.qmd#vmmodel">validmind.vm_models.VMModel</a><span class="muted">,</span></span><span class="params"><span class="n">min_threshold</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="kc">0.5</span></span>)<span class="p"> â†’ </span><span class="return-annotation"><span class="n">Tuple</span><span class="p">\[</span><span class="n">List</span><span class="p">\[</span><span class="n">Dict</span><span class="p">\[</span><span class="nb">str</span><span class="p">, </span><span class="nb">float</span><span class="p">\]</span><span class="p">\]</span><span class="p">, </span><span class="nb">bool</span><span class="p">, </span><a href="/validmind/validmind/vm_models.qmd#rawdata">validmind.vm_models.RawData</a><span class="p">\]</span></span>:

:::

<!-- docstring.jinja2 -->

Validates model by checking if the ROC AUC score meets or surpasses a specified threshold.

### Purpose

The Minimum ROC AUC Score test is used to determine the model's performance by ensuring that the Receiver Operating Characteristic Area Under the Curve (ROC AUC) score on the validation dataset meets or exceeds a predefined threshold. The ROC AUC score indicates how well the model can distinguish between different classes, making it a crucial measure in binary and multiclass classification tasks.

### Test Mechanism

This test implementation calculates the multiclass ROC AUC score on the true target values and the model's predictions. The test converts the multi-class target variables into binary format using `LabelBinarizer` before computing the score. If this ROC AUC score is higher than the predefined threshold (defaulted to 0.5), the test passes; otherwise, it fails. The results, including the ROC AUC score, the threshold, and whether the test passed or failed, are then stored in a `ThresholdTestResult` object.

### Signs of High Risk

- A high risk or failure in the model's performance as related to this metric would be represented by a low ROC AUC score, specifically any score lower than the predefined minimum threshold. This suggests that the model is struggling to distinguish between different classes effectively.

### Strengths

- The test considers both the true positive rate and false positive rate, providing a comprehensive performance measure.
- ROC AUC score is threshold-independent meaning it measures the model's quality across various classification thresholds.
- Works robustly with binary as well as multi-class classification problems.

### Limitations

- ROC AUC may not be useful if the class distribution is highly imbalanced; it could perform well in terms of AUC but still fail to predict the minority class.
- The test does not provide insight into what specific aspects of the model are causing poor performance if the ROC AUC score is unsatisfactory.
- The use of macro average for multiclass ROC AUC score implies equal weightage to each class, which might not be appropriate if the classes are imbalanced.
