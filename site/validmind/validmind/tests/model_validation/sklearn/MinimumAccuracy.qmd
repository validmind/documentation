---
title: "[validmind](/validmind/validmind.qmd).MinimumAccuracy"
sidebar: validmind-reference
toc-depth: 4
toc-expand: 4
# module.qmd.jinja2
---

<!-- function.qmd.jinja2 -->

## MinimumAccuracy<span class="suffix"></span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="decorators"><span class="decorator">@<span class="n">tags(<span class="s">'sklearn'</span>, <span class="s">'binary_classification'</span>, <span class="s">'multiclass_classification'</span>, <span class="s">'model_performance'</span>)</span></span>

<span class="decorator">@<span class="n">tasks(<span class="s">'classification'</span>, <span class="s">'text_classification'</span>)</span></span> </span>

<span class="kw">def</span><span class="name">MinimumAccuracy</span>(<span class="params"><span class="n">dataset</span><span class="p">:</span><a href="/validmind/validmind/vm_models.qmd#vmdataset">validmind.vm_models.VMDataset</a><span class="muted">,</span></span><span class="params"><span class="n">model</span><span class="p">:</span><a href="/validmind/validmind/vm_models.qmd#vmmodel">validmind.vm_models.VMModel</a><span class="muted">,</span></span><span class="params"><span class="n">min_threshold</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="kc">0.7</span></span>)<span class="p"> → </span><span class="return-annotation"><span class="n">Tuple</span><span class="p">\[</span><span class="n">List</span><span class="p">\[</span><span class="n">Dict</span><span class="p">\[</span><span class="nb">str</span><span class="p">, </span><span class="nb">float</span><span class="p">\]</span><span class="p">\]</span><span class="p">, </span><span class="nb">bool</span><span class="p">, </span><a href="/validmind/validmind/vm_models.qmd#rawdata">validmind.vm_models.RawData</a><span class="p">\]</span></span>:

:::

<!-- docstring.jinja2 -->

Checks if the model's prediction accuracy meets or surpasses a specified threshold.

### Purpose

The Minimum Accuracy test’s objective is to verify whether the model's prediction accuracy on a specific dataset meets or surpasses a predetermined minimum threshold. Accuracy, which is simply the ratio of correct predictions to total predictions, is a key metric for evaluating the model's performance. Considering binary as well as multiclass classifications, accurate labeling becomes indispensable.

### Test Mechanism

The test mechanism involves contrasting the model's accuracy score with a preset minimum threshold value, with the default being 0.7. The accuracy score is computed utilizing sklearn’s `accuracy_score` method, where the true labels `y_true` and predicted labels `class_pred` are compared. If the accuracy score is above the threshold, the test receives a passing mark. The test returns the result along with the accuracy score and threshold used for the test.

### Signs of High Risk

- Model fails to achieve or surpass the predefined score threshold.
- Persistent scores below the threshold, indicating a high risk of inaccurate predictions.

### Strengths

- Simplicity, presenting a straightforward measure of holistic model performance across all classes.
- Particularly advantageous when classes are balanced.
- Versatile, as it can be implemented on both binary and multiclass classification tasks.

### Limitations

- Misleading accuracy scores when classes in the dataset are highly imbalanced.
- Favoritism towards the majority class, giving an inaccurate perception of model performance.
- Inability to measure the model's precision, recall, or capacity to manage false positives or false negatives.
- Focused on overall correctness and may not be sufficient for all types of model analytics.
