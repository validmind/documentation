---
title: "[validmind](/validmind/validmind.qmd).RobustnessDiagnosis"
sidebar: validmind-reference
toc-depth: 4
toc-expand: 4
# module.qmd.jinja2
---

<!-- function.qmd.jinja2 -->

## RobustnessDiagnosis<span class="suffix"></span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="decorators"><span class="decorator">@<span class="n">tags(<span class="s">'sklearn'</span>, <span class="s">'model_diagnosis'</span>, <span class="s">'visualization'</span>)</span></span><span class="decorator">@<span class="n">tasks(<span class="s">'classification'</span>, <span class="s">'regression'</span>)</span></span></span>

<span class="kw">def</span><span class="name">RobustnessDiagnosis</span>(<span class="params"><span class="n">datasets</span><span class="p">:</span><span class="n">List</span><span class="p">\[</span><a href="/validmind/validmind/vm_models.html#vmdataset">validmind.vm_models.VMDataset</a><span class="p">\]</span><span class="muted">,</span></span><span class="params"><span class="n">model</span><span class="p">:</span><a href="/validmind/validmind/vm_models.html#vmmodel">validmind.vm_models.VMModel</a><span class="muted">,</span></span><span class="params"><span class="n">metric</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="muted">,</span></span><span class="params"><span class="n">scaling_factor_std_dev_list</span><span class="p">:</span><span class="n">List</span><span class="p">\[</span><span class="nb">float</span><span class="p">\]</span><span class="o">=</span><span class="n">DEFAULT_STD_DEV_LIST</span><span class="muted">,</span></span><span class="params"><span class="n">performance_decay_threshold</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="n">DEFAULT_DECAY_THRESHOLD</span></span>):

:::

<!-- docstring.jinja2 -->

Assesses the robustness of a machine learning model by evaluating performance decay under noisy conditions.

### Purpose

The Robustness Diagnosis test aims to evaluate the resilience of a machine learning model when subjected to perturbations or noise in its input data. This is essential for understanding the model's ability to handle real-world scenarios where data may be imperfect or corrupted.

### Test Mechanism

This test introduces Gaussian noise to the numeric input features of the datasets at varying scales of standard deviation. The performance of the model is then measured using a specified metric. The process includes:

- Adding Gaussian noise to numerical input features based on scaling factors.
- Evaluating the model's performance on the perturbed data using metrics like AUC for classification tasks and MSE for regression tasks.
- Aggregating and plotting the results to visualize performance decay relative to perturbation size.

### Signs of High Risk

- A significant drop in performance metrics with minimal noise.
- Performance decay values exceeding the specified threshold.
- Consistent failure to meet performance standards across multiple perturbation scales.

### Strengths

- Provides insights into the model's robustness against noisy or corrupted data.
- Utilizes a variety of performance metrics suitable for both classification and regression tasks.
- Visualization helps in understanding the extent of performance degradation.

### Limitations

- Gaussian noise might not adequately represent all types of real-world data perturbations.
- Performance thresholds are somewhat arbitrary and might need tuning.
- The test may not account for more complex or unstructured noise patterns that could affect model robustness.
