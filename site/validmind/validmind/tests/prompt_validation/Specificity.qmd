---
title: "[validmind](/validmind/validmind.html).Specificity"
sidebar: validmind-reference
toc-depth: 4
toc-expand: 4
# module.qmd.jinja2
---

## call_model<span class='muted'>()</span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="kw">def</span><span class="name">call_model</span>(<span class="params"><span class="n">system_prompt</span><span class="p">:</span><span class="nb">str</span><span class="muted">,</span></span><span class="params"><span class="n">user_prompt</span><span class="p">:</span><span class="nb">str</span><span class="muted">,</span></span><span class="params"><span class="n">temperature</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="kc">0.0</span><span class="muted">,</span></span><span class="params"><span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="kc">42</span></span>):

:::

<!-- docstring.jinja2 -->

Call LLM with the given prompts and return the response

## get_explanation<span class='muted'>()</span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="kw">def</span><span class="name">get_explanation</span>(<span class="param"><span class="n">response</span><span class="p">:</span><span class="nb">str</span></span>):

:::

<!-- docstring.jinja2 -->

Get just the explanation from the response string TODO: use json response mode instead of this

e.g. "Score: 8 Explanation: <some-explanation>" -> "<some-explanation>"

## get_score<span class='muted'>()</span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="kw">def</span><span class="name">get_score</span>(<span class="param"><span class="n">response</span><span class="p">:</span><span class="nb">str</span></span>):

:::

<!-- docstring.jinja2 -->

Get just the score from the response string TODO: use json response mode instead of this

e.g. "Score: 8 Explanation: <some-explanation>" -> 8

<!-- function.qmd.jinja2 -->

## Specificity[()]{.muted}

<!-- signatures.jinja2 -->

::: {.signature}

<span class="decorators"><span class="decorator">@<span class="n">tags(<span class="s">'llm'</span>, <span class="s">'zero_shot'</span>, <span class="s">'few_shot'</span>)</span></span><span class="decorator">@<span class="n">tasks(<span class="s">'text_classification'</span>, <span class="s">'text_summarization'</span>)</span></span></span>

<span class="kw">def</span><span class="name">Specificity</span>(<span class="params"><span class="n">model</span><span class="muted">,</span></span><span class="params"><span class="n">min_threshold</span><span class="o">=</span><span class="kc">7</span></span>):

:::

<!-- docstring.jinja2 -->

Evaluates and scores the specificity of prompts provided to a Large Language Model (LLM), based on clarity, detail, and relevance.

### Purpose

The Specificity Test evaluates the clarity, precision, and effectiveness of the prompts provided to a Language Model (LLM). It aims to ensure that the instructions embedded in a prompt are indisputably clear and relevant, thereby helping to remove ambiguity and steer the LLM towards desired outputs. This level of specificity significantly affects the accuracy and relevance of LLM outputs.

### Test Mechanism

The Specificity Test employs an LLM to grade each prompt based on clarity, detail, and relevance parameters within a specificity scale that extends from 1 to 10. On this scale, prompts scoring equal to or more than a predefined threshold (set to 7 by default) pass the evaluation, while those scoring below this threshold fail it. Users can adjust this threshold as per their requirements.

### Signs of High Risk

- Prompts scoring consistently below the established threshold
- Vague or ambiguous prompts that do not provide clear direction to the LLM
- Overly verbose prompts that may confuse the LLM instead of providing clear guidance

### Strengths

- Enables precise and clear communication with the LLM to achieve desired outputs
- Serves as a crucial means to measure the effectiveness of prompts
- Highly customizable, allowing users to set their threshold based on specific use cases

### Limitations

- This test doesn't consider the content comprehension capability of the LLM
- High specificity score doesn't guarantee a high-quality response from the LLM, as the model's performance is also dependent on various other factors
- Striking a balance between specificity and verbosity can be challenging, as overly detailed prompts might confuse or mislead the model

<!-- class.qmd.jinja2 -->

## [class]{.muted} MissingRequiredTestInputError

<!-- signatures.jinja2 -->

::: {.signature}

<span class="kw">class</span><span class="name">MissingRequiredTestInputError</span>:

:::

<!-- docstring.jinja2 -->

When a required test context variable is missing.

**Inherited members**

- **From BaseError**: [class BaseError[()]{.muted}](#class-baseerror), [__init__[()]{.muted}](#__init__), [__str__[()]{.muted}](#__str__), [description[()]{.muted}](#description)
- **From builtins.BaseException**: with_traceback, add_note
