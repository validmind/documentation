---
title: "[validmind](/validmind/validmind.qmd).HighPearsonCorrelation"
sidebar: validmind-reference
toc-depth: 4
toc-expand: 4
# module.qmd.jinja2
---

<!-- function.qmd.jinja2 -->

## HighPearsonCorrelation<span class="suffix"></span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="decorators"><span class="decorator">@<span class="n">tags(<span class="s">'tabular_data'</span>, <span class="s">'data_quality'</span>, <span class="s">'correlation'</span>)</span></span>

<span class="decorator">@<span class="n">tasks(<span class="s">'classification'</span>, <span class="s">'regression'</span>)</span></span> </span>

<span class="kw">def</span><span class="name">HighPearsonCorrelation</span>(<span class="params"><span class="n">dataset</span><span class="p">:</span><a href="/validmind/validmind/vm_models.qmd#vmdataset">validmind.vm_models.VMDataset</a><span class="muted">,</span></span><span class="params"><span class="n">max_threshold</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="kc">0.3</span><span class="muted">,</span></span><span class="params"><span class="n">top_n_correlations</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="kc">10</span><span class="muted">,</span></span><span class="params"><span class="n">feature_columns</span><span class="p">:</span><span class="nb">list</span><span class="o">=</span><span class="kc">None</span></span>)<span class="p"> â†’ </span><span class="return-annotation"><span class="n">Tuple</span><span class="p">\[</span><span class="n">List</span><span class="p">\[</span><span class="n">Dict</span><span class="p">\[</span><span class="nb">str</span><span class="p">, </span><span class="n">Any</span><span class="p">\]</span><span class="p">\]</span><span class="p">, </span><span class="nb">bool</span><span class="p">, </span><a href="/validmind/validmind/vm_models.qmd#rawdata">validmind.vm_models.RawData</a><span class="p">\]</span></span>:

:::

<!-- docstring.jinja2 -->

Identifies highly correlated feature pairs in a dataset suggesting feature redundancy or multicollinearity.

### Purpose

The High Pearson Correlation test measures the linear relationship between features in a dataset, with the main goal of identifying high correlations that might indicate feature redundancy or multicollinearity. Identification of such issues allows developers and risk management teams to properly deal with potential impacts on the machine learning model's performance and interpretability.

### Test Mechanism

The test works by generating pairwise Pearson correlations for all features in the dataset, then sorting and eliminating duplicate and self-correlations. It assigns a Pass or Fail based on whether the absolute value of the correlation coefficient surpasses a pre-set threshold (defaulted at 0.3). It lastly returns the top n strongest correlations regardless of passing or failing status (where n is 10 by default but can be configured by passing the `top_n_correlations` parameter).

### Signs of High Risk

- A high risk indication would be the presence of correlation coefficients exceeding the threshold.
- If the features share a strong linear relationship, this could lead to potential multicollinearity and model overfitting.
- Redundancy of variables can undermine the interpretability of the model due to uncertainty over the authenticity of individual variable's predictive power.

### Strengths

- Provides a quick and simple means of identifying relationships between feature pairs.
- Generates a transparent output that displays pairs of correlated variables, the Pearson correlation coefficient, and a Pass or Fail status for each.
- Aids in early identification of potential multicollinearity issues that may disrupt model training.

### Limitations

- Can only delineate linear relationships, failing to shed light on nonlinear relationships or dependencies.
- Sensitive to outliers where a few outliers could notably affect the correlation coefficient.
- Limited to identifying redundancy only within feature pairs; may fail to spot more complex relationships among three or more variables.
