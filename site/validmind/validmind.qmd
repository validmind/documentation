---
title: ValidMind Library
toc-depth: 3
toc-expand: 3
toc-location: left
toc-title: ""
---

The ValidMind Library is a suite of developer tools and methods designed to automate the documentation and validation of your models.

Designed to be model agnostic, the ValidMind Library provides all the standard functionality without requiring you to rewrite any functions as long as your model is built in Python.

With a rich array of documentation tools and test suites, from documenting descriptions of your datasets to testing your models for weak spots and overfit areas, the ValidMind Library helps you automate model documentation by feeding the ValidMind Platform with documentation artifacts and test results.

To install the client library:

```bash
pip install validmind
```

To initialize the client library, paste the code snippet with the client integration details directly into your
development source code, replacing this example with your own:

```python
import validmind as vm

vm.init(
  api_host = "https://api.dev.vm.validmind.ai/api/v1/tracking/tracking",
  api_key = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
  api_secret = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
  project = "<project-identifier>"
)
```

After you have pasted the code snippet into your development source code and executed the code, the Python client
library will register with ValidMind. You can now use the ValidMind Library to document and test your models,
and to upload to the ValidMind Platform.

#### Python Library API

* [\_\_version\_\_](#__version__)
* [init()](#init)
* [init_dataset()](#init_dataset)
* [init_model()](#init_model)
* [init_r_model()](#init_r_model)
* [get_test_suite()](#get_test_suite)
* [log_metric()](#log_metric)
* [preview_template()](#preview_template)
* [reload()](#reload)
* [run_documentation_tests()](#run_documentation_tests)
* [run_test_suite()](#run_test_suite)
* [tags()](#tags)
* [tasks()](#tasks)
* [test()](#test)

#### Submodules

* [\_\_version\_\_](#__version__)
* [datasets](#datasets)
* [errors](#errors)
* [test_suites](#test_suites)
* [tests](#tests)
* [unit_metrics](#unit_metrics)
* [vm_models](#vm_models)


## Python Library API

### \_\_version\_\_

```python
2.6.5
```

### get_test_suite()

```python
def get_test_suite(
    test_suite_id: str = None, 
    section: str = None, 
    args = (), 
    kwargs = {}
) -> validmind.vm_models.TestSuite:
```

Gets a TestSuite object for the current project or a specific test suite
        
This function provides an interface to retrieve the TestSuite instance for the
current project or a specific TestSuite instance identified by test_suite_id.
The project Test Suite will contain sections for every section in the project's
documentation template and these Test Suite Sections will contain all the tests
associated with that template section.
        
#### Arguments
            
- **test_suite_id (str, optional)**: The test suite name. If not passed, then theproject's test suite will be returned. Defaults to None.
- **section (str, optional)**: The section of the documentation template from whichto retrieve the test suite. This only applies if test_suite_id is None.Defaults to None.
- **args**: Additional arguments to pass to the TestSuite
- **kwargs**: Additional keyword arguments to pass to the TestSuite
        
### init()

```python
def init(
    project: Optional = None, 
    api_key: Optional = None, 
    api_secret: Optional = None, 
    api_host: Optional = None, 
    model: Optional = None, 
    monitoring: bool = False
)
```

Initializes the API client instances and calls the /ping endpoint to ensure
the provided credentials are valid and we can connect to the ValidMind API.
        
If the API key and secret are not provided, the client will attempt to
retrieve them from the environment variables `VM_API_KEY` and `VM_API_SECRET`.
        
#### Arguments
            
- **project (str, optional)**: The project CUID. Alias for model. Defaults to None. [DEPRECATED]
- **model (str, optional)**: The model CUID. Defaults to None.
- **api_key (str, optional)**: The API key. Defaults to None.
- **api_secret (str, optional)**: The API secret. Defaults to None.
- **api_host (str, optional)**: The API host. Defaults to None.
- **monitoring (bool)**: The ongoing monitoring flag. Defaults to False.
        
**Raises:**
        
- **ValueError**: If the API key and secret are not provided
                
### init_dataset()

```python
def init_dataset(
    dataset, 
    model = None, 
    index = None, 
    index_name: str = None, 
    date_time_index: bool = False, 
    columns: list = None, 
    text_column: str = None, 
    target_column: str = None, 
    feature_columns: list = None, 
    extra_columns: dict = None, 
    class_labels: dict = None, 
    type: str = None, 
    input_id: str = None, 
    __log = True
) -> validmind.vm_models.dataset.VMDataset:
```

Initializes a VM Dataset, which can then be passed to other functions
that can perform additional analysis and tests on the data. This function
also ensures we are reading a valid dataset type.
        
The following dataset types are supported:
- Pandas DataFrame
- Polars DataFrame
- Numpy ndarray
- Torch TensorDataset
        
#### Arguments
            
- **dataset**: dataset from various python libraries
- **model (VMModel)**: ValidMind model object
- **targets (vm.vm.DatasetTargets)**: A list of target variables
- **target_column (str)**: The name of the target column in the dataset
- **feature_columns (list)**: A list of names of feature columns in the dataset
- **extra_columns (dictionary)**: A dictionary containing the names of the
- **prediction_column and group_by_columns in the dataset**: 
- **class_labels (dict)**: A list of class labels for classification problems
- **type (str)**: The type of dataset (one of DATASET_TYPES)
- **input_id (str)**: The input ID for the dataset (e.g. "my_dataset"). By default,this will be set to `dataset` but if you are passing this dataset as atest input using some other key than `dataset`, then you should setthis to the same key.
        
**Raises:**
        
- **ValueError**: If the dataset type is not supported
                
**Returns:**
        
- **vm.vm.Dataset**: A VM Dataset instance
                
### init_model()

```python
def init_model(
    model: object = None, 
    input_id: str = 'model', 
    attributes: dict = None, 
    predict_fn: callable = None, 
    __log = True, 
    kwargs = {}
) -> validmind.vm_models.model.VMModel:
```

Initializes a VM Model, which can then be passed to other functions
that can perform additional analysis and tests on the data. This function
also ensures we are creating a model supported libraries.
        
#### Arguments
            
- **model**: A trained model or VMModel instance
- **input_id (str)**: The input ID for the model (e.g. "my_model"). By default,this will be set to `model` but if you are passing this model as atest input using some other key than `model`, then you should setthis to the same key.
- **attributes (dict)**: A dictionary of model attributes
- **predict_fn (callable)**: A function that takes an input and returns a prediction
- ****kwargs**: Additional arguments to pass to the model
        
**Raises:**
        
- **ValueError**: If the model type is not supported
                
**Returns:**
        
- **vm.VMModel**: A VM Model instance
                
### init_r_model()

```python
def init_r_model(
    model_path: str, 
    input_id: str = 'model'
) -> validmind.vm_models.model.VMModel:
```

Initializes a VM Model for an R model
        
R models must be saved to disk and the filetype depends on the model type...
Currently we support the following model types:
        
- LogisticRegression `glm` model in R: saved as an RDS file with `saveRDS`
- LinearRegression `lm` model in R: saved as an RDS file with `saveRDS`
- XGBClassifier: saved as a .json or .bin file with `xgb.save`
- XGBRegressor: saved as a .json or .bin file with `xgb.save`
        
LogisticRegression and LinearRegression models are converted to sklearn models by extracting
the coefficients and intercept from the R model. XGB models are loaded using the xgboost
since xgb models saved in .json or .bin format can be loaded directly with either Python or R
        
#### Arguments
            
- **model_path (str)**: The path to the R model saved as an RDS or XGB file
- **model_type (str)**: The type of the model (one of R_MODEL_TYPES)
        
**Returns:**
        
- **vm.vm.Model**: A VM Model instance
                
### log_metric()

```python
def log_metric(
    key: str, 
    value: float, 
    inputs: Optional = None, 
    params: Optional = None, 
    recorded_at: Optional = None
)
```

Logs a unit metric
        
Unit metrics are key-value pairs where the key is the metric name and the value is
a scalar (int or float). These key-value pairs are associated with the currently
selected model (inventory model in the ValidMind Platform) and keys can be logged
to over time to create a history of the metric. On the ValidMind Platform, these metrics
will be used to create plots/visualizations for documentation and dashboards etc.
        
#### Arguments
            
- **key (str)**: The metric key
- **value (float)**: The metric value
- **inputs (list, optional)**: A list of input IDs that were used to compute the metric.
- **params (dict, optional)**: Dictionary of parameters used to compute the metric.
- **recorded_at (str, optional)**: The timestamp of the metric. Server will usecurrent time if not provided.
        
### preview_template()

```python
def preview_template()
```

Preview the documentation template for the current project
        
This function will display the documentation template for the current project. If
the project has not been initialized, then an error will be raised.
        
**Raises:**
        
- **ValueError**: If the project has not been initialized
                
### reload()

```python
def reload()
```

Reconnect to the ValidMind API and reload the project configuration
        
### run_documentation_tests()

```python
def run_documentation_tests(
    section = None, 
    send = True, 
    fail_fast = False, 
    inputs = None, 
    config = None, 
    kwargs = {}
)
```

Collect and run all the tests associated with a template
        
This function will analyze the current project's documentation template and collect
all the tests associated with it into a test suite. It will then run the test
suite, log the results to the ValidMind API, and display them to the user.
        
#### Arguments
            
- **section (str or list, optional)**: The section(s) to preview. Defaults to None.
- **send (bool, optional)**: Whether to send the results to the ValidMind API. Defaults to True.
- **fail_fast (bool, optional)**: Whether to stop running tests after the first failure. Defaults to False.
- **inputs (dict, optional)**: A dictionary of test inputs to pass to the TestSuite
- **config**: A dictionary of test parameters to override the defaults
- ****kwargs**: backwards compatibility for passing in test inputs using keyword arguments
        
**Returns:**
        
- **TestSuite or dict**: The completed TestSuite instance or a dictionary of TestSuites if section is a list.
                
**Raises:**
        
- **ValueError**: If the project has not been initialized
                
### run_test_suite()

```python
def run_test_suite(
    test_suite_id, 
    send = True, 
    fail_fast = False, 
    config = None, 
    inputs = None, 
    kwargs = {}
)
```

High Level function for running a test suite
        
This function provides a high level interface for running a test suite. A test suite is
a collection of tests. This function will automatically find the correct test suite
class based on the test_suite_id, initialize each of the tests, and run them.
        
#### Arguments
            
- **test_suite_id (str)**: The test suite name (e.g. 'classifier_full_suite')
- **config (dict, optional)**: A dictionary of parameters to pass to the tests in thetest suite. Defaults to None.
- **send (bool, optional)**: Whether to post the test results to the API. send=Falseis useful for testing. Defaults to True.
- **fail_fast (bool, optional)**: Whether to stop running tests after the first failure. Defaults to False.
- **inputs (dict, optional)**: A dictionary of test inputs to pass to the TestSuite e.g. `model`, `dataset``models` etc. These inputs will be accessible by any test in the test suite. See the testdocumentation or `vm.describe_test()` for more details on the inputs required for each.
- ****kwargs**: backwards compatibility for passing in test inputs using keyword arguments
        
**Raises:**
        
- **ValueError**: If the test suite name is not found or if there is an error initializing the test suite
                
**Returns:**
        
- **TestSuite**: the TestSuite instance
                
### tags()

```python
def tags(tags* = ()):
```

Decorator for specifying tags for a test.
        
#### Arguments
            
- ***tags**: The tags to apply to the test.
        

### tasks()

```python
def tasks(tasks* = ()):
```

Decorator for specifying the task types that a test is designed for.
        
#### Arguments
            
- ***tasks**: The task types that the test is designed for.
        

### test()

```python
def test(func_or_id):
```

Decorator for creating and registering custom tests
        
This decorator registers the function it wraps as a test function within ValidMind
under the provided ID. Once decorated, the function can be run using the
`validmind.tests.run_test` function.
        
The function can take two different types of arguments:
        
- Inputs: ValidMind model or dataset (or list of models/datasets). These arguments
  must use the following names: `model`, `models`, `dataset`, `datasets`.
- Parameters: Any additional keyword arguments of any type (must have a default
  value) that can have any name.
        
The function should return one of the following types:
        
- Table: Either a list of dictionaries or a pandas DataFrame
- Plot: Either a matplotlib figure or a plotly figure
- Scalar: A single number (int or float)
- Boolean: A single boolean value indicating whether the test passed or failed
        
The function may also include a docstring. This docstring will be used and logged
as the metric's description.
        
#### Arguments
            
- **func**: The function to decorate
- **test_id**: The identifier for the metric. If not provided, the function name is used.
        
**Returns:**
  The decorated function.


## Submodules

    
    
    
    
### \_\_version\_\_


    
    
    
    
    
    
### datasets


Example datasets that can be used with the ValidMind Library.

    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
    
    
### errors


This module contains all the custom errors that are used in the ValidMind Library.

The following base errors are defined for others:
- BaseError
- APIRequestError


#### class APIRequestError(BaseError)

Generic error for API request errors that are not known.

                

#### class BaseError(Exception)



                
                    

```python
def description(self, args = (), kwargs = {}):
```


```python
def message():
```


#### class GetTestSuiteError(BaseError)

When the test suite could not be found.

                

#### class InitializeTestSuiteError(BaseError)

When the test suite was found but could not be initialized.

                

#### class InvalidAPICredentialsError(APIRequestError)



                
                    

```python
def description(self, args = (), kwargs = {}):
```


#### class InvalidContentIdPrefixError(APIRequestError)

When an invalid text content_id is sent to the API.

                

#### class InvalidInputError(BaseError)

When an invalid input object.

                

#### class InvalidMetricResultsError(APIRequestError)

When an invalid metric results object is sent to the API.

                

#### class InvalidProjectError(APIRequestError)



                
                    

```python
def description(self, args = (), kwargs = {}):
```


#### class InvalidRequestBodyError(APIRequestError)

When a POST/PUT request is made with an invalid request body.

                

#### class InvalidTestParametersError(BaseError)

When an invalid parameters for the test.

                

#### class InvalidTestResultsError(APIRequestError)

When an invalid test results object is sent to the API.

                

#### class InvalidTextObjectError(APIRequestError)

When an invalid Metadat (Text) object is sent to the API.

                

#### class InvalidValueFormatterError(BaseError)

When an invalid value formatter is provided when serializing results.

                

#### class InvalidXGBoostTrainedModelError(BaseError)

When an invalid XGBoost trained model is used when calling init_r_model.

                

#### class LoadTestError(BaseError)

Exception raised when an error occurs while loading a test

                
                    

```python
def original_error():
```


#### class MismatchingClassLabelsError(BaseError)

When the class labels found in the dataset don't match the provided target labels.

                

#### class MissingAPICredentialsError(BaseError)



                
                    

```python
def description(self, args = (), kwargs = {}):
```


#### class MissingCacheResultsArgumentsError(BaseError)

When the cache_results function is missing arguments.

                

#### class MissingClassLabelError(BaseError)

When the one or more class labels are missing from provided dataset targets.

                

#### class MissingDependencyError(BaseError)

When a required dependency is missing.

                
                    

```python
def extra():
```


```python
def required_dependencies():
```


#### class MissingDocumentationTemplate(BaseError)

When the client config is missing the documentation template.

                

#### class MissingModelIdError(BaseError)



                
                    

```python
def description(self, args = (), kwargs = {}):
```


#### class MissingOrInvalidModelPredictFnError(BaseError)

When the pytorch model is missing a predict function or its predict
method does not have the expected arguments.

                

#### class MissingRExtrasError(BaseError)

When the R extras have not been installed.

                
                    

```python
def description(self, args = (), kwargs = {}):
```


#### class MissingRequiredTestInputError(BaseError)

When a required test context variable is missing.

                

#### class MissingTextContentIdError(APIRequestError)

When a Text object is sent to the API without a content_id.

                

#### class MissingTextContentsError(APIRequestError)

When a Text object is sent to the API without a "text" attribute.

                

#### class SkipTestError(BaseError)

Useful error to throw when a test cannot be executed.

                

#### class TestInputInvalidDatasetError(BaseError)

When an invalid dataset is used in a test context.

                

#### class UnsupportedColumnTypeError(BaseError)

When an unsupported column type is found on a dataset.

                

#### class UnsupportedDatasetError(BaseError)

When an unsupported dataset is used.

                

#### class UnsupportedFigureError(BaseError)

When an unsupported figure object is constructed.

                

#### class UnsupportedModelError(BaseError)

When an unsupported model is used.

                

#### class UnsupportedModelForSHAPError(BaseError)

When an unsupported model is used for SHAP importance.

                

#### class UnsupportedRModelError(BaseError)

When an unsupported R model is used.

                
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
### test_suites


Entrypoint for test suites.


#### class ClassifierDiagnosis(TestSuite)

Test suite for sklearn classifier model diagnosis tests

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class ClassifierFullSuite(TestSuite)

Full test suite for binary classification models.

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class ClassifierMetrics(TestSuite)

Test suite for sklearn classifier metrics

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class ClassifierModelValidation(TestSuite)

Test suite for binary classification models.

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class ClassifierPerformance(TestSuite)

Test suite for sklearn classifier models

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            

#### class ClusterFullSuite(TestSuite)

Full test suite for clustering models.

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class ClusterMetrics(TestSuite)

Test suite for sklearn clustering metrics

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class ClusterPerformance(TestSuite)

Test suite for sklearn cluster performance

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            

#### class EmbeddingsFullSuite(TestSuite)

Full test suite for embeddings models.

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class EmbeddingsMetrics(TestSuite)

Test suite for embeddings metrics

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class EmbeddingsPerformance(TestSuite)

Test suite for embeddings model performance

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            

#### class LLMClassifierFullSuite(TestSuite)

Full test suite for LLM classification models.

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class PromptValidation(TestSuite)

Test suite for prompt validation

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            

#### class NLPClassifierFullSuite(TestSuite)

Full test suite for NLP classification models.

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            

#### class KmeansParametersOptimization(TestSuite)

Test suite for sklearn hyperparameters optimization

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            

#### class RegressionFullSuite(TestSuite)

Full test suite for regression models.

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class RegressionMetrics(TestSuite)

Test suite for performance metrics of regression metrics

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class RegressionPerformance(TestSuite)

Test suite for regression model performance

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            

#### class RegressionModelDescription(TestSuite)

Test suite for performance metric of regression model of statsmodels library

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class RegressionModelsEvaluation(TestSuite)

Test suite for metrics comparison of regression model of statsmodels library

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            

#### class SummarizationMetrics(TestSuite)

Test suite for Summarization metrics

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            

#### class TabularDataQuality(TestSuite)

Test suite for data quality on tabular datasets

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class TabularDataset(TestSuite)

Test suite for tabular datasets.

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class TabularDatasetDescription(TestSuite)

Test suite to extract metadata and descriptive
statistics from a tabular dataset

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            

#### class TextDataQuality(TestSuite)

Test suite for data quality on text data

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            

#### class TimeSeriesDataQuality(TestSuite)

Test suite for data quality on time series datasets

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class TimeSeriesDataset(TestSuite)

Test suite for time series datasets.

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class TimeSeriesModelValidation(TestSuite)

Test suite for time series model validation.

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class TimeSeriesMultivariate(TestSuite)

This test suite provides a preliminary understanding of the features
and relationship in multivariate dataset. It presents various
multivariate visualizations that can help identify patterns, trends,
and relationships between pairs of variables. The visualizations are
designed to explore the relationships between multiple features
simultaneously. They allow you to quickly identify any patterns or
trends in the data, as well as any potential outliers or anomalies.
The individual feature distribution can also be explored to provide
insight into the range and frequency of values observed in the data.
This multivariate analysis test suite aims to provide an overview of
the data structure and guide further exploration and modeling.

                
                    

```python
def suite_id():
```


```python
def tests():
```


#### class TimeSeriesUnivariate(TestSuite)

This test suite provides a preliminary understanding of the target variable(s)
used in the time series dataset. It visualizations that present the raw time
series data and a histogram of the target variable(s).

The raw time series data provides a visual inspection of the target variable's
behavior over time. This helps to identify any patterns or trends in the data,
as well as any potential outliers or anomalies. The histogram of the target
variable displays the distribution of values, providing insight into the range
and frequency of values observed in the data.

                
                    

```python
def suite_id():
```


```python
def tests():
```

    
            
    
    
    
### tests


ValidMind Tests Module

    
            

#### class TestProviderStore

Singleton class for storing test providers

                
                    

```python
def get_test_provider(self, namespace):
```
Get a test provider by namespace

Args:
    namespace (str): The namespace of the test provider

Returns:
    TestProvider: The test provider

```python
def has_test_provider(self, namespace):
```
Check if a test provider exists by namespace

Args:
    namespace (str): The namespace of the test provider

Returns:
    bool: True if the test provider exists

```python
def register_test_provider(self, namespace, test_provider):
```
Register an external test provider

Args:
    namespace (str): The namespace of the test provider
    test_provider (TestProvider): The test provider

```python
def test_providers():
```


#### class TestStore

Singleton class for storing loaded tests

                
                    

```python
def get_test(self, test_id):
```
Get a test by test ID

Args:
    test_id (str): The test ID

Returns:
    object: The test class or function

```python
def register_test(self, test_id, test = None):
```
Register a test

```python
def tests():
```

    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            

#### class BooleanOutputHandler(OutputHandler)



                
                    

```python
def can_handle(self, item):
```


```python
def process(self, item, result):
```


#### class FigureOutputHandler(OutputHandler)



                
                    

```python
def can_handle(self, item):
```


```python
def process(self, item, result):
```


#### class MetricOutputHandler(OutputHandler)



                
                    

```python
def can_handle(self, item):
```


```python
def process(self, item, result):
```


#### class OutputHandler(ABC)

Base class for handling different types of test outputs

                
                    

```python
def can_handle(self, item):
```
Check if this handler can process the given item

```python
def process(self, item, result):
```
Process the item and update the TestResult

#### class TableOutputHandler(OutputHandler)



                
                    

```python
def can_handle(self, item):
```


```python
def process(self, item, result):
```

    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            

#### class LocalTestProvider

Test providers in ValidMind are responsible for loading tests from different sources,
such as local files, databases, or remote services. The LocalTestProvider specifically
loads tests from the local file system.

To use the LocalTestProvider, you need to provide the root_folder, which is the
root directory for local tests. The test_id is a combination of the namespace (set
when registering the test provider) and the path to the test class module, where
slashes are replaced by dots and the .py extension is left out.

Example usage:

```
# Create an instance of LocalTestProvider with the root folder
test_provider = LocalTestProvider("/path/to/tests/folder")

# Register the test provider with a namespace
register_test_provider("my_namespace", test_provider)

# List all tests in the namespace (returns a list of test IDs)
test_provider.list_tests()
# this is used by the validmind.tests.list_tests() function to aggregate all tests
# from all test providers

# Load a test using the test_id (namespace + path to test class module)
test = test_provider.load_test("my_namespace.my_test_class")
# full path to the test class module is /path/to/tests/folder/my_test_class.py
```

Attributes:
    root_folder (str): The root directory for local tests.

                
                    

```python
def list_tests(self):
```
List all tests in the given namespace

Returns:
    list: A list of test IDs

```python
def load_test(self, test_id):
```
Load the test identified by the given test_id.

Args:
    test_id (str): The identifier of the test. This corresponds to the relative
    path of the python file from the root folder, with slashes replaced by dots

Returns:
    The test class that matches the last part of the test_id.

Raises:
    LocalTestProviderLoadModuleError: If the test module cannot be imported
    LocalTestProviderLoadTestError: If the test class cannot be found in the module

```python
def root_folder():
```


#### class TestProvider(Protocol)

Protocol for user-defined test providers

                
                    

```python
def list_tests(self):
```
List all tests in the given namespace

Returns:
    list: A list of test IDs

```python
def load_test(self, test_id):
```
Load the test function identified by the given test_id

Args:
    test_id (str): The test ID (does not contain the namespace under which
        the test is registered)

Returns:
    callable: The test function

Raises:
    FileNotFoundError: If the test is not found

#### class ValidMindTestProvider

Test provider for ValidMind tests

                
                    

```python
def list_tests(self):
```
List all tests in the ValidMind test provider

```python
def load_test(self, test_id):
```
Load a ValidMind test or unit metric

```python
def metrics_provider():
```


```python
def tests_provider():
```

    
            
    
    
    
### unit_metrics


    
    
    
    
### vm_models


Models entrypoint


#### class DataFrameDataset(VMDataset)

VM dataset implementation for pandas DataFrame.

                
                    

#### class PolarsDataset(VMDataset)

VM dataset implementation for Polars DataFrame.

                
                    

#### class TorchDataset(VMDataset)

VM dataset implementation for PyTorch Datasets.

                
                    

#### class VMDataset(VMInput)

Base class for VM datasets

Child classes should be used to support new dataset types (tensor, polars etc)
by converting the user's dataset into a numpy array collecting metadata like
column names and then call this (parent) class `__init__` method.

This way we can support multiple dataset types but under the hood we only
need to work with numpy arrays and pandas dataframes in this class.

Attributes:
    raw_dataset (np.ndarray): The raw dataset as a NumPy array.
    input_id (str): Identifier for the dataset.
    index (np.ndarray): The raw dataset index as a NumPy array.
    columns (Set[str]): The column names of the dataset.
    target_column (str): The target column name of the dataset.
    feature_columns (List[str]): The feature column names of the dataset.
    feature_columns_numeric (List[str]): The numeric feature column names of the dataset.
    feature_columns_categorical (List[str]): The categorical feature column names of the dataset.
    text_column (str): The text column name of the dataset for NLP tasks.
    target_class_labels (Dict): The class labels for the target columns.
    df (pd.DataFrame): The dataset as a pandas DataFrame.
    extra_columns (Dict): Extra columns to include in the dataset.

                
                    

```python
def add_extra_column(self, column_name, column_values = None):
```
Adds an extra column to the dataset without modifying the dataset `features` and `target` columns.

Args:
    column_name (str): The name of the extra column.
    column_values (np.ndarray, optional): The values of the extra column.

```python
def assign_predictions(self, model, prediction_column = None, prediction_values = None, probability_column = None, probability_values = None, prediction_probabilities = None, kwargs = {}):
```
Assign predictions and probabilities to the dataset.

Args:
    model (VMModel): The model used to generate the predictions.
    prediction_column (str, optional): The name of the column containing the predictions. Defaults to None.
    prediction_values (list, optional): The values of the predictions. Defaults to None.
    probability_column (str, optional): The name of the column containing the probabilities. Defaults to None.
    probability_values (list, optional): The values of the probabilities. Defaults to None.
    prediction_probabilities (list, optional): DEPRECATED: The values of the probabilities. Defaults to None.
    kwargs: Additional keyword arguments that will get passed through to the model's `predict` method.

```python
def column_aliases():
```


```python
def columns():
```


```python
def df():
```
Returns the dataset as a pandas DataFrame.

Returns:
    pd.DataFrame: The dataset as a pandas DataFrame.

```python
def extra_columns():
```


```python
def index():
```


```python
def input_id():
```


```python
def prediction_column(self, model, column_name = None):
```
Get or set the prediction column for a model.

```python
def probability_column(self, model, column_name = None):
```
Get or set the probability column for a model.

```python
def target_class_labels():
```


```python
def target_classes(self):
```
Returns the target class labels or unique values of the target column.

```python
def target_column():
```


```python
def text_column():
```


```python
def with_options(self, kwargs = {}):
```
Support options provided when passing an input to run_test or run_test_suite

Example:
```python
# to only use a certain subset of columns in the dataset:
run_test(
    "validmind.SomeTestID",
    inputs={
        "dataset": {
            "input_id": "my_dataset_id",
            "columns": ["col1", "col2"],
        }
    }
)

# behind the scenes, this retrieves the dataset object (VMDataset) from the registry
# and then calls the `with_options()` method and passes `{"columns": ...}`
```

Args:
    **kwargs: Options:
        - columns: Filter columns in the dataset

Returns:
    VMDataset: A new instance of the dataset with only the specified columns

```python
def x():
```
Returns the input features (X) of the dataset.

Returns:
    np.ndarray: The input features.

```python
def x_df(self):
```
Returns a dataframe containing only the feature columns

```python
def y():
```
Returns the target variables (y) of the dataset.

Returns:
    np.ndarray: The target variables.

```python
def y_df(self):
```
Returns a dataframe containing the target column

```python
def y_pred(self, model):
```
Returns the predictions for a given model.

Attempts to stack complex prediction types (e.g., embeddings) into a single,
multi-dimensional array.

Args:
    model (VMModel): The model whose predictions are sought.

Returns:
    np.ndarray: The predictions for the model

```python
def y_pred_df(self, model):
```
Returns a dataframe containing the predictions for a given model

```python
def y_prob(self, model):
```
Returns the probabilities for a given model.

Args:
    model (str): The ID of the model whose predictions are sought.

Returns:
    np.ndarray: The probability variables.

```python
def y_prob_df(self, model):
```
Returns a dataframe containing the probabilities for a given model
    
            

#### class ExtraColumns

Extra columns for the dataset.

                
                    

```python
def add_extra(self, column_name):
```


```python
def extras():
```


```python
def flatten(self):
```
Get a list of all column names

```python
def from_dict(cls, data):
```


```python
def group_by_column():
```


```python
def prediction_column(self, model, column_name = None):
```
Get or set the prediction column for a model.

```python
def prediction_columns():
```


```python
def probability_column(self, model, column_name = None):
```
Get or set the probability column for a model.

```python
def probability_columns():
```

    
            
    
            

#### class Figure

Figure objects track the schema supported by the ValidMind API

                
                    

```python
def figure():
```


```python
def key():
```


```python
def ref_id():
```


```python
def serialize(self):
```
Serializes the Figure to a dictionary so it can be sent to the API

```python
def serialize_files(self):
```
Creates a `requests`-compatible files object to be sent to the API

```python
def to_widget(self):
```
Returns the ipywidget compatible representation of the figure. Ideally
we would render images as-is, but Plotly FigureWidgets don't work well
on Google Colab when they are combined with ipywidgets.
    
            

#### class VMInput(ABC)

Base class for ValidMind Input types

                
                    

```python
def with_options(self, kwargs = {}):
```
Allows for setting options on the input object that are passed by the user
when using the input to run a test or set of tests

To allow options, just override this method in the subclass (see VMDataset)
and ensure that it returns a new instance of the input with the specified options
set.

Args:
    **kwargs: Arbitrary keyword arguments that will be passed to the input object

Returns:
    VMInput: A new instance of the input with the specified options set
    
            

#### class ModelAttributes

Model attributes definition

                
                    

```python
def architecture():
```


```python
def framework():
```


```python
def framework_version():
```


```python
def from_dict(cls, data):
```
Creates a ModelAttributes instance from a dictionary

```python
def language():
```


```python
def task():
```


#### class ModelPipeline

Helper class for chaining models together

This shouldn't be used directly, it just gets used when chaining models with the
`|` operator since you can't use a list directly - you must use a type that
overloads the `|` operator.

                
                    

```python
def models():
```


#### class ModelTask(Enum)

Model task enums

                
                    

```python
def CLASSIFICATION():
```


```python
def REGRESSION():
```


#### class VMModel(VMInput)

An base class that wraps a trained model instance and its associated data.

Attributes:
    model (object, optional): The trained model instance. Defaults to None.
    input_id (str, optional): The input ID for the model. Defaults to None.
    attributes (ModelAttributes, optional): The attributes of the model. Defaults to None.
    name (str, optional): The name of the model. Defaults to the class name.

                
                    

```python
def attributes():
```


```python
def class_():
```


```python
def input_id():
```


```python
def language():
```


```python
def library():
```


```python
def library_version():
```


```python
def model():
```


```python
def name():
```


```python
def predict(self, args = (), kwargs = {}):
```
Predict method for the model. This is a wrapper around the model's

```python
def predict_proba(self, args = (), kwargs = {}):
```
Predict probabilties - must be implemented by subclass if needed

```python
def serialize(self):
```
Serializes the model to a dictionary so it can be sent to the API
    
            

#### class ErrorResult(Result)

Result for test suites that fail to load or run properly

                
                    

```python
def error():
```


```python
def log_async(self):
```


```python
def message():
```


```python
def name():
```


```python
def to_widget(self):
```


#### class Result

Base Class for test suite results

                
                    

```python
def log(self):
```
Log the result... Must be overridden by subclasses

```python
def name():
```


```python
def result_id():
```


```python
def show(self):
```
Display the result... May be overridden by subclasses

```python
def to_widget(self):
```
Create an ipywdiget representation of the result... Must be overridden by subclasses

#### class ResultTable

A dataclass that holds the table summary of result

                
                    

```python
def data():
```


```python
def serialize(self):
```


```python
def title():
```


#### class TestResult(Result)

Test result

                
                    

```python
def add_figure(self, figure):
```


```python
def add_table(self, table):
```


```python
def description():
```


```python
def figures():
```


```python
def inputs():
```


```python
def log(self, section_id = None, position = None, unsafe = False):
```
Log the result to ValidMind

Args:
    section_id (str): The section ID within the model document to insert the
        test result
    position (int): The position (index) within the section to insert the test
        result
    unsafe (bool): If True, log the result even if it contains sensitive data
        i.e. raw data from input datasets

```python
def log_async(self, section_id = None, position = None, unsafe = False):
```


```python
def metadata():
```


```python
def metric():
```


```python
def name():
```


```python
def params():
```


```python
def passed():
```


```python
def ref_id():
```


```python
def serialize(self):
```
Serialize the result for the API

```python
def tables():
```


```python
def test_name():
```
Get the test name, using custom title if available.

```python
def title():
```


```python
def to_widget(self):
```

    
            
    
            
    
            
    
    
    

#### Module Hierarchy##### api_client

* [api_client](api_client.qmd)

ValidMind API client

Note that this takes advantage of the fact that python modules are singletons to store and share
the configuration and session across the entire project regardless of where the client is imported.

##### client

* [client](client.qmd)

Client interface for all data and model validation functions

##### client_config

* [client_config](client_config.qmd)

Central class to track configuration of the ValidMind Library
client against the ValidMind API

##### datasets

* [datasets](datasets.qmd)

Example datasets that can be used with the ValidMind Library.

###### classification

* [classification](datasets/classification.qmd)

Entrypoint for classification datasets.

###### credit_risk

* [credit_risk](datasets/credit_risk.qmd)

Entrypoint for credit risk datasets.

###### nlp

* [nlp](datasets/nlp.qmd)

Example datasets that can be used with the ValidMind Library.

###### regression

* [regression](datasets/regression.qmd)

Entrypoint for regression datasets

##### errors

* [errors](errors.qmd)

This module contains all the custom errors that are used in the ValidMind Library.

The following base errors are defined for others:
- BaseError
- APIRequestError

##### html_templates

* [html_templates](html_templates.qmd)
###### content_blocks

* [content_blocks](html_templates/content_blocks.qmd)
##### input_registry

* [input_registry](input_registry.qmd)

Central class to register inputs

##### logging

* [logging](logging.qmd)

ValidMind logging module.

##### models

* [models](models.qmd)
###### foundation

* [foundation](models/foundation.qmd)
###### function

* [function](models/function.qmd)
###### huggingface

* [huggingface](models/huggingface.qmd)
###### metadata

* [metadata](models/metadata.qmd)
###### pipeline

* [pipeline](models/pipeline.qmd)
###### pytorch

* [pytorch](models/pytorch.qmd)
###### r_model

* [r_model](models/r_model.qmd)
###### sklearn

* [sklearn](models/sklearn.qmd)
##### template

* [template](template.qmd)
##### test_suites

* [test_suites](test_suites.qmd)

Entrypoint for test suites.

###### classifier

* [classifier](test_suites/classifier.qmd)

Test suites for sklearn-compatible classifier models

Ideal setup is to have the API client to read a
custom test suite from the project's configuration

###### cluster

* [cluster](test_suites/cluster.qmd)

Test suites for sklearn-compatible clustering models

Ideal setup is to have the API client to read a
custom test suite from the project's configuration

###### embeddings

* [embeddings](test_suites/embeddings.qmd)

Test suites for embeddings models

Ideal setup is to have the API client to read a
custom test suite from the project's configuration

###### llm

* [llm](test_suites/llm.qmd)

Test suites for LLMs

###### nlp

* [nlp](test_suites/nlp.qmd)

Test suites for NLP models

###### parameters_optimization

* [parameters_optimization](test_suites/parameters_optimization.qmd)

Test suites for sklearn-compatible hyper parameters tunning

Ideal setup is to have the API client to read a
custom test suite from the project's configuration

###### regression

* [regression](test_suites/regression.qmd)
###### statsmodels_timeseries

* [statsmodels_timeseries](test_suites/statsmodels_timeseries.qmd)

Time Series Test Suites from statsmodels

###### summarization

* [summarization](test_suites/summarization.qmd)

Test suites for llm summarization models

###### tabular_datasets

* [tabular_datasets](test_suites/tabular_datasets.qmd)

Test suites for tabular datasets

###### text_data

* [text_data](test_suites/text_data.qmd)

Test suites for text datasets

###### time_series

* [time_series](test_suites/time_series.qmd)

Time Series Test Suites

##### tests

* [tests](tests.qmd)

ValidMind Tests Module

###### comparison

* [comparison](tests/comparison.qmd)
###### data_validation

* [data_validation](tests/data_validation.qmd)
###### decorator

* [decorator](tests/decorator.qmd)

Decorators for creating and registering tests with the ValidMind Library.

###### load

* [load](tests/load.qmd)

Module for listing and loading tests.

###### model_validation

* [model_validation](tests/model_validation.qmd)
###### output

* [output](tests/output.qmd)
###### prompt_validation

* [prompt_validation](tests/prompt_validation.qmd)
###### run

* [run](tests/run.qmd)
###### test_providers

* [test_providers](tests/test_providers.qmd)
##### unit_metrics

* [unit_metrics](unit_metrics.qmd)
##### utils

* [utils](utils.qmd)
##### vm_models

* [vm_models](vm_models.qmd)

Models entrypoint

###### dataset

* [dataset](vm_models/dataset.qmd)
###### figure

* [figure](vm_models/figure.qmd)

Figure objects track the figure schema supported by the ValidMind API

###### input

* [input](vm_models/input.qmd)

Base class for ValidMind Input types

###### model

* [model](vm_models/model.qmd)

Model class wrapper module

###### result

* [result](vm_models/result.qmd)

