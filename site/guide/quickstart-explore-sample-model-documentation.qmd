---
title: "Explore sample model documentation"
date: last-modified
---

First, let's take a look at how the ValidMind handles model documentation. The best place to start is with the ValidMind Platform UI.

![](quickstart-platform-dashboard.png){width=90% fig-alt="An image showing the ValidMind Platform UI main dashboard"}

The ValidMind Platform UI is the central place to: 

- Work with model documentation and test results uploaded with the ValidMind Developer Framework.
- Prepare validation reports, work with model findings, and link evidence to findings.
- Collaborate with others, including model developers, model validators, and reviewers.

## Steps

1. [Log in to the ValidMind UI]({{< var vm_ui >}}).

2. Click **Model Inventory**.

3. Locate or search for the `[QuickStart] Customer Churn Model - Initial Validation` and select it.

   ![](quickstart-customer-churn-model.png){width=90% fig-alt="An image showing the main page for the QuickStart Customer Churn Model"}


   On the model overview page that opens, you can find important information about the model, such as:

    - The use case
    - The owners, validators, developers, and business unit associated with the model
    - The risk tier, model status, and current version
    - Model findings, recent activity, and much more

   In the left sidebar, you can find helpful links to the _model documentation_, _model findings_, _validation report_, _(activity) archive_, and _getting started_ information for integrating with the ValidMind Developer Framework.

   ::: {.callout-tip}
   Note that the model status is **In Initial Validation**. This is the status that a model starts in as part of the default workflow. You can click **{{< fa arrow-right-arrow-left >}} See workflow** to visualize the entire workflow that this model will go through.
   :::

5. In the left sidebar, select **Documentation** > **2. Data preparation** > **2.1. Data description**. 

   ![](data-description.png){width=90% fig-align="left" fig-alt="An image showing the data description page in the ValidMind UI"}

   This content is _generated by the ValidMind Developer Framework_ and provides information about the dataset used, including histograms, information about dataset quality, and test results.

   Sections that need your attention get flagged with `Requires Attention`. These sections get flagged automatically whenever a test result is above or below a certain threshold.

6. In the left sidebar, select **3. Model Development** and any of the subsection to see information that has been uploaded by the developer framework about:

   - Model training
   - Model evaluation
   - Model explainability and interpretability
   - Model diagnosis

   If you expand the **ValidMind Insights** right sidebar, the _documentation guidelines_ can tell you more about what these sections mean and help you with the task of documenting the model as a developer. If you are a validator, this is also where you can _add findings_. 

7. Finally, take a look at section **4. Monitoring and Governance**. 

   Sections like **4.1 Monitoring Plan** are not generated by the developer framework, but they get added by the model developer in the Platform UI. You can add both new text and test sections, called _blocks_ to your model documentation.

## What's next
 
Continue with [Register your first model](quickstart-register-your-first-model.qmd) to learn more about using the ValidMind Platform hands-on.