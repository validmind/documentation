# SelfCheckNLIScore

Evaluates text generation models' performance by quantifying the level of hallucination in generated texts compared to reference texts.

**Purpose**: The HallucinationScore metric is designed to assess the factual accuracy and reliability of text generated by models, focusing on the detection and quantification of hallucinationsâ€”instances where generated content deviates from factual or expected outputs. By comparing generated texts against reference texts, this metric highlights discrepancies indicative of hallucinations, offering insights into the model's ability to produce contextually and factually coherent content.

**Test Mechanism**: To compute the HallucinationScore, the metric employs a comparison between the generated texts (model predictions) and the provided reference texts (true values). Using the SelfCheckNLI model, it evaluates each generated text's level of factual congruence with the reference, assigning a hallucination score based on the semantic coherence and factual accuracy. The scores for each text instance are then visualized in a line plot, allowing for the examination of hallucination trends across the dataset.

**Signs of High Risk**:
- High hallucination scores across a significant portion of the dataset, indicating a prevalence of factually inaccurate or irrelevant content generation.
- Patterns of consistent hallucination in specific contexts or subjects, suggesting gaps in the model's understanding or knowledge.
- Sharp fluctuations in hallucination scores, which may reveal inconsistencies in the model's performance or sensitivity to certain types of input.

**Strengths**:
- Directly addresses the critical aspect of factual accuracy in generated text, beyond mere linguistic or stylistic coherence.
- Provides a granular, instance-by-instance analysis of model performance, allowing for targeted improvements and diagnostics.
- Facilitates a deeper understanding of a model's capabilities and limitations in producing reliable and accurate content.

**Limitations**:
- Reliance on the SelfCheckNLI model means the accuracy and effectiveness of the HallucinationScore are contingent upon the performance and suitability of the underlying NLI model.
- May not fully capture the subtleties of certain factual inaccuracies or the contextual relevance of reference texts, especially in complex or nuanced domains.
- Potentially resource-intensive, given the computational demands of running advanced NLI models for large datasets.