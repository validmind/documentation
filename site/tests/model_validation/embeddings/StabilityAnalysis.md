# StabilityAnalysis

Assesses the stability of embeddings generated by a model when faced with perturbed input data to ensure robustness
and consistency.

### Purpose

The Embedding Stability test evaluates the robustness of the embeddings generated by a model when the input text is
perturbed. By comparing the cosine similarities between the original and perturbed embeddings, it gauges the
model's ability to maintain consistent semantic representations under slight variations in the input data.

### Test Mechanism

This test works by:

- Perturbing the original text data.
- Generating embeddings for both the original and perturbed datasets using the model.
- Calculating the cosine similarities between the original and perturbed embeddings.
- Analyzing the distribution of these similarities (mean, min, max, median, and standard deviation).
- Determining the test result based on whether the mean similarity exceeds a predefined threshold (default is 0.7).

### Signs of High Risk

- Mean cosine similarity below the threshold (default is 0.7).
- Large standard deviation of cosine similarities, indicating inconsistency.
- Minimum similarity score significantly lower than expected.
- Failure to pass the threshold test based on the mean similarity.

### Strengths

- Provides a quantitative measure of embedding stability.
- Helps in identifying weaknesses in the model's ability to handle minor input variations.
- Visualization of similarity distributions aids in comprehensive analysis.
- Easy to interpret results with clear pass/fail criteria.

### Limitations

- Relies on the chosen perturbation method, which may not cover all possible variations in real-world data.
- Thresholds for similarity might need adjustment based on specific application requirements.
- Cosine similarity, while useful, may not capture all aspects of semantic stability.