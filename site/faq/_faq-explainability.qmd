## Do you include explainability-related testing and documentation? 
<span id="explanability"></span>
Yes, {{< var vm.product >}} includes explainability-related testing and documentation as part of our offerings. Our approach incorporates a comprehensive suite of tests designed to evaluate model interpretability and identify potential risks, ensuring transparency and reliability in model outcomes. 

Below is an overview of our key explainability-related tests:

- **Features AUC**^[[FeaturesAUC](/tests/model_validation/FeaturesAUC.md)] — Assesses the discriminatory power of individual features in binary classification models, providing insights into how well each feature differentiates between classes. This test supports explainability by isolating the contribution of each feature to the classification task.
- **Feature Importance**^[[FeatureImportance](/tests/model_validation/sklearn/FeatureImportance.md)] — Generates feature importance scores to identify and compare impactful features across different models and datasets. By highlighting the relative significance of features, this test clarifies how inputs influence model predictions.
- **Overfit Diagnosis**^[[OverfitDiagnosis](/tests/model_validation/sklearn/OverfitDiagnosis.md)] — Detects potential overfitting by comparing performance between training and testing sets for specific feature segments, highlighting areas of significant deviation. This test aids explainability by revealing where model behavior is inconsistent, offering insights into its generalization capability.
- **Permutation Feature Importance**^[[PermutationFeatureImportance](/tests/model_validation/sklearn/PermutationFeatureImportance.md)] — Measures feature significance by analyzing the impact of randomly rearranging feature values on model performance. This test quantifies the dependency of model performance on each feature, making it clear which inputs drive the predictions.
- **SHAP Global Importance**^[[SHAPGlobalImportance](/tests/model_validation/sklearn/SHAPGlobalImportance.md)] — Uses SHAP (SHapley Additive exPlanations) values to assign global importance to features, offering a clear explanation of model outcomes and supporting risk identification. SHAP values provide a mathematically sound attribution of model predictions to specific features, enhancing interpretability.
- **Weakspots Diagnosis**^[[WeakspotsDiagnosis](/tests/model_validation/sklearn/WeakspotsDiagnosis.md)] — Identifies and visualizes regions of suboptimal model performance across the feature space, highlighting areas that may require further attention. This test explains where and why the model struggles by connecting poor performance to specific feature regions.

::: {.callout}
## When logged for documentation, each test automatically generates a comprehensive report as soon as it is executed. 

- {{< var vm.product >}} leverages generative AI to produce tailored, detailed summaries that include the test description, key insights, and a concise summary of results. 
- This automated documentation ensures that every test outcome is transparently recorded, clearly communicated, and immediately actionable.

:::