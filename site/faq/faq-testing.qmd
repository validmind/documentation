---
title: "Testing"
date: last-modified
aliases:
  - /guide/faq-testing.html
listing:
  - id: faq-testing
    type: grid
    grid-columns: 3
    max-description-length: 250
    sort: false
    fields: [title, description]
    contents:
    - ../developer/model-testing/testing-overview.qmd
    - ../developer/model-testing/test-descriptions.qmd
    - ../guide/monitoring/ongoing-monitoring.qmd
categories: ["testing", "model documentation", "customization", "custom data", "explainability", "ongoing monitoring", "validmind library"]
---

## How do the out-of-the-box tests developed by {{< var vm.product >}} work?

All the default tests are developed using open-source Python and R libraries.

The {{< var validmind.developer >}}[^1] test interface is a light wrapper that defines utility functions to agnostically interact with different dataset and model backends, and contains functions to collect and post results to the {{< var validmind.platform >}}[^2] using a generic results schema.

## When do I use tests and tests suites?

While you have the flexibility to decide when to use which {{< var vm.product >}} tests, here are a few typical scenarios:[^3]

- **Dataset testing** — To document and validate your dataset.
- **Model testing** — To document and validate your model.
- **End-to-end testing** — To document a binary classification model and the relevant dataset end-to-end.

## Can we configure, customize, or add our own tests?

Yes, {{< var vm.product >}} allows tests to be manipulated at several levels:

- You can configure which tests are required to run programmatically depending on the model use case.[^4]
- You can change the thresholds and parameters for default tests already available in the {{< var vm.developer >}} — for instance, changing the threshold parameter for the class imbalance flag.[^5]
- You can also connect your own custom tests with the {{< var validmind.developer >}}. These custom tests are configurable and are able to run programmatically, just like the rest of the {{< var vm.developer >}}.[^6]
- Personalize tests further for your use case by using {{< var vm.product >}}'s `RawData` feature[^7] to customize the output of tests.

::: {.callout}
In addition to custom tests, you can also add use case and test-specific context for any test to enhance the LLM-generated test descriptions using the {{< var validmind.developer >}}.[^8]
:::

{{< include _faq-explainability.qmd >}}

{{< include _faq-synthetic-datasets.qmd >}}

{{< include _faq-monitoring.qmd >}}

## Learn more

:::{#faq-testing}
:::


<!-- FOOTNOTES -->

[^1]: [{{< var validmind.developer >}}](/developer/validmind-library.qmd)

[^2]: [Accessing {{< var vm.product >}}](/guide/configuration/accessing-validmind.qmd)

[^3]: [When do I use tests and test suites?](/developer/model-testing/testing-overview.qmd#when-do-i-use-tests-and-test-suites)

[^4]: [`run_documentation_tests()`](/validmind/validmind.qmd#run_documentation_tests)

[^5]: [`ClassImbalance()`](/validmind/validmind/tests/data_validation/ClassImbalance.qmd)

[^6]: [Can I use my own tests?](/developer/model-testing/testing-overview.qmd#can-i-use-my-own-tests)

[^7]: [Understand and utilize `RawData` in {{< var vm.product >}} tests](/notebooks/how_to/understand_utilize_rawdata.ipynb)

[^8]: [Add context to LLM-generated test descriptions](/notebooks/how_to/add_context_to_llm_descriptions.ipynb)