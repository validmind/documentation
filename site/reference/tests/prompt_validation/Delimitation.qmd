---
title: Delimitation
toc-depth: 3
toc-expand: 3
---

## call_model[()]{.muted}

```python
def call_model(
    system_prompt: {'cls': 'ExprName', 'name': 'str'},    user_prompt: {'cls': 'ExprName', 'name': 'str'},    temperature: {'cls': 'ExprName', 'name': 'float'} = 0.0,    seed: {'cls': 'ExprName', 'name': 'int'} = 42):
```

Call LLM with the given prompts and return the response

## get_explanation[()]{.muted}

```python
def get_explanation(
    response: {'cls': 'ExprName', 'name': 'str'}):
```

Get just the explanation from the response string TODO: use json response mode instead of this

```
e.g. "Score: 8
```

Explanation: <some-explanation>" -> "<some-explanation>"

## get_score[()]{.muted}

```python
def get_score(
    response: {'cls': 'ExprName', 'name': 'str'}):
```

Get just the score from the response string TODO: use json response mode instead of this

```
e.g. "Score: 8
```

Explanation: <some-explanation>" -> 8

## Delimitation[()]{.muted}

```python
def Delimitation(
    model,
    min_threshold = 7):
```

Evaluates the proper use of delimiters in prompts provided to Large Language Models.

### Purpose

The Delimitation Test aims to assess whether prompts provided to the Language Learning Model (LLM) correctly use delimiters to mark different sections of the input. Well-delimited prompts help simplify the interpretation process for the LLM, ensuring that the responses are precise and accurate.

### Test Mechanism

The test employs an LLM to examine prompts for appropriate use of delimiters such as triple quotation marks, XML tags, and section titles. Each prompt is assigned a score from 1 to 10 based on its delimitation integrity. Prompts with scores equal to or above the preset threshold (which is 7 by default, although it can be adjusted as necessary) pass the test.

### Signs of High Risk

- Prompts missing, improperly placed, or incorrectly used delimiters, leading to misinterpretation by the LLM.
- High-risk scenarios with complex prompts involving multiple tasks or diverse data where correct delimitation is crucial.
- Scores below the threshold, indicating a high risk.

### Strengths

- Ensures clarity in demarcating different components of given prompts.
- Reduces ambiguity in understanding prompts, especially for complex tasks.
- Provides a quantified insight into the appropriateness of delimiter usage, aiding continuous improvement.

### Limitations

- Only checks for the presence and placement of delimiters, not whether the correct delimiter type is used for the specific data or task.
- May not fully reveal the impacts of poor delimitation on the LLM's final performance.
- The preset score threshold may not be refined enough for complex tasks and prompts, requiring regular manual adjustment.

## [class]{.muted} MissingRequiredTestInputError

```python
class MissingRequiredTestInputError(BaseError):
```

When a required test context variable is missing.

**Inherited members**

- **From BaseError**: [class BaseError[()]{.muted}](#class-baseerror), [__init__[()]{.muted}](#__init__), [__str__[()]{.muted}](#__str__), [description[()]{.muted}](#description)
- **From builtins.BaseException**: with_traceback, add_note
