---
title: "[validmind](/reference/validmind.html).Delimitation"
sidebar: validmind-reference
toc-depth: 4
toc-expand: 4
# module.qmd.jinja2
---

## call_model<span class='muted'>()</span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="kw">def</span><span class="name">call_model</span>(<span class="params"><span class="n">system_prompt</span><span class="p">:</span><span class="nb"><!-- types.jinja2 - format_type -->str</span><span class="muted">,</span></span><span class="params"><span class="n">user_prompt</span><span class="p">:</span><span class="nb"><!-- types.jinja2 - format_type -->str</span><span class="muted">,</span></span><span class="params"><span class="n">temperature</span><span class="p">:</span><span class="nb"><!-- types.jinja2 - format_type -->float</span><span class="o"> = </span><span class="kc">0.0</span><span class="muted">,</span></span><span class="params"><span class="n">seed</span><span class="p">:</span><span class="nb"><!-- types.jinja2 - format_type -->int</span><span class="o"> = </span><span class="kc">42</span></span>)

:::

<!-- docstring.jinja2 -->

Call LLM with the given prompts and return the response

## get_explanation<span class='muted'>()</span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="kw">def</span><span class="name">get_explanation</span>(<span class="params"><span class="n">response</span><span class="p">:</span><span class="nb"><!-- types.jinja2 - format_type -->str</span></span>)

:::

<!-- docstring.jinja2 -->

Get just the explanation from the response string

TODO: use json response mode instead of this

```
e.g. "Score: 8
```

Explanation: <some-explanation>" -> "<some-explanation>"

## get_score<span class='muted'>()</span>

<!-- signatures.jinja2 -->

::: {.signature}

<span class="kw">def</span><span class="name">get_score</span>(<span class="params"><span class="n">response</span><span class="p">:</span><span class="nb"><!-- types.jinja2 - format_type -->str</span></span>)

:::

<!-- docstring.jinja2 -->

Get just the score from the response string

TODO: use json response mode instead of this

```
e.g. "Score: 8
```

Explanation: <some-explanation>" -> 8

<!-- function.qmd.jinja2 -->

## Delimitation[()]{.muted}

<!-- signatures.jinja2 -->

::: {.signature}

<span class="kw">def</span><span class="name">Delimitation</span>(<span class="params"><span class="n">model</span><span class="muted">,</span></span><span class="params"><span class="n">min_threshold</span><span class="o"> = </span><span class="kc">7</span></span>)

:::

<!-- docstring.jinja2 -->

Evaluates the proper use of delimiters in prompts provided to Large Language Models.

### Purpose

The Delimitation Test aims to assess whether prompts provided to the Language Learning Model (LLM) correctly use delimiters to mark different sections of the input. Well-delimited prompts help simplify the interpretation process for the LLM, ensuring that the responses are precise and accurate.

### Test Mechanism

The test employs an LLM to examine prompts for appropriate use of delimiters such as triple quotation marks, XML tags, and section titles. Each prompt is assigned a score from 1 to 10 based on its delimitation integrity. Prompts with scores equal to or above the preset threshold (which is 7 by default, although it can be adjusted as necessary) pass the test.

### Signs of High Risk

- Prompts missing, improperly placed, or incorrectly used delimiters, leading to misinterpretation by the LLM.
- High-risk scenarios with complex prompts involving multiple tasks or diverse data where correct delimitation is crucial.
- Scores below the threshold, indicating a high risk.

### Strengths

- Ensures clarity in demarcating different components of given prompts.
- Reduces ambiguity in understanding prompts, especially for complex tasks.
- Provides a quantified insight into the appropriateness of delimiter usage, aiding continuous improvement.

### Limitations

- Only checks for the presence and placement of delimiters, not whether the correct delimiter type is used for the specific data or task.
- May not fully reveal the impacts of poor delimitation on the LLM's final performance.
- The preset score threshold may not be refined enough for complex tasks and prompts, requiring regular manual adjustment.

<!-- class.qmd.jinja2 -->

## [class]{.muted} MissingRequiredTestInputError

<!-- signatures.jinja2 -->

::: {.signature}

<span class="kw">class</span><span class="name">MissingRequiredTestInputError</span>()

:::

<!-- docstring.jinja2 -->

When a required test context variable is missing.

**Inherited members**

- **From BaseError**: [class BaseError[()]{.muted}](#class-baseerror), [__init__[()]{.muted}](#__init__), [__str__[()]{.muted}](#__str__), [description[()]{.muted}](#description)
- **From builtins.BaseException**: with_traceback, add_note
