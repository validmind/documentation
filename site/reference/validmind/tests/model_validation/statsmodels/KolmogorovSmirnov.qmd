---
title: "[validmind](/reference/validmind.html).KolmogorovSmirnov"
sidebar: validmind-reference
toc-depth: 4
toc-expand: 4
# module.qmd.jinja2
---

<!-- function.qmd.jinja2 -->

## KolmogorovSmirnov[()]{.muted}

<!-- signatures.jinja2 -->

::: {.signature}

<span class="kw">def</span><span class="name">KolmogorovSmirnov</span>(<span class="params"><span class="n">model</span><span class="p">:</span><!-- types.jinja2 - format_type --><span class="n">VMModel</span><span class="muted">,</span></span><span class="params"><span class="n">dataset</span><span class="p">:</span><!-- types.jinja2 - format_type --><span class="n">VMDataset</span><span class="muted">,</span></span><span class="params"><span class="n">dist</span><span class="p">:</span><!-- types.jinja2 - format_type --><span class="nb">str</span><span class="o">=</span><span class="s1">'norm'</span></span>):

:::

<!-- docstring.jinja2 -->

Assesses whether each feature in the dataset aligns with a normal distribution using the Kolmogorov-Smirnov test.

### Purpose

The Kolmogorov-Smirnov (KS) test evaluates the distribution of features in a dataset to determine their alignment with a normal distribution. This is important because many statistical methods and machine learning models assume normality in the data distribution.

### Test Mechanism

This test calculates the KS statistic and corresponding p-value for each feature in the dataset. It does so by comparing the cumulative distribution function of the feature with an ideal normal distribution. The KS statistic and p-value for each feature are then stored in a dictionary. The p-value threshold to reject the normal distribution hypothesis is not preset, providing flexibility for different applications.

### Signs of High Risk

- Elevated KS statistic for a feature combined with a low p-value, indicating a significant divergence from a normal distribution.
- Features with notable deviations that could create problems if the model assumes normality in data distribution.

### Strengths

- The KS test is sensitive to differences in the location and shape of empirical cumulative distribution functions.
- It is non-parametric and adaptable to various datasets, as it does not assume any specific data distribution.
- Provides detailed insights into the distribution of individual features.

### Limitations

- The test's sensitivity to disparities in the tails of data distribution might cause false alarms about non-normality.
- Less effective for multivariate distributions, as it is designed for univariate distributions.
- Does not identify specific types of non-normality, such as skewness or kurtosis, which could impact model fitting.

<!-- class.qmd.jinja2 -->

## [class]{.muted} InvalidTestParametersError

<!-- signatures.jinja2 -->

::: {.signature}

<span class="kw">class</span><span class="name">InvalidTestParametersError</span>:

:::

<!-- docstring.jinja2 -->

When an invalid parameters for the test.

**Inherited members**

- **From BaseError**: [class BaseError[()]{.muted}](#class-baseerror), [__init__[()]{.muted}](#__init__), [__str__[()]{.muted}](#__str__), [description[()]{.muted}](#description)
- **From builtins.BaseException**: with_traceback, add_note
