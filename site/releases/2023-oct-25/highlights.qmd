---
title: "October 25, 2023"
---

## Release highlights

This release introduces a new guide for modifying configurations and parameters within the ValidMind Developer Framework. It also brings new features to the Platform UI that enable you to remove blocks of content from model documentation and work with your settings more effectively.

### ValidMind Developer Framework (v1.22.0)

<!--- NR the next three notebooks have been commented out as they are not ready to be released.--->
<!---[SC-2284] Support regression models by @AnilSorathiya in [#259](https://github.com/validmind/developer-framework/pull/259)
#### Support for regression models

The ValidMind Developer Framework has added support for regression models. The updates include:

- A new demo notebook featuring a simple regression model
- Utilization of the standard California housing tabular dataset for the demo
- Addition of new metrics, `Errors` and `R-squared`, to support regression model evaluation
- Use of existing tabular dataset metrics for data validation

[Try it ...](../../notebooks/code_samples/regression/quickstart_regression_full_suite.ipynb)--->

<!---[SC-2411] Clustering models support by @AnilSorathiya in [#271](https://github.com/validmind/developer-framework/pull/271)
#### Support for clustering models

The ValidMind Developer Framework has added support for clustering models. The updates include:

- A new demo notebook for a simple clustering model 
- Utilization of a standard digits dataset for the demo
- Addition of new metrics to support clustering model evaluation

[Try it ...](../../notebooks/code_samples/clustering/quickstart_custer_demo.ipynb)--->

<!---John6797/sc 2416/embeddings models support by @johnwalz97 in [#272](https://github.com/validmind/developer-framework/pull/272)
#### Support for embeddings models

We added initial support for text embeddings models in the ValidMind Developer Framework which enables you to create, use and test a BERT embeddings model utilizing the Hugging Face library. The updates include:

- A new demo notebook
- A new folder in `model_validation` tests for embeddings, along with initial versions of tests for text embedding models
- Support for `feature_extraction` tasks in the Hugging Face model wrapper of the ValidMind Developer Framework
- Updated software dependencies

[Try it ...](../../notebooks/POC/bert-embeddings-model-ow-poc.ipynb)--->

<!---[SC-2236] Demo notebook for changing config/parameters by @AnilSorathiya in [#251](https://github.com/validmind/developer-framework/pull/251)--->
#### New notebook to demonstrate how to change configuration parameters

This notebook serves as a guide for modifying configuration and parameters within the ValidMind Developer Framework. It includes the following features:

- A preview template allowing users to select a sample test for configuration
- Instructions on how to pass custom configurations to `run_documentation_tests()`
- An option to run documentation tests focused on a specific section, avoiding the need to run the entire template

[Try it ...](../../notebooks/how_to/configure_parameters_demo.ipynb)

### ValidMind Platform UI (v1.8.0)

<!---Feature: Remove block from documentation by @gtagle in [#467](https://github.com/validmind/frontend/pull/467)--->
#### Remove blocks from documentation

You can now remove blocks of text or test-related content from model documentation in the editor of the Platform UI. This new feature gives you more control over your documentation and enables you to remove content that is no longer needed.

![](../../guide/remove-test-driven-block.gif){width=50%}

To remove text blocks and test-driven blocks from model documentation, you first select the block you want to remove and click {{< fa trash-can >}}, either in the text-block's toolbar or in the test-driven's block single-button toolbar:

[Try it ...](../../guide/edit-content.qmd#remove-content-blocks)

<!--- NR I don't think we have any user-facing docs for this feature ... 
  [Try it ...]()--->

<!---feat: Add settings landing page by @wkm97 in [#466](https://github.com/validmind/frontend/pull/466)--->
#### New Settings landing page

A new **Settings** landing page now organizes more of your settings for the ValidMind platform in one convenient place.

![New Settings page](../../guide/settings-page.png)

From this page you can manage:

- Your organization, including the name and the API and secret key you use to connect to the ValidMind platform.
- The documentation templates that standardize the documentation table of contents for your projects and configure the required validation tests for specific model use cases.
- Workflows that determine the statuses of your model documentation and how they transition through the workflow according to your requirements.

[Try it ...](https://app.dev.vm.validmind.ai/settings/)

## Enhancements

<!---[SC-2346] Rouge and Bert score metrics should show average scores by @juanmleng in [#263](https://github.com/validmind/developer-framework/pull/263)--->
- **Rouge and Bert Score metrics now show average scores**: Introduced `RougeMetricsAggregate` and `BertScoreAggregate` to offer a high-level overview of model performance across a large number of text rows. These metrics complement the detailed row-by-row analysis provided by `RougeMetrics` and `BertScore`.
<!--- NR this notebook is not currently included in our docs site:
Tested these metrics running `foundational_models_summarization_high_code.ipynb` --->

<!---[SC-2143] Metrics for safety toxicity and bias in text summarization by @juanmleng in [#258](https://github.com/validmind/developer-framework/pull/258)--->
- **Added metrics for safety toxicity and bias in text summarization**. We introduced several new metrics to evaluate safety and bias risks in text summarization:
  
  - `ToxicityScore`: Measures safety risk
  - `ToxicityHistogram`: Provides a distribution of safety risk scores
  - `RegardScore`: Evaluates bias risk
  - `RegardHistogram`: Shows distribution of bias risk scores
<!--- NR this notebook is not currently included in our docs site:
To test these metrics, see notebook `foundation_models_summarization_bias.ipynb`---> 

## Bug fixes

<!---[SC-2303] Shap metric issue resolved by @juanmleng in [#262](https://github.com/validmind/developer-framework/pull/262)--->
- **Shap metric issue resolved**. - We set `matplotlib` to version `3.7.x` in `pyproject.toml` to fix an incompatibility with the latest `matplotlib` version (`3.8.0`). This incompatibility was causing SHAP plot errors. We will keep track of `matplotlib` releases for future updates. Once fixed, we will consider updating the version. 

## Documentation updates

<!---Platform overview rewrite by @nrichers in [#138](https://github.com/validmind/documentation/pull/138)--->
- **Platform overview rewrite**. We expanded our platform overview to provide more background information about what ValidMind offers and how we enable you to comply with policies and regulations such as SR 11-7 and SS1/23. [Try it ...](../../guide/overview.qmd)

<!---QuickStart updates for the closed beta by @nrichers in [#141](https://github.com/validmind/documentation/pull/141)--->
- **QuickStart updates for the closed beta**. We updated the QuickStart section of our documentation to reflect recent UI and sign-up flow changes. [Try it ...](../../guide/quickstart.qmd)

<!---John6797/sc 2211/update test descriptions by @johnwalz97 in [#244](https://github.com/validmind/developer-framework/pull/244)
- **John6797/sc 2211/update test descriptions**. Add full markdown descriptions to all tests
--->

<!--- Rework how we include notebooks in our docs site [#139](https://github.com/validmind/documentation/pull/139)--->
- **Improved handling of Jupyter notebooks for code samples and testing how-to content**. We now programmatically embed these notebooks in our documentation site and generate a downloadable `notebooks.zip` file with all notebooks and supporting datasets. Try it:
  
  - [Code samples](../../guide/samples-jupyter-notebooks.qmd)
  - [Tests and test suites](../../guide/testing-overview.qmd)

## How to upgrade

To access the latest version of the [ValidMind Platform UI](http://app.prod.validmind.ai/), reload your browser tab.

To upgrade the ValidMind Developer Framework:

- [Using Jupyter Hub](../../guide/quickstart-try-developer-framework-with-jupyterhub.qmd): reload your browser tab and re-run the `!pip install --upgrade validmind` cell.

- [Using Docker](../../guide/quickstart-try-developer-framework-with-docker.qmd): pull the latest Docker image:
  
  ```jsx
  docker pull validmind/validmind-jupyter-demo:latest
  
  ```
  
- [In your own developer environment](../../guide/install-and-initialize-developer-framework.qmd): restart your notebook and re-run:
  
  ```python
  !pip install validmind
  ```