---
title: "Enhancements -- October 25, 2023"
keywords: "release notes, model risk management, ValidMind"
---

<!---[SC-2346] Rouge and Bert score metrics should show average scores by @juanmleng in [#263](https://github.com/validmind/developer-framework/pull/263)--->
- **Rouge and Bert Score metrics now show average scores**: Introduced `RougeMetricsAggregate` and `BertScoreAggregate` to offer a high-level overview of model performance across a large number of text rows. These metrics complement the detailed row-by-row analysis provided by `RougeMetrics` and `BertScore`.
<!--- NR this notebook is not currently included in our docs site:
Tested these metrics running `foundational_models_summarization_high_code.ipynb` --->

<!---[SC-2143] Metrics for safety toxicity and bias in text summarization by @juanmleng in [#258](https://github.com/validmind/developer-framework/pull/258)--->
- **Added metrics for safety toxicity and bias in text summarization**. We introduced several new metrics to evaluate safety and bias risks in text summarization:
  
  - `ToxicityScore`: Measures safety risk
  - `ToxicityHistogram`: Provides a distribution of safety risk scores
  - `RegardScore`: Evaluates bias risk
  - `RegardHistogram`: Shows distribution of bias risk scores
<!--- NR this notebook is not currently included in our docs site:
To test these metrics, see notebook `foundation_models_summarization_bias.ipynb`---> 