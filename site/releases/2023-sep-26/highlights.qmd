---
title: "September 26, 2023"
keywords: "release notes, ai risk, model risk management, ValidMind"
date: last-modified
---

## Release highlights

<!---User journey improvements by @nrichers in [#128](https://github.com/validmind/documentation/pull/128)--->
   - **User journey improvements**. We enhanced the architecture and content of our external docs site to make the user journey more efficient for model developers and model validators who are new to our products:
   
   * Reworked the "Get Started" section to include more conceptual information and an overview of the high-level workflows. [Try it ...](../../guide/get-started.qmd)
   
   * Revised the "Developer Framework" section to provide an end-to-end overview of the workflow that model developers should follow as they adopt the framework.  [Try it ...](../../guide/get-started-developer-framework.qmd)


### ValidMind Developer Framework (v1.19.0)

<!---John6797/sc 2062/sentiment analysis demo notebook should support by @johnwalz97 in [#224](https://github.com/validmind/validmind-python/pull/224)--->
- **Sentiment analysis demo LLM notebook support**. We added initial support for large language models (LLMs) in ValidMind via the new `FoundationModel` class. Users may create an instance of a `FoundationModel` and specify a `predict_fn` and a `prompt` and pass that into any test plan or test suite, for eample. The `predict_fn` must be defined by the user and implements the logic for calling the Foundation LLM (usually via API).
   
::: {.callout-tip}
## Interested in our LLM functionality?
Large language model (LLM) functionality will be part of our closed beta: 

- [Read the announcement](https://validmind.com/announcing-validminds-closed-beta-coming-soon/)
- [Join the waitlist](../../guide/join-closed-beta.qmd)
:::

<!---John6797/sc 2088/implement prompt validation metrics poc by @johnwalz97 in [#232](https://github.com/validmind/validmind-python/pull/232)--->
- **John6797/sc 2088/implement prompt validation metrics poc**. This PR adds the first round of native Prompt Validation tests to the Validmind Dev Framework. It also adds a demo notebook and very simple template to test out these metrics on the Sentiment Analysis LLM model we have built.

<!---
### ValidMind Platform UI (v1.6.0)
--->

## How to upgrade

To access the latest version of the [ValidMind Platform UI](http://app.prod.validmind.ai/), reload your browser tab.

To upgrade the ValidMind Developer Framework:

- [Using Jupyter Hub](../../guide/try-developer-framework-with-jupyterhub.qmd): reload your browser tab and re-run the `!pip install --upgrade validmind` cell.

- [Using Docker](../../guide/try-developer-framework-with-docker.qmd): pull the latest Docker image:
    
    ```jsx
    docker pull validmind/validmind-jupyter-demo:latest
    
    ```
    
- [In your own developer environment](../../guide/install-and-initialize-developer-framework.qmd): restart your notebook and re-run:
    
    ```python
    !pip install validmind
    ```