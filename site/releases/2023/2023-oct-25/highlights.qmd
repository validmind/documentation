---
title: "October 25, 2023"
date: 2023-10-25
aliases: 
  - /releases/2023-oct-25/highlights.html
---

We've introduced new features to the {{< var vm.platform >}} that enable you to remove blocks of content from documentation and work with your settings more effectively.

::: {.highlights}

## {{< fa bullhorn >}} Release highlights

<!-- ### {{< var validmind.developer >}} (v1.22.0) -->

<!--- NR the next three notebooks have been commented out as they are not ready to be released.--->
<!---[SC-2284] Support regression models by @AnilSorathiya in [#259](https://github.com/validmind/validmind-library/pull/259)
#### Support for regression models

The {{< var validmind.developer >}} has added support for regression models. The updates include:

- A new demo notebook featuring a simple regression model
- Utilization of the standard California housing tabular dataset for the demo
- Addition of new tests, `Errors` and `R-squared`, to support regression model evaluation
- Use of existing tabular dataset tests for data validation

[Try it ...](/notebooks/code_samples/regression/quickstart_regression_full_suite.ipynb)--->

<!---[SC-2411] Clustering models support by @AnilSorathiya in [#271](https://github.com/validmind/validmind-library/pull/271)
#### Support for clustering models

The {{< var validmind.developer >}} has added support for clustering models. The updates include:

- A new demo notebook for a simple clustering model 
- Utilization of a standard digits dataset for the demo
- Addition of new tests to support clustering model evaluation

[Try it ...](/notebooks/code_samples/clustering/quickstart_custer_demo.ipynb)--->

<!---John6797/sc 2416/embeddings models support by @johnwalz97 in [#272](https://github.com/validmind/validmind-library/pull/272)
#### Support for embeddings models

We added initial support for text embeddings models in the {{< var validmind.developer >}} which enables you to create, use and test a BERT embeddings model utilizing the Hugging Face library. The updates include:

- A new demo notebook
- A new folder in `model_validation` tests for embeddings, along with initial versions of tests for text embedding models
- Support for `feature_extraction` tasks in the Hugging Face model wrapper of the {{< var validmind.developer >}}
- Updated software dependencies

[Try it ...](/notebooks/POC/bert-embeddings-model-ow-poc.ipynb)--->

<!---[SC-2236] Demo notebook for changing config/parameters by @AnilSorathiya in [#251](https://github.com/validmind/validmind-library/pull/251)--->
<!-- #### New notebook to demonstrate how to change configuration parameters

This notebook serves as a guide for modifying configuration and parameters within the {{< var validmind.developer >}}. It includes the following features:

- A preview template allowing users to select a sample test for configuration
- Instructions on how to pass custom configurations to `run_documentation_tests()`
- An option to run documentation tests focused on a specific section, avoiding the need to run the entire template

[Try it ...](/notebooks/how_to/configure_test_parameters.ipynb) -->

### {{< var validmind.platform >}} (v1.8.0)

<!---Feature: Remove block from documentation by @gtagle in [#467](https://github.com/validmind/frontend/pull/467)--->
#### Remove blocks from documentation

:::: {.flex .flex-wrap .justify-around}

::: {.w-40-ns}
You can now remove blocks of text or test-related content from model documentation in the editor of the {{< var vm.platform >}}. 

- This new feature gives you more control over your documentation and enables you to remove content that is no longer needed.
- To remove text blocks and test-driven blocks from model documentation, you first select the block you want to remove and click {{< fa trash-can >}}, either in the text-block's toolbar or in the test-driven's block single-button toolbar.

[Remove content blocks](/guide/model-documentation/work-with-content-blocks.qmd#remove-content-blocks){.button .button-green}

:::

::: {.w-50-ns}

![Removing a test-driven block](/guide/model-documentation/remove-test-driven-block.gif){fig-alt="A gif showcasing the process of removing a test-driven block" .screenshot}

:::

::::



<!--- NR I don't think we have any user-facing docs for this feature ... 
  [Try it ...]()--->

<!---feat: Add settings landing page by @wkm97 in [#466](https://github.com/validmind/frontend/pull/466)--->
#### New {{< fa gear >}} Settings landing page

A new **{{< fa gear >}} Settings** landing page now organizes more of your settings for the {{< var validmind.platform >}} in one convenient place.

:::: {.flex .flex-wrap .justify-around}

::: {.w-40-ns}
From this page you can manage:

- Your organization, including the name and the API and secret key you use to connect to the {{< var validmind.platform >}}.
- The documentation templates that standardize the documentation table of contents for your projects and configure the required validation tests for specific model use cases.
- Workflows that determine the statuses of your model and how it transitions through your model risk management process according to your requirements.

:::

::: {.w-50-ns}

![New {{< fa gear >}} Settings page](settings-page.png){fig-alt="A screenshot showing the new ValidMind Platform settings page" .screenshot}

:::

::::

:::


## Enhancements

### {{< var validmind.developer >}} (v1.22.0)

<!---[SC-2346] Rouge and Bert score tests should show average scores by @juanmleng in [#263](https://github.com/validmind/validmind-library/pull/263)--->
#### Rouge and Bert Score tests now show average scores

:::: {.flex .flex-wrap .justify-around}

::: {.w-80-ns}
- Introduced `RougeMetricsAggregate` and `BertScoreAggregate` to offer a high-level overview of model performance across a large number of text rows. 
- These tests complement the detailed row-by-row analysis provided by `RougeScore` and `BertScore`.
:::

::: {.w-20-ns .tc}

[RougeScore](/tests/model_validation/RougeScore.md){.button}

[BertScore](/tests/model_validation/BertScore.md){.button}

:::

::::

<!--- NR this notebook is not currently included in our docs site:
Tested these metrics running `foundational_models_summarization_high_code.ipynb` --->

<!---[SC-2143] Tests for safety toxicity and bias in text summarization by @juanmleng in [#258](https://github.com/validmind/validmind-library/pull/258)--->
#### Tests for safety toxicity and bias in text summarization

We introduced several new tests to evaluate safety and bias risks in text summarization:

:::: {.flex .flex-wrap .justify-around}

::: {.w-70-ns}
- `ToxicityScore`: Measures safety risk
- `ToxicityHistogram`: Provides a distribution of safety risk scores
- `RegardScore`: Evaluates bias risk
- `RegardHistogram`: Shows distribution of bias risk scores

:::

::: {.w-30-ns}

[ToxicityScore](/tests/model_validation/ToxicityScore.md){.button}

[RegardScore](/tests/model_validation/RegardScore.md){.button}

:::

::::

<!--- NR this notebook is not currently included in our docs site:
To test these metrics, see notebook `foundation_models_summarization_bias.ipynb`---> 

## Bug fixes

### {{< var validmind.developer >}} (v1.22.0)

<!---[SC-2303] Shap test issue resolved by @juanmleng in [#262](https://github.com/validmind/validmind-library/pull/262)--->
#### Shap test issue resolved
- We set `matplotlib` to version `3.7.x` in `pyproject.toml` to fix an incompatibility with the latest `matplotlib` version (`3.8.0`). 
- This incompatibility was causing SHAP plot errors. We will keep track of `matplotlib` releases for future updates. Once fixed, we will consider updating the version. 

## Documentation

### Code samples

<!---John6797/sc 2211/update test descriptions by @johnwalz97 in [#244](https://github.com/validmind/validmind-library/pull/244)
- **John6797/sc 2211/update test descriptions**. Add full markdown descriptions to all tests
--->

<!--- Rework how we include notebooks in our docs site [#139](https://github.com/validmind/documentation/pull/139)--->
#### Improved handling of Jupyter Notebooks

We now programmatically embed our Jupyter Notebooks in our documentation site and generate a downloadable `notebooks.zip` file with all notebooks and supporting datasets. 

:::: {.flex .flex-wrap .justify-around}

::: {.w-30-ns}
[Code samples](/developer/samples-jupyter-notebooks.qmd){.button}

:::

::: {.w-30-ns}
[Run tests and test suites](/developer/model-testing/testing-overview.qmd){.button}

:::

::::

### User guide updates

<!---Platform overview rewrite by @nrichers in [#138](https://github.com/validmind/documentation/pull/138)--->
#### Product overview rewrite
:::: {.flex .flex-wrap .justify-around}

::: {.w-70-ns}
We expanded our platform overview to provide more background information about what {{< var vm.product >}} offers and how we enable you to comply with policies and regulations such as SR 11-7 and SS1/23. 

:::

::: {.w-30-ns .tc}
[About {{< var vm.product >}}](/about/overview.qmd){.button}

:::

::::

<!---QuickStart updates for the closed beta by @nrichers in [#141](https://github.com/validmind/documentation/pull/141)--->
#### QuickStart updates for the closed beta
:::: {.flex .flex-wrap .justify-around}

::: {.w-80-ns}
We updated the QuickStart section of our documentation to reflect recent {{< var validmind.platform >}} and sign-up flow changes. 
:::

::: {.w-20-ns .tc}
[Quickstart â€” Model Development](/get-started/developer/quickstart-developer.qmd){.button}

:::

::::

{{< include /releases/_how-to-upgrade.qmd >}}