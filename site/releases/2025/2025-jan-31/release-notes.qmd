---
title: "January 31, 2025"
---

## Release highlights — `25.01`

<!---
PR #1117: User Dashboards
URL: https://github.com/validmind/frontend/pull/1117
Labels: enhancement
--->
### Custom reports and dashboards

Create personalized views to surface the insights you want right when you log in to the ValidMind platform — the ability to customize reports in ValidMind's MRM platform provides essential flexibility to meet diverse stakeholder needs. With customizable reporting, your teams can tailor the format, metrics, and level of detail to each audience while maintaining consistency in the underlying data. 

![Custom dashboards allow you to create personalized views](custom-dashboards.png)

You can add as many dashboards as you need to suit different use cases, whether it's managing model documentation and testing as a developer, tracking findings in validation reports as a developer, or monitoring analytics. 

This ability means technical teams can drill into detailed model performance metrics, business leaders can get strategic portfolio views, and risk and compliance teams can receive standardized documentation that aligns with their specific requirements. 

To populate your dashboards, you add widgets to display the information that matters to you. Choose from widgets for:

- Model inventory views
- Saved model findings
- Detailed analytics visualizations
- A list of recent activity

:::: {.flex .flex-wrap .justify-around}

::: {.w-70-ns}
For a detailed technical overview of this feature, check out our blog post. The post explores the architecture decisions, implementation details, and best practices we followed while building this feature.
:::

::: {.w-30-ns .tc}
[Tech deep dive: Custom reports and dashboards](https://validmind.com/blog/tech-deep-dive-custom-reports-dashboards/){.button}
:::

::::

:::: {.flex .flex-wrap .justify-around}

::: {.w-70-ns}
Or read our docs to get started.
:::

::: {.w-30-ns .tc}
[Customize your dashboard](https://docs.validmind.ai/guide/configuration/customize-your-dashboard.html){.button}
:::

::::

<!---
PR #1161: Added basic support to prevent concurrent changes for analytics/dashb…
URL: https://github.com/validmind/frontend/pull/1161
Labels: enhancement
--->
### Analytics dashboards now support edit and view modes

We've made it easier to collaborate on dashboards by adding dedicated view and edit modes. 
When you want to make changes, simply click the **Edit** button to enter edit mode. Once you're done, click 'Done Editing' to save your changes and return to view mode.

![Screenshot showing edit mode](401290459-838f933f-f15a-4503-bbe7-a6514f736773.png)

![Screenshot showing view mode](401290475-80a68ccb-2d56-417b-82d2-2d6a85766f30.png)

To prevent any confusion when multiple people are working on the same dashboard, we've added some helpful safeguards:

- If someone else makes changes while you're editing, you'll get a friendly notification to reload the page
- The system automatically detects if you're looking at an older version of the dashboard and prompts you to get the latest updates

These improvements help ensure that everyone stays in sync while customizing their dashboards.

<!---
PR #263: Add Initial Support for Post-Processing Functions
URL: https://github.com/validmind/validmind-library/pull/263
Labels: enhancement, highlight
--->
<!-- ### Add initial support for post-processing functions

Adding support for post-processing functions -->

<!---
PR #615: Pulling in latest changes from validmind-library PR#282
URL: https://github.com/validmind/documentation/pull/615
Labels: documentation, highlight
--->
### Jupyter Notebook template

Want to create some code samples for ValidMind? We've now made it easier for contributors to submit custom code samples.

Our **[End-to-end notebook template generation](e2e-notebook.ipynb) notebook** will generate a new file with all the bits and pieces of a standard ValidMind notebook to get you started.

The same functionality is also accessible in our library's [Makefile](../../Makefile) as a command:

```bash
make notebook
```

#### Mini-templates

The template generation notebook draws from a number of mini-templates, should you need to revise them or grab the information from them manually:

- [`about-validmind.ipynb`](about-validmind.ipynb): Conceptual overview of ValidMind & prerequisites.
- [`install-initialize-validmind.ipynb`](install-initialize-validmind.ipynb): ValidMind Library installation & initialization instructions.
- [`next-steps.ipynb`](next-steps.ipynb): Directions to review the generated documentation within the ValidMind Platform & additional learning resources.
- [`upgrade-validmind.ipynb`](upgrade-validmind.ipynb): Instructions for comparing & upgrading versions of the ValidMind Library.

[README.md](https://github.com/validmind/validmind-library/edit/main/notebooks/templates/README.md){.button}

### New notebook code samples

<!---
PR #256: [SC-7588] Explore dynamic llm context injection in test descriptions
URL: https://github.com/validmind/validmind-library/pull/256
Labels: enhancement
--->
#### Add context to LLM-based descriptions

Added the capability to include contextual information in LLM-based descriptions. This enhancement improves test result descriptions by incorporating additional context that can be specified through environment variables.

A new Jupyter notebook demonstrates how to add context to LLM-based descriptions. The notebook provides examples of:

- Setting up the environment
- Initializing datasets and models
- Running tests with and without context

To support this feature, a new `_get_llm_global_context()` function in the `test_descriptions.py` script retrieves context from environment variables. This function validates that context is enabled and not empty before use. Additionally, the `generate_description` function has been updated to include this contextual information in the LLM description generation process.

[Adding Context to LLM-based Descriptions](https://github.com/validmind/validmind-library/blob/main/notebooks/code_sharing/llm/llm_descriptions_context.ipynb){.button}

<!---
PR #280: [SC-7864] Create credit risk scorecard notebook using XGBoost
URL: https://github.com/validmind/validmind-library/pull/280
Labels: enhancement
--->
#### Credit risk scorecards using XGBoost

We've introduced enhancements and bug fixes to the {{< var validmind.developer >}}, focusing on credit risk scorecard modeling. Key changes include:

- **New Jupyter notebooks**: Two notebooks demonstrate the application scorecard model using the {{< var vm.developer >}}. They provide a step-by-step guide for loading a demo dataset, preprocessing data, training models, and documenting the model.

- **New tests in `validmind/tests`**:

  - [`MutualInformation`](/tests/data_validation/MutualInformation.md): Evaluates feature relevance by calculating mutual information scores between features and the target variable.  
  - [`ScoreBandDefaultRates`](/tests/data_validation/ScoreBandDefaultRates.md): Analyzes default rates and population distribution across credit score bands.  
  - [`CalibrationCurve`](/tests/data_validation/CalibrationCurve.md): Assesses calibration by comparing predicted probabilities against observed frequencies.  
  - [`ClassifierThresholdOptimization`](/tests/data_validation/ClassifierThresholdOptimization.md): Visualizes threshold optimization methods for binary classification models.  
  - [`ModelParameters`](/tests/data_validation/ModelParameters.md): Extracts and displays model parameters for transparency and reproducibility.  
  - [`ScoreProbabilityAlignment`](/tests/data_validation/ScoreProbabilityAlignment.md): Evaluates alignment between credit scores and predicted probabilities.  

Modifications have also been made to existing tests to improve functionality and accuracy. The `TooManyZeroValues` test now includes a row count and applies a percentage threshold for zero values.

The `split` function in `lending_club.py` has been enhanced to support an optional validation set, allowing for more flexible dataset splitting.

A new utility function, `get_demo_test_config`, has been added to generate a default test configuration for demo purposes.

:::: {.flex .flex-wrap .justify-around}

::: {.w-50-ns .tc}
[Document an application scorecard model](https://jupyterhub.validmind.ai/hub/user-redirect/lab/tree/code_samples/credit_risk/application_scorecard_with_ml.ipynb){.button}
:::

::: {.w-50-ns .tc}
[Document an application scorecard model](https://jupyterhub.validmind.ai/hub/user-redirect/lab/tree/code_samples/credit_risk/application_scorecard_full_suite.ipynb){.button}
:::

::::

<!---
PR #290: [SC-8008] Ongoing monitoring notebook for application scorecard model
URL: https://github.com/validmind/validmind-library/pull/290
Labels: enhancement
--->
#### Ongoing monitoring notebook for application scorecard model

We've introduced several enhancements and bug fixes to the {{ <var validmind.developer > }}, particularly focusing on credit risk scorecard models and ongoing monitoring capabilities. Key changes include:

**New notebooks**: Two new notebooks for application scorecard models and ongoing monitoring provide step-by-step guides for using the {{< var validmind.developer >}} with credit risk datasets:

   - `application_scorecard_ongoing_monitoring.ipynb`: Includes new metrics for data and model drift, and populates the ongoing monitoring document for the scorecard model.
   - `application_scorecard_executive.ipynb`: documents the scorecard model with just one function, namely `lending_club.document_model()`.

**Custom tests**: Introduced custom tests for scorecard models, allowing users to define and run their own tests using the ValidMind Library:

   - `ScoreBandDiscriminationMetrics.py`: Evaluates discrimination metrics across different score bands.  

**Ongoing monitoring enhancements**: Added new tests for ongoing monitoring of models, including:  

   - [`CalibrationCurveDrift`](/tests/data_validation/CalibrationCurveDrift.md): Evaluates changes in probability calibration.  
   - [`ClassDiscriminationDrift`](/tests/data_validation/ClassDiscriminationDrift.md): Compares classification discrimination metrics.  
   - [`ClassImbalanceDrift`](/tests/data_validation/ClassImbalanceDrift.md): Evaluates drift in class distribution.  
   - [`ClassificationAccuracyDrift`](/tests/data_validation/ClassificationAccuracyDrift.md): Compares classification accuracy metrics.  
   - [`ConfusionMatrixDrift`](/tests/data_validation/ConfusionMatrixDrift.md): Compares confusion matrix metrics.  
   - [`CumulativePredictionProbabilitiesDrift`](/tests/data_validation/CumulativePredictionProbabilitiesDrift.md): Compares cumulative prediction probability distributions.  
   - [`FeatureDrift`](/tests/data_validation/FeatureDrift.md): Evaluates changes in feature distribution.  
   - [`PredictionAcrossEachFeature`](/tests/data_validation/PredictionAcrossEachFeature.md): Assesses prediction distributions across features.  
   - [`PredictionCorrelation`](/tests/data_validation/PredictionCorrelation.md): Assesses correlation changes between predictions and features.  
   - [`PredictionProbabilitiesHistogramDrift`](/tests/data_validation/PredictionProbabilitiesHistogramDrift.md): Compares prediction probability distributions.  
   - [`PredictionQuantilesAcrossFeatures`](/tests/data_validation/PredictionQuantilesAcrossFeatures.md): Assesses prediction distributions across features using quantiles.  
   - [`ROCCurveDrift`](/tests/data_validation/ROCCurveDrift.md): Compares ROC curves.  
   - [`ScoreBandsDrift`](/tests/data_validation/ScoreBandsDrift.md): Analyzes drift in score bands.  
   - [`ScorecardHistogramDrift`](/tests/data_validation/ScorecardHistogramDrift.md): Compares score distributions.  
   - [`TargetPredictionDistributionPlot`](/tests/data_validation/TargetPredictionDistributionPlot.md): Assesses differences in prediction distributions.  

**Dataset and model enhancements**: Improved dataset loading, preprocessing, and feature engineering functions with verbosity control for cleaner output.  

:::: {.flex .flex-wrap .justify-around}

::: {.w-50-ns .tc}
[Ongoing monitoring for application scorecard](https://jupyterhub.validmind.ai/hub/user-redirect/lab/tree/code_samples/ongoing_monitoring/application_scorecard_ongoing_monitoring.ipynb){.button}
:::

::: {.w-50-ns .tc}
[Document an application scorecard model](https://jupyterhub.validmind.ai/hub/user-redirect/lab/tree/code_samples/credit_risk/application_scorecard_executive.ipynb){.button}
:::

::::

## Enhancements

<!---
PR #1179: [SC-8104] Support configurable default models in Admin UI
URL: https://github.com/validmind/frontend/pull/1179
Labels: enhancement
--->
### Support configurable default models in the admin UI

:::: {.flex .flex-wrap .justify-around}

::: {.w-60-ns}
![Screenshot showing admin UI configuration](404439892-5d2f2ce8-aa75-40cb-8685-878eb2d013b9.png){width="827" fig-alt="Screenshot 2025-01-17 at 12:22:55 PM" .screenshot}
:::

::: {.w-40-ns}
Admin users can now create organizations without models, allowing more flexibility in setup. The Populate Demo Models switch is now disabled when no models are selected, preventing unintended configurations.
:::

::::

<!---
PR #1173: [SC-7551] add allow_duplicates flag to CreateInventoryModel
URL: https://github.com/validmind/frontend/pull/1173
Labels: enhancement
--->
### Add `allow_duplicates` flag to `CreateInventoryModel` function

<!-- NR should this be commented out? The screenshot shows the inspect pane and this seems quite low level. -->

We've introduced a new parameter `allow_duplicates` to the `CreateInventoryModel` function in the `API.ts` file. The `allow_duplicates` parameter is a boolean that determines whether duplicate inventory models are allowed when creating a new inventory model.

![Screenshot 2025-01-13 at 10:26:25 AM](402655672-79e6bae5-efe0-4be0-a772-3047f483f031.png){width="1475" .screenshot}

<!---
PR #1132: Added Model Inventory Page layout customization
URL: https://github.com/validmind/frontend/pull/1132
Labels: enhancement
--->
### Added model inventory page layout customization

<!-- NR TO DO this needs info ... Might be a highlight -->

Added the ability to customize the layout of the model inventory

<!---
PR #1172: [SC-8043] Show optional prompt for Risk Assessment
URL: https://github.com/validmind/frontend/pull/1172
Labels: enhancement
--->
### Show optional prompt for risk assessment

Risk assessment generation has been enhanced to allow you to provide an optional prompt before starting text generation. This feature lets you guide the output, ensuring that the generated text aligns more closely with your specific requirements.

![Screenshot 2025-01-13 at 9:33:31 AM](402640824-492758fc-2669-46c6-9c81-198e990b9efe.png){width="809" .screenshot}

<!---
PR #1176: [SC-8072] Support threshold lines in unit metric plots
URL: https://github.com/validmind/frontend/pull/1176
Labels: enhancement
--->
<!---
PR #293: [SC-8072] Support threshold lines in unit metric plots
URL: https://github.com/validmind/validmind-library/pull/293
Labels: enhancement
--->
### Support threshold lines in unit metric plots

When logging metrics using `log_metric()`, you can now include a `thresholds` dictionary. For example, use `thresholds={"target": 0.8, "minimum": 0.6}` to define multiple reference levels.

![Threshold lines in unit metric plots](403022728-81371dda-3e2c-4b53-abbe-a0caa7c0501a.png){width="949" fig-alt="A screenshot showing threshold lines in unit metric plots" .screenshot}

These thresholds automatically appear as horizontal reference lines when you add a *Metric Over Time* block to the documentation. The visualization uses a distinct color palette to differentiate between thresholds. It displays only the most recent threshold configuration and includes threshold information in both the chart legend and data table.

This enhancement provides immediate visual context for metric values. It helps track metric performance against multiple defined thresholds over time.

Usage example:

```
log_metric(
    key="AUC Score",
    value=auc,
    recorded_at=datetime(2024, 1, 1),
    thresholds={
        "high_risk": 0.6,
        "medium_risk": 0.7,
        "low_risk": 0.8,
    }
)
```

<!---
PR #1125: [SC-7628] updates to admin landing page
URL: https://github.com/validmind/frontend/pull/1125
Labels: enhancement
--->
<!-- ### Updates to admin landing page

Only in case we are starting to document the admin app

The landing page/admin checks whether you are authenticated and authorized. You can find the rules in the ticket description above. -->

<!---
PR #1124: ReportCounters are now clickable
URL: https://github.com/validmind/frontend/pull/1124
Labels: enhancement
--->
<!-- NR Not enough info here, PR description is not clear, either -->
<!-- ### Report counters are now clickable


Counter visualizations are now clickable -->

<!---
PR #1096: Simplifies workflow nodes and introduces zoom-based detail
URL: https://github.com/validmind/frontend/pull/1096
Labels: enhancement
--->
### Simplifies workflow nodes

Workflows are now easier to read when zoomed out, helped by a larger modal window and simplified nodes:

![Workflow visualization showing simplified nodes](388211099-678f2ad6-8d3e-4dd1-a846-c03aeee77e3f.png){width="1552" fig-alt="A screenshot showing the simplified workflow visualization with nodes" .screenshot}  

Zooming in reveals more details:

![Workflow visualization in zoomed-out view](388211631-995714ee-be70-4ea5-b0f6-46e1ec3294ed.png){width="1552" fig-alt="A screenshot showing the simplified workflow visualization" .screenshot}  

Hovering over a node highlights all `in` and `out` connections, making relationships clearer:

![Workflow connection highlighting on hover](388212015-b560f745-c9e9-45d9-91e8-1bae6887130b.png){width="1552" fig-alt="A screenshot showing the workflow connection highlighting" .screenshot}  

<!---
PR #1128: [SC-7684] admin manage users
URL: https://github.com/validmind/frontend/pull/1128
Labels: enhancement
--->

<!-- ### Admin manage users

Adding users management to admin app - list users, create user

---

Adding admin tools with option for `RBAC` refresh -->

<!---
PR #274: [SC-7759] Exposing static descriptions in test results
URL: https://github.com/validmind/validmind-library/pull/274
Labels: enhancement
--->
### ## Expose static descriptions in test results

The `TestResult` class now has a `doc` property to separate static test documentation from LLM-generated descriptions.  

- `result.doc` contains the test’s original docstring.  
- `result.description` provides the dynamically generated description.  

This makes it easier to distinguish between the test’s purpose and its AI-generated summary.  

<!---
PR #285: John6797/sc 7792/add raw data to validmind library tests
URL: https://github.com/validmind/validmind-library/pull/285
Labels: enhancement
--->
### Add raw data to `validmind` library tests

We added raw data storage across all ValidMind tests. Every test now returns a `RawData` object, allowing post-processing functions to recreate any test output. This enhances flexibility and customizability.

<!---
PR #295: feat: add print_env function
URL: https://github.com/validmind/validmind-library/pull/295
Labels: enhancement
--->
### New `print_env` function

We've added a new diagnostic utility function `validmind.print_env()` that displays comprehensive information about your running environment. This function is particularly useful when:

- Troubleshooting issues in your code
- Seeking support from the ValidMind team
- Verifying your environment configuration

Simply call the function to get a detailed overview of your environment:

```python
import validmind

validmind.print_env()
```

This function outputs key details like Python version, installed package versions, and relevant environment variables, making it easier to diagnose issues and share your setup with others.

<!-- NR TO DO I see this function in the latest API reference docs that I've been working on but it seems to be missing from this release. -->

<!-- ## Bug fixes -->

<!---
PR #1153: fix admin auth check
URL: https://github.com/validmind/frontend/pull/1153
Labels: bug
--->
<!-- ### Fix admin auth check

N/A -->

<!---
PR #1155: admin route not working on dev, fix env check
URL: https://github.com/validmind/frontend/pull/1155
Labels: bug
--->
<!-- ### Admin route not working  

Check the development environment to fix the issue with the admin route

n/a -->

<!---
PR #1143: Fixes ckeditor console errors
URL: https://github.com/validmind/frontend/pull/1143
Labels: 
--->
<!-- ### Fixes ckeditor console errors -->

<!--- Replace this comment with your description --->

{{< include /releases/_how-to-upgrade.qmd >}}
