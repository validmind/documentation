---
# Copyright © 2023-2026 ValidMind Inc. All rights reserved.
# Refer to the LICENSE file in the root of this repository for details.
# SPDX-License-Identifier: AGPL-3.0 AND ValidMind Commercial
title: "Managing <br>AI Use Cases"
subtitle: "AI Governance — Module 2 of 4<br><br>_Click [{{< fa chevron-right >}}](#learning-objectives) to start_"
lightbox: true
format:
  revealjs:
    include-in-header:
      - text: |
          <script src="/training/assets/vmurl-settings.js"></script>
    controls: true
    controls-tutorial: true
    help: true
    controls-back-arrows: visible
    transition: slide
    theme: [../assets/slides.scss, ../assets/use-cases.scss]
    slide-number: true
    chalkboard: false
    preview-links: auto
    view-distance: 2
    logo: /favicon.svg
    footer: "{{< var validmind.training >}} | [Home {{< fa person-walking-dashed-line-arrow-right >}}](/training/training.qmd)"
    revealjs-plugins:
      - slideover
  html:
    output-file: _managing-ai-use-cases.html
    search: false
title-slide-attributes:
  data-background-image: "../assets/digitalspace-colours.svg"
  data-background-opacity: "0.8"
skip_preview: true
---

# Learning objectives {.center}

_"As an **AI governance professional**, I want to learn how to register AI use cases, conduct impact assessments, and manage lifecycle stages in {{< var vm.product >}}."_

::: {.tc}
<br>
This second module is part of a four-part series:
<br><br>
[AI Governance](/training/ai-governance/ai-governance-register.qmd){.button target="_blank"}
:::

## Module 2 — Contents {.center}

::: {.f2}
1. [Use case inventories](#use-case-inventories)
2. [Risk classification](#risk-classification)
3. [Impact assessments](#impact-assessments)
4. [Lifecycle stages](#lifecycle-stages)

:::

{{< include /training/assets/_revealjs-navigation.qmd >}}

# Use case inventories {background-image="../assets/digitalspace-colours.svg" .title-accent}

## What is a use case inventory? {.center}

A centralized registry of all AI systems and their purposes, use case inventories help you:

::: {.mt4}
[{{< fa check >}}]{.dark-pink} &ensp; Understand where AI is used

[{{< fa check >}}]{.dark-pink} &ensp; Track ownership and accountability

[{{< fa check >}}]{.dark-pink} &ensp; Assess aggregate risk exposure

[{{< fa check >}}]{.dark-pink} &ensp; Demonstrate governance to regulators
:::

## Inventory fields {.center}

:::: {.columns}

::: {.column width="50%" .pr3 .f2}
Configure custom inventory fields for AI governance:

::: {.f4 .mt5}
| Field type | Examples |
|------------|----------|
| Classification | Risk tier, impact level |
| Ownership | Use case owner, business sponsor |
| Purpose | Intended use, use boundaries |
| Status | Lifecycle stage, approval status |
:::

:::

::: {.column width="50%" .pl3 .tilt-left .f3}
![Custom field configuration](custom-fields.gif){fig-alt="A short video showing custom field configuration in ValidMind settings" .screenshot}
:::

::::

## The inventory in action {.center}

:::: {.columns}

::: {.column width="60%" .pr3 .tilt-right .mt5 .f3}
![The ValidMind inventory](intentory-in-action.gif){fig-alt="A short video showing the ValidMind inventory with AI use cases displaying tier, model owner, and model stage fields" .screenshot}
:::

::: {.column width="40%" .pl3 .nt2 .f2}
The **Inventory** displays AI use cases with:

- **Tier** — Risk classification level
- **Model owner** — Accountability assignment
- **Model stage** — Current lifecycle stage
:::

::::

# Risk classification {background-image="../assets/digitalspace-colours.svg" .title-accent}

## Why classify risk? {.center}

Risk classification enables **proportionate governance**. Higher-risk AI systems receive:

::: {.mt4}
[{{< fa check >}}]{.dark-pink} &ensp; More rigorous review

[{{< fa check >}}]{.dark-pink} &ensp; Additional documentation requirements

[{{< fa check >}}]{.dark-pink} &ensp; Enhanced monitoring

[{{< fa check >}}]{.dark-pink} &ensp; Stricter approval gates
:::

## Classification schemes {.center}

Align your classification to relevant regulations:

::: {.mt4 .f2}
| Framework | Classification levels |
|-----------|----------------------|
| EU AI Act | Prohibited, high-risk, limited-risk, minimal-risk |
| Internal | Critical, high, medium, low |
| Tiered | Tier 1, Tier 2, Tier 3, Tier 4 |
:::

## Configuring risk tiers {.center}

:::: {.columns}

::: {.column width="50%" .pr3 .f2}
In {{< var vm.product >}}, you can:

1. **Add custom fields** for risk classification
2. **Configure different workflows** per tier
3. **Apply documentation templates** by tier
4. **Generate reports** filtered by risk level
:::

::: {.column width="50%" .pl3 .mt4}
![Risk overview](analytics-risk-overview.png){fig-alt="A screenshot showing risk tier field configuration in ValidMind" .screenshot .tilt-left}
:::

::::

# Impact assessments {background-image="../assets/digitalspace-colours.svg" .title-accent}

## Purpose of impact assessments {.center}

Impact assessments evaluate potential risks and harms from AI deployment. They document:

::: {.mt4}
[{{< fa check >}}]{.dark-pink} &ensp; Who is affected by the AI system

[{{< fa check >}}]{.dark-pink} &ensp; What decisions the AI influences

[{{< fa check >}}]{.dark-pink} &ensp; Potential for harm or discrimination

[{{< fa check >}}]{.dark-pink} &ensp; Mitigating controls
:::

## Impact assessment process {.center}

1. **Identify stakeholders** — Who does this AI system affect?
2. **Assess impact** — What are the potential consequences?
3. **Evaluate risks** — What could go wrong?
4. **Document controls** — How are risks mitigated?
5. **Review and approve** — Governance sign-off

## Recording assessments {.center}

Use {{< var vm.product >}} to:

::: {.mt4}
[{{< fa check >}}]{.dark-pink} &ensp; Attach impact assessment documentation

[{{< fa check >}}]{.dark-pink} &ensp; Track assessment completion status

[{{< fa check >}}]{.dark-pink} &ensp; Route assessments through approval workflows

[{{< fa check >}}]{.dark-pink} &ensp; Maintain audit trail of governance decisions
:::

# Lifecycle stages {background-image="../assets/digitalspace-colours.svg" .title-accent}

## AI governance lifecycle {.center}

![](ai-governance-lifecycle.svg){fig-alt="Diagram showing the eight stages of the AI governance lifecycle: Intake (use case owner registers AI system), Assessment (Governance / Risk classify and assess), Documentation (Owner / Risk document model and use case), Validation (Validator test and validate model), Approval (Committee / Compliance sign-off) highlighted in magenta, Deployment (Owner / IT deploy to production), Monitoring (Risk / Ops ongoing oversight), Review (Governance / Audit periodic review), with a dashed arrow from Review back to re-assess or re-approve."}

::: {.f3 .nt4}
The AI governance lifecycle moves from intake and risk assessment through documentation and validation to a formal approval gate, then deployment, ongoing monitoring, and periodic review — with a feedback loop so systems can be re-assessed and re-approved when needed.
:::

## Managing stage transitions {.center}

{{< var vm.product >}} tracks AI systems through their lifecycle:

- **Status fields** indicate current stage
- **Workflows** control transitions
- **Documentation** captures stage requirements
- **Audit trail** records all changes

## Next steps {.center}

Continue to Module 3 to learn about configuring AI workflows.
<br>
<br>

::: {.tc}
[Module 3: Configuring AI workflows](configuring-ai-workflows.html){.button target="_blank"}
:::
