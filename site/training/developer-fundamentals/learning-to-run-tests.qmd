---
title: "Learning to <br>Run Tests"
subtitle: "Developer Fundamentals — Module 2 of 4<br><br>_Click [{{< fa chevron-right >}}](#learning-objectives) to start_"
lightbox: true
format:
  revealjs:
    controls: true
    controls-tutorial: true
    help: true
    controls-back-arrows: visible
    transition: slide
    theme: [default, ../assets/slides.scss]
    slide-number: true
    chalkboard: false
    preview-links: auto
    view-distance: 2
    logo: /validmind.png
    footer: "{{< var validmind.training >}} | [Home {{< fa person-walking-dashed-line-arrow-right >}}](/training/training.qmd)"
    revealjs-plugins:
      - slideover
  html:
  # Change this to the file name prepended by a _ to get around the global HTML output settings required by _metadata.yml
    output-file: _learning-to-run-tests.html
    search: false
title-slide-attributes:
  data-background-color: "#083E44"
  data-background-image: "../assets/home-hero.svg"
skip_preview: true
---

# Learning objectives {.center}

_"As a **developer** who has registered a model with {{< var vm.product >}}, I want to identify relevant tests to run from {{< var vm.product >}}'s test repository, run and log tests for my model, and insert the test results into my model's documentation."_

::: {.tc}
<br>
This second module is part of a four-part series:
<br><br>
[Developer Fundamentals](/training/developer-fundamentals/developer-fundamentals-register.qmd){.button target="_blank"}
:::


## Module 2 — Contents {.center}

::: {.f2}
1. [{{< var vm.product >}} for model development](#validmind-for-model-development)
2. [Explore ValidMind tests](#explore-validmind-tests)
3. [Run tests with the {{< var validmind.developer >}}](#run-validmind-tests)
4. [Log tests to the {{< var validmind.platform >}}](#log-validmind-tests)
5. [Test an existing model](#test-an-existing-model)

:::

First, let's make sure you can log in to {{< var vm.product >}}.

{{< include /training/assets/_revealjs-navigation.qmd >}}

## Before you begin {.center}

::: {.panel-tabset}

### Prerequisite course

To continue, you need to have been [onboarded](developer-fundamentals-register.qmd#register){target="_blank"} onto {{< var validmind.training >}} with the [**{{< fa code >}} Developer**]{.bubble} role and completed the first module of this course:

::: {.tc}
<!-- IMPORTANT: USE THE .HTML PATH AND NOT THE .QMD PATH FOR THE REVEALJS OUTPUT -->
[Using {{< var vm.product >}} for Model Development](using-validmind-for-model-development.html){.button target="_blank"}
:::

:::: {.tc .mt5 .f2 .embed}
Already logged in and refreshed this module? Click [{{< fa chevron-right >}}]() to continue.

:::

### Log in

1. Log in to check your access:

:::: {.flex .flex-wrap .justify-around}

::: {.w-50-ns .tc}

[Log in to JupyterHub]({{< var url.jupyterhub >}}/){.button target="_blank"}

:::

::: {.w-50-ns .tc}
[Log in to {{< var vm.product >}}](https://app.prod.validmind.ai){.button target="_blank"}
:::

::::


::: {.tc .f3}
Be sure to return to this page afterwards.
:::

2. After you successfully log in, refresh the page to connect this training module up to the {{< var validmind.platform >}}: 

::: {.tc}
<button class="button" onClick="window.location.reload();">Refresh Page</button>

:::


:::


<!-- USING THE VARIABLE IN THE HEADING MESSES UP THE PAGE ANCHOR -->

# ValidMind for model development {background-color="#083E44" background-image="/training/assets/home-hero.svg"}

## {.scrollable .center}

:::: {.columns}
::: {.column width="30%" .pr4 .f2}
Jupyter Notebook series

::: {.f3}
When you run these notebooks, they will generate a draft of model documentation and upload it to {{< var vm.product >}}, complete with supporting test results.

::: {.f5 .nt2 .pl2 .mb4}
<br>
You will need to have already completed **1 — Set up the {{< var validmind.developer >}}** during the first module to proceed.
:::

:::
:::

::: {.column width="70%" .bl .pl4 .f3}
### {{< var vm.product >}} for model development

Our series of four introductory notebooks for model developers include sample code and how-to information to get you started with {{< var vm.product >}}:

1 — [Set up the {{< var validmind.developer >}}](/notebooks/tutorials/model_development/1-set_up_validmind.ipynb){target="_blank"}<br>
2 — [Start the model development process](/notebooks/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}<br>
3 — [Integrate custom tests](/notebooks/tutorials/model_development/3-integrate_custom_tests.ipynb){target="_blank"}<br>
4 — [Finalize testing and documentation](/notebooks/tutorials/model_development/4-finalize_testing_documentation.ipynb){target="_blank"}<br>
<br>

::: {.f4 .pl3 .pr3 .embed}
In this second module, we'll run through **2 — Start the model development process** together. 
:::

:::
::::

Let's continue our journey with **2 — Start the model development process** on the next page. {{< fa hand-point-right >}}

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html" background-interactive="yes" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**2 — Start the model development process**

During this course, we'll run through these notebooks together, and at the end of your learning journey you'll have a fully documented sample model ready for review.

For now, **scroll through this notebook** to explore. When you are done, click [{{< fa chevron-right >}}]() to continue.

::::

<!-- USING THE VARIABLE IN THE HEADING MESSES UP THE PAGE ANCHOR -->

# Explore ValidMind tests {background-color="#083E44" background-image="/training/assets/home-hero.svg"}

## {background-iframe="/developer/model-testing/test-descriptions.html" background-interactive="true" data-preload="yes"}

::: {.slideover--l .three-quarters .auto-collapse-5}
::: {.tc}
**{{< var vm.product >}} test repository**

:::

{{< var vm.product >}} provides a wealth out-of-the-box of tests to help you ensure that your model is being built appropriately.

In this module, you'll become familiar with the individual tests available in {{< var vm.product >}}, as well as how to run them and change parameters as necessary.

For now, **scroll through these test descriptions** to explore. When you're done, click [{{< fa chevron-right >}}]() to continue.

:::

## Get your code snippet

:::: {.columns}

::: {.column width="80%"}

<!-- FOR COPYING THE CODE SNIPPET WE NEED TO USE THIS IFRAME WORKAROUND -->

<div style="zoom: 0.6; overflow: hidden;">
  <iframe 
    src="https://app.prod.validmind.ai/model-inventory" 
    width="100%" 
    height="750" 
    style="border: 1px solid #083E44; border-radius: 8px; border-right-width: 2px; border-bottom-width: 3px;"
    data-preload="yes" 
    sandbox="allow-same-origin allow-scripts allow-popups allow-forms"
    allow="clipboard-read; clipboard-write">
  </iframe>
</div>

:::

::: {.column width="20%" .f4}

::: {.f5}
{{< var vm.product >}} generates a unique *code snippet* for each registered model to connect with your developer environment:

1. From the **{{< fa cubes >}} Inventory**, select the name of your model to open up the model details page.
2. On the left sidebar that appears for your model, click **Getting Started**.
3. Locate the code snippet and click **Copy snippet to clipboard**.

:::

When you're done, click [{{< fa chevron-right >}}]() to continue.

:::

::::

:::: {.tc .f6 .embed}
**Can't load the {{< var validmind.platform >}}?**

Make sure you're logged in and have refreshed the page in a Chromium-based web browser.

:::

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html#initialize-the-validmind-library" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**Connect to your model**

With your code snippet copied to your clipboard:

1. Open **2 — Start the model development process**: [{{< fa square-arrow-up-right >}} JupyterHub]({{< var url.jupyterhub >}}/hub/user-redirect/lab/tree/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}
2. Run the following cells in the Setting up section:
    - **Initialize the {{< var validmind.developer >}}**
    - **Import sample dataset**.

When you're done, return to this page and click [{{< fa chevron-right >}}]() to continue.

::::

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html#identify-qualitative-tests" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**Identify qualitative tests**

Next, we'll use the [`list_tests()` function](/notebooks/EXECUTED/model_development/1-set_up_validmind.ipynb#explore-available-tests){target="_blank"} to pinpoint tests we want to run:

1. Continue with **2 — Start the model development process**: [{{< fa square-arrow-up-right >}} JupyterHub]({{< var url.jupyterhub >}}/hub/user-redirect/lab/tree/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}
2. Run all the cells under the Setting up section: **Identify qualitative tests**

When you're done, return to this page and click [{{< fa chevron-right >}}]() to continue.

::::

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html#initialize-the-validmind-datasets" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**Initialize {{< var vm.product >}} datasets**

Then, we'll use the [`init_dataset()` function](/validmind/validmind.qmd#init_dataset){target="_blank"} to connect the sample data with a {{< var vm.product >}} `Dataset` object in preparation for running tests:

1. Continue with **2 — Start the model development process**: [{{< fa square-arrow-up-right >}} JupyterHub]({{< var url.jupyterhub >}}/hub/user-redirect/lab/tree/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}
2. Run the following cell in the Setting up section: **Initialize the {{< var vm.product >}} datasets**

When you're done, return to this page and click [{{< fa chevron-right >}}]() to continue.

::::

<!-- USING THE VARIABLE IN THE HEADING MESSES UP THE PAGE ANCHOR -->

# Run ValidMind tests {background-color="#083E44" background-image="/training/assets/home-hero.svg"}

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html#run-tabular-data-tests" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**Run tabular data tests**

You run individual tests by calling the [`run_test()` function](/validmind/validmind/tests.qmd#run_test){target="_blank"} provided by the `validmind.tests` module:

1. Continue with **2 — Start the model development process**: [{{< fa square-arrow-up-right >}} JupyterHub]({{< var url.jupyterhub >}}/hub/user-redirect/lab/tree/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}
2. Run all the cells under the Running tests section: **Run tabular data tests**.

When you're done, return to this page and click [{{< fa chevron-right >}}]() to continue.

::::

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html#utilize-test-output" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**Utilize test output**

You can utilize the output from a ValidMind test for further use, for example, if you want to remove highly correlated features:

1. Continue with **2 — Start the model development process**: [{{< fa square-arrow-up-right >}} JupyterHub]({{< var url.jupyterhub >}}/hub/user-redirect/lab/tree/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}
2. Run all the cells under the Running tests section: **Utilize test output**.

When you're done, return to this page and click [{{< fa chevron-right >}}]() to continue.

::::

<!-- USING THE VARIABLE IN THE HEADING MESSES UP THE PAGE ANCHOR -->

# Log ValidMind tests {background-color="#083E44" background-image="/training/assets/home-hero.svg"}

## {.scrollable .center}

:::: {.columns}
::: {.column width="30%" .pr4 .f2}
Document test results

::: {.tc}
[Learn more ...](/validmind/validmind/vm_models.qmd#log){.button target="_blank"}

:::

<br>Try it **live** on the next page. {{< fa hand-point-right >}}
:::

::: {.column width="70%" .bl .pl4 .f3}
Every test result returned by the `run_test()` function has a `.log()` method that can be used to send the test results to the {{< var validmind.platform >}}:

- When using `run_documentation_tests()`, documentation sections will be automatically populated with the results of all tests registered in the documentation template.
- When logging individual test results to the platform, you'll need to manually add those results to the desired section of the model documentation.

:::
::::

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html#run-and-log-multiple-tests" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**Run & log multiple tests**

The [`run_documentation_tests()` function](/validmind/validmind.qmd#run_documentation_tests){target="_blank"} allows you to run multiple tests at once and automatically log the results to your documentation:

1. Continue with **2 — Start the model development process**: [{{< fa square-arrow-up-right >}} JupyterHub]({{< var url.jupyterhub >}}/hub/user-redirect/lab/tree/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}
2. Run the following cell in the Documenting results section: **Run and log multiple tests**.

When you're done, return to this page and click [{{< fa chevron-right >}}]() to continue.

::::

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html#run-and-log-an-individual-test" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**Run & log an individual test**

Next, we'll run an individual test and log the result to the {{< var validmind.platform >}}:

1. Continue with **2 — Start the model development process**: [{{< fa square-arrow-up-right >}} JupyterHub]({{< var url.jupyterhub >}}/hub/user-redirect/lab/tree/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}
2. Run the following cell in the Running tests section: **Run and log an individual test**.

When you're done, return to this page and click [{{< fa chevron-right >}}]() to continue.

::::

## {.scrollable .center}

:::: {.columns}
::: {.column width="30%" .pr4 .f2}
Work with test results

::: {.tc}
[Learn more ...](/notebooks/EXECUTED/model_development/2-start_development_process.ipynb#add-individual-test-results-to-model-documentation){.button target="_blank"}

:::

<br>Try it **live** on the next page. {{< fa hand-point-right >}}
:::

::: {.column width="70%" .bl .pl4 .f4}
### Add individual test results to model documentation

With the test results logged, let's head to the model we connected to at the beginning of this notebook and insert our test results into the documentation:

1. From the **{{< fa cubes >}} Inventory** in the {{< var validmind.platform >}}, go to the model you connected to earlier.

2. In the left sidebar that appears for your model, click **{{< fa book-open >}} Documentation**.

3. Locate the Data Preparation section and click on **2.3 Correlations and Interactions** to expand that section.

4. Hover under the Pearson Correlation Matrix content block until a horizontal dashed line with a **{{< fa plus >}}** button appears, indicating that you can insert a new block.

5. Click **{{< fa plus >}}** and then select **Test-Driven Block** under [from library]{.smallcaps}:

    - Click on **VM Library** under [test-driven]{.smallcaps} in the left sidebar.
    - In the search bar, type in `HighPearsonCorrelation`.
    - Select `HighPearsonCorrelation:balanced_raw_dataset` as the test.

6. Finally, click **Insert 1 Test Result to Document** to add the test result to the documentation.

    Confirm that the individual results for the high correlation test has been correctly inserted into section **2.3 Correlations and Interactions** of the documentation.

:::
::::


## {background-iframe="https://app.prod.validmind.ai/model-inventory/" background-interactive="true" data-preload="yes"}

:::: {.slideover--b .auto-collapse-10}
**Insert a test-driven block**

1. Select the model you connected to earlier.
2. In the left sidebar that appears for your model, click **{{< fa book-open >}} Documentation**.
3. Locate the Data Preparation section and click on **2.3 Correlations and Interactions** to expand that section.
4. Hover under the Pearson Correlation Matrix content block until a horizontal dashed line with a **{{< fa plus >}}** button appears, indicating that you can insert a new block.
5. Click **{{< fa plus >}}** and then select **Test-Driven Block** under [from library]{.smallcaps}:
    - Click on **VM Library** under [test-driven]{.smallcaps} in the left sidebar.
    - In the search bar, type in `HighPearsonCorrelation`.
    - Select `HighPearsonCorrelation:balanced_raw_dataset` as the test.
5. Finally, click **Insert 1 Test Result to Document** to add the test result to the documentation.

When you're done, click [{{< fa chevron-right >}}]() to continue.

::::


# Test an existing model {background-color="#083E44" background-image="/training/assets/home-hero.svg"}

## {.scrollable .center}

:::: {.columns}
::: {.column width="50%" .pr4 .f2}
Model testing with {{< var vm.product >}}

:::

::: {.column width="50%" .bl .pl4 .f2}
Try it **live** on the next pages. {{< fa hand-point-right >}}

:::
::::

::: {.f3}
<br>
So far, we’ve focused on the data assessment and pre-processing that usually occurs prior to any models being built. Now, let’s instead assume we have already built a model and we want to incorporate some model results into our documentation:

::: {.panel-tabset .f4}

### 1. Train your model

Using {{< var vm.product >}} tests, we’ll train a simple logistic regression model on our dataset and evaluate its performance by using the `LogisticRegression` class from the `sklearn.linear_model`.

### 2. Initialize the model object

The last step for evaluating the model’s performance is to initialize the {{< var vm.product >}} `Dataset` and `Model` objects in preparation for assigning model predictions to each dataset.

### 3. Assign predictions

Once the model has been registered you can assign model predictions to the training and test datasets. The `assign_predictions()` method from the `Dataset` object can link existing predictions to any number of models.

### 4. Run the model evaluation tests
In this next example, we’ll focus on running the tests within the Model Development section of the model documentation. Only tests associated with this section will be executed, and the corresponding results will be updated in the model documentation.

:::

:::

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html#train-simple-logistic-regression-model" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**Train your model**

Using {{< var vm.product >}} tests, we'll train a simple logistic regression model on our dataset and evaluate its performance:

1. Continue with **2 — Start the model development process**: [{{< fa square-arrow-up-right >}} JupyterHub]({{< var url.jupyterhub >}}/hub/user-redirect/lab/tree/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}
2. Run all the cells under the Model testing section: **Train simple logistic regression model**.

When you're done, return to this page and click [{{< fa chevron-right >}}]() to continue.

::::

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html#initialize-model-evaluation-objects" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**Initialize a model object**

Use the `init_dataset()` and [`init_model()` functions](/validmind/validmind.qmd#init_model){target="_blank"} to initialize these objects:

1. Continue with **2 — Start the model development process**: [{{< fa square-arrow-up-right >}} JupyterHub]({{< var url.jupyterhub >}}/hub/user-redirect/lab/tree/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}
2. Run the cell under the following Model testing section: **Initialize model evaluation objects**.

When you're done, return to this page and click [{{< fa chevron-right >}}]() to continue.

::::

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html#assign-predictions" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**Assign predictions**
Use the [`assign_predictions()` method](/validmind/validmind/vm_models.qmd#assign_predictions){target="_blank"} from the `Dataset` object to link existing predictions to any number of models:

1. Continue with **2 — Start the model development process**: [{{< fa square-arrow-up-right >}} JupyterHub]({{< var url.jupyterhub >}}/hub/user-redirect/lab/tree/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}
2. Run the cell under the following Model testing section: **Assign predictions**.

When you're done, return to this page and click [{{< fa chevron-right >}}]() to continue.

::::

## {background-iframe="/notebooks/EXECUTED/model_development/2-start_development_process.html#run-the-model-evaluation-tests" data-preload="yes"}

:::: {.slideover--r .three-quarters}
**Run the model evaluation tests**

Finally, we'll run only the tests within the Model Development section of the model documentation:

1. Continue with **2 — Start the model development process**: [{{< fa square-arrow-up-right >}} JupyterHub]({{< var url.jupyterhub >}}/hub/user-redirect/lab/tree/tutorials/model_development/2-start_development_process.ipynb){target="_blank"}
2. Run the cell under the following Model testing section: **Run the model evaluation tests**.

When you're done, return to this page and click [{{< fa chevron-right >}}]() to continue.

::::

# In summary {background-color="#083E44" background-image="/training/assets/home-hero.svg"}

## {.scrollable .center}

:::: {.columns}
::: {.column width="30%" .pr4 .f2}
Learning to run tests

:::

::: {.column width="70%" .bl .pl4 .f3}
In this second module, you learned how to:

- [x] Identify relevant tests to run from {{< var vm.product >}}'s test repository
- [x] Initialize {{< var vm.product >}} `Dataset` and `Model` objects
- [x] Run out-of-the-box tests with the {{< var validmind.developer >}}
- [x] Log test results to the {{< var validmind.platform >}}
- [x] Insert logged test results into your model's documentation

:::
::::

::: {.tc}
<br>
Continue your model development journey with:
<br><br>
<!-- IMPORTANT: USE THE .HTML PATH AND NOT THE .QMD PATH FOR THE REVEALJS OUTPUT -->
[Implementing Custom Tests](implementing-custom-tests.html){.button target="_blank"}
:::